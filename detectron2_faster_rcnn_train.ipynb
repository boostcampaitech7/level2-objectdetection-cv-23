{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import torch\n",
    "import detectron2\n",
    "from detectron2.data import detection_utils as utils\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.config import get_cfg, CfgNode\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.evaluation import COCOEvaluator\n",
    "from detectron2.data import build_detection_test_loader, build_detection_train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register Dataset\n",
    "try:\n",
    "    register_coco_instances('coco_trash_train', {}, '/data/ephemeral/home/workspace/dataset/train.json', '/data/ephemeral/home/workspace/dataset/')\n",
    "except AssertionError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    register_coco_instances('coco_trash_test', {}, '/data/ephemeral/home/workspace/dataset/test.json', '/data/ephemeral/home/workspace/dataset/')\n",
    "except AssertionError:\n",
    "    pass\n",
    "\n",
    "MetadataCatalog.get('coco_trash_train').thing_classes = [\"General trash\", \"Paper\", \"Paper pack\", \"Metal\", \n",
    "                                                         \"Glass\", \"Plastic\", \"Styrofoam\", \"Plastic bag\", \"Battery\", \"Clothing\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config 불러오기\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file('COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config 수정하기\n",
    "cfg.DATASETS.TRAIN = ('coco_trash_train',)\n",
    "cfg.DATASETS.TEST = ('coco_trash_test',)\n",
    "\n",
    "cfg.DATALOADER.NUM_WOREKRS = 2\n",
    "\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url('COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml')\n",
    "\n",
    "cfg.SOLVER.IMS_PER_BATCH = 4\n",
    "cfg.SOLVER.BASE_LR = 0.001\n",
    "cfg.SOLVER.MAX_ITER = 15000\n",
    "cfg.SOLVER.STEPS = (8000,12000)\n",
    "cfg.SOLVER.GAMMA = 0.005\n",
    "cfg.SOLVER.CHECKPOINT_PERIOD = 3000\n",
    "\n",
    "cfg.OUTPUT_DIR = './output'\n",
    "\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 10\n",
    "\n",
    "cfg.TEST.EVAL_PERIOD = 3000\n",
    "\n",
    "# mlflow config 추가 \n",
    "cfg.MLFLOW = CfgNode()\n",
    "cfg.MLFLOW.EXPERIMENT_NAME = \"detectron2_faster_rcnn\"\n",
    "cfg.MLFLOW.RUN_NAME = \"#0_detectron2_baseline_training\"\n",
    "cfg.MLFLOW.TRACKING_URI = \"http://10.28.224.171:30280\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.engine import HookBase\n",
    "import mlflow\n",
    "\n",
    "class MLflowHook(HookBase):\n",
    "    \"\"\"\n",
    "    custom hook class를 사용하여 mlflow에 model artifacts와 metrics, parameters 추가 \n",
    "    \"\"\"\n",
    "    def __init__(self, cfg) -> None:\n",
    "        super().__init__()\n",
    "        self.cfg = cfg.clone()\n",
    "    \n",
    "    # tracking server URI, experiment 이름, run 이름을 설정하고 실행을 시작\n",
    "    def before_train(self):\n",
    "        with torch.no_grad():\n",
    "            mlflow.set_tracking_uri(self.cfg.MLFLOW.TRACKING_URI)\n",
    "            mlflow.set_experiment(self.cfg.MLFLOW.EXPERIMENT_NAME)\n",
    "            mlflow.start_run(run_name=self.cfg.MLFLOW.RUN_NAME)\n",
    "        for k, v in self.cfg.items():\n",
    "                mlflow.log_param(k, v) \n",
    "                \n",
    "    # iteration step마다 Detectron2의 EventStorage에서 latest training metrics을 요청\n",
    "    def after_step(self):\n",
    "        with torch.no_grad():\n",
    "            latest_metrics = self.trainer.storage.latest()\n",
    "            for k, v in latest_metrics.items():\n",
    "                mlflow.log_metric(key=k, value=v[0], step=v[1])\n",
    "    \n",
    "    # Detectron2 구성을 YAML 파일에 덤프하고 마지막으로 모든 출력 파일(config YAML 포함)을 MLflow에 로깅      \n",
    "    def after_train(self):\n",
    "        with torch.no_grad():\n",
    "            with open(os.path.join(self.cfg.OUTPUT_DIR, \"model-config.yaml\"), \"w\") as f:\n",
    "                f.write(self.cfg.dump())\n",
    "            mlflow.log_artifacts(self.cfg.OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapper - input data를 어떤 형식으로 return할지 (따라서 augmnentation 등 데이터 전처리 포함 됨)\n",
    "import detectron2.data.transforms as T\n",
    "\n",
    "def MyMapper(dataset_dict):\n",
    "    dataset_dict = copy.deepcopy(dataset_dict)\n",
    "    image = utils.read_image(dataset_dict['file_name'], format='BGR')\n",
    "    \n",
    "    transform_list = [\n",
    "        T.RandomFlip(prob=0.5, horizontal=False, vertical=True),\n",
    "        T.RandomBrightness(0.8, 1.8),\n",
    "        T.RandomContrast(0.6, 1.3)\n",
    "    ]\n",
    "    \n",
    "    image, transforms = T.apply_transform_gens(transform_list, image)\n",
    "    \n",
    "    dataset_dict['image'] = torch.as_tensor(image.transpose(2,0,1).astype('float32'))\n",
    "    \n",
    "    annos = [\n",
    "        utils.transform_instance_annotations(obj, transforms, image.shape[:2])\n",
    "        for obj in dataset_dict.pop('annotations')\n",
    "        if obj.get('iscrowd', 0) == 0\n",
    "    ]\n",
    "    \n",
    "    instances = utils.annotations_to_instances(annos, image.shape[:2])\n",
    "    dataset_dict['instances'] = utils.filter_empty_instances(instances)\n",
    "    \n",
    "    return dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer - DefaultTrainer를 상속\n",
    "class MyTrainer(DefaultTrainer):\n",
    "    \n",
    "    @classmethod\n",
    "    def build_train_loader(cls, cfg, sampler=None):\n",
    "        return build_detection_train_loader(\n",
    "        cfg, mapper = MyMapper, sampler = sampler\n",
    "        )\n",
    "    \n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "        if output_folder is None:\n",
    "            os.makedirs('./output_eval', exist_ok = True)\n",
    "            output_folder = './output_eval'\n",
    "            \n",
    "        return COCOEvaluator(dataset_name, cfg, False, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/10 01:15:33 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (6): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (7): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (8): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (9): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (10): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (11): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (12): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (13): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (14): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (15): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (16): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (17): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (18): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (19): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (20): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (21): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (22): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=11, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=40, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/10 01:15:33 d2.data.datasets.coco]: \u001b[0mLoaded 4883 images in COCO format from /data/ephemeral/home/workspace/dataset/train.json\n",
      "\u001b[32m[10/10 01:15:33 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 4883 images left.\n",
      "\u001b[32m[10/10 01:15:33 d2.data.build]: \u001b[0mDistribution of instances among all 10 categories:\n",
      "\u001b[36m|   category    | #instances   |  category   | #instances   |  category  | #instances   |\n",
      "|:-------------:|:-------------|:-----------:|:-------------|:----------:|:-------------|\n",
      "| General trash | 3966         |    Paper    | 6352         | Paper pack | 897          |\n",
      "|     Metal     | 936          |    Glass    | 982          |  Plastic   | 2943         |\n",
      "|   Styrofoam   | 1263         | Plastic bag | 5178         |  Battery   | 159          |\n",
      "|   Clothing    | 468          |             |              |            |              |\n",
      "|     total     | 23144        |             |              |            |              |\u001b[0m\n",
      "\u001b[32m[10/10 01:15:33 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/10 01:15:33 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[10/10 01:15:33 d2.data.common]: \u001b[0mSerializing 4883 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/10 01:15:33 d2.data.common]: \u001b[0mSerialized dataset takes 2.30 MiB\n",
      "\u001b[32m[10/10 01:15:33 d2.data.build]: \u001b[0mMaking batched data loader with batch_size=4\n",
      "\u001b[32m[10/10 01:15:33 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_R_101_FPN_3x/137851257/model_final_f6e8b1.pkl ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (11, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (11,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (40, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (40,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/10 01:15:34 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/10 01:15:34 INFO mlflow.tracking.fluent: Experiment with name 'detectron2_faster_rcnn' does not exist. Creating a new experiment.\n",
      "/opt/conda/lib/python3.10/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/10 01:15:47 d2.utils.events]: \u001b[0m eta: 2:01:10  iter: 19  total_loss: 3.186  loss_cls: 2.282  loss_box_reg: 0.7591  loss_rpn_cls: 0.09385  loss_rpn_loc: 0.02435    time: 0.4867  last_time: 0.4796  data_time: 0.0282  last_data_time: 0.0145   lr: 1.9981e-05  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:15:58 d2.utils.events]: \u001b[0m eta: 2:00:11  iter: 39  total_loss: 2.807  loss_cls: 1.862  loss_box_reg: 0.7333  loss_rpn_cls: 0.05259  loss_rpn_loc: 0.02533    time: 0.4837  last_time: 0.4800  data_time: 0.0143  last_data_time: 0.0129   lr: 3.9961e-05  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:16:09 d2.utils.events]: \u001b[0m eta: 2:00:01  iter: 59  total_loss: 1.973  loss_cls: 1.102  loss_box_reg: 0.6842  loss_rpn_cls: 0.05342  loss_rpn_loc: 0.0398    time: 0.4839  last_time: 0.4841  data_time: 0.0150  last_data_time: 0.0173   lr: 5.9941e-05  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:16:20 d2.utils.events]: \u001b[0m eta: 1:59:57  iter: 79  total_loss: 1.695  loss_cls: 0.8372  loss_box_reg: 0.7189  loss_rpn_cls: 0.0351  loss_rpn_loc: 0.02802    time: 0.4836  last_time: 0.4835  data_time: 0.0152  last_data_time: 0.0141   lr: 7.9921e-05  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:16:31 d2.utils.events]: \u001b[0m eta: 1:59:47  iter: 99  total_loss: 1.671  loss_cls: 0.7632  loss_box_reg: 0.7318  loss_rpn_cls: 0.05198  loss_rpn_loc: 0.03411    time: 0.4836  last_time: 0.4828  data_time: 0.0152  last_data_time: 0.0140   lr: 9.9901e-05  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:16:42 d2.utils.events]: \u001b[0m eta: 1:59:39  iter: 119  total_loss: 1.474  loss_cls: 0.6941  loss_box_reg: 0.7133  loss_rpn_cls: 0.02606  loss_rpn_loc: 0.02339    time: 0.4837  last_time: 0.4838  data_time: 0.0169  last_data_time: 0.0172   lr: 0.00011988  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:16:53 d2.utils.events]: \u001b[0m eta: 1:59:29  iter: 139  total_loss: 1.621  loss_cls: 0.7109  loss_box_reg: 0.7643  loss_rpn_cls: 0.03084  loss_rpn_loc: 0.02893    time: 0.4835  last_time: 0.4809  data_time: 0.0153  last_data_time: 0.0146   lr: 0.00013986  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:17:04 d2.utils.events]: \u001b[0m eta: 1:59:17  iter: 159  total_loss: 1.468  loss_cls: 0.6604  loss_box_reg: 0.6902  loss_rpn_cls: 0.0349  loss_rpn_loc: 0.02881    time: 0.4835  last_time: 0.4805  data_time: 0.0163  last_data_time: 0.0144   lr: 0.00015984  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:17:15 d2.utils.events]: \u001b[0m eta: 1:59:09  iter: 179  total_loss: 1.444  loss_cls: 0.668  loss_box_reg: 0.7168  loss_rpn_cls: 0.04477  loss_rpn_loc: 0.03064    time: 0.4836  last_time: 0.4824  data_time: 0.0168  last_data_time: 0.0143   lr: 0.00017982  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:17:26 d2.utils.events]: \u001b[0m eta: 1:59:00  iter: 199  total_loss: 1.244  loss_cls: 0.5707  loss_box_reg: 0.6161  loss_rpn_cls: 0.01883  loss_rpn_loc: 0.01455    time: 0.4836  last_time: 0.4800  data_time: 0.0163  last_data_time: 0.0160   lr: 0.0001998  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:17:37 d2.utils.events]: \u001b[0m eta: 1:58:50  iter: 219  total_loss: 1.383  loss_cls: 0.6255  loss_box_reg: 0.6825  loss_rpn_cls: 0.03125  loss_rpn_loc: 0.02506    time: 0.4836  last_time: 0.4852  data_time: 0.0149  last_data_time: 0.0187   lr: 0.00021978  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:17:48 d2.utils.events]: \u001b[0m eta: 1:58:41  iter: 239  total_loss: 1.497  loss_cls: 0.6618  loss_box_reg: 0.7182  loss_rpn_cls: 0.03978  loss_rpn_loc: 0.03639    time: 0.4836  last_time: 0.4874  data_time: 0.0150  last_data_time: 0.0175   lr: 0.00023976  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:17:59 d2.utils.events]: \u001b[0m eta: 1:58:33  iter: 259  total_loss: 1.436  loss_cls: 0.6423  loss_box_reg: 0.6707  loss_rpn_cls: 0.02855  loss_rpn_loc: 0.03413    time: 0.4837  last_time: 0.4927  data_time: 0.0161  last_data_time: 0.0216   lr: 0.00025974  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:18:10 d2.utils.events]: \u001b[0m eta: 1:58:26  iter: 279  total_loss: 1.238  loss_cls: 0.5404  loss_box_reg: 0.6174  loss_rpn_cls: 0.02669  loss_rpn_loc: 0.02839    time: 0.4838  last_time: 0.4877  data_time: 0.0161  last_data_time: 0.0169   lr: 0.00027972  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:18:20 d2.utils.events]: \u001b[0m eta: 1:58:18  iter: 299  total_loss: 1.229  loss_cls: 0.5641  loss_box_reg: 0.5672  loss_rpn_cls: 0.02804  loss_rpn_loc: 0.02652    time: 0.4838  last_time: 0.4816  data_time: 0.0165  last_data_time: 0.0143   lr: 0.0002997  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:18:31 d2.utils.events]: \u001b[0m eta: 1:58:08  iter: 319  total_loss: 1.275  loss_cls: 0.592  loss_box_reg: 0.6077  loss_rpn_cls: 0.02954  loss_rpn_loc: 0.03349    time: 0.4838  last_time: 0.4821  data_time: 0.0155  last_data_time: 0.0144   lr: 0.00031968  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:18:42 d2.utils.events]: \u001b[0m eta: 1:57:57  iter: 339  total_loss: 1.266  loss_cls: 0.5839  loss_box_reg: 0.5835  loss_rpn_cls: 0.02763  loss_rpn_loc: 0.03157    time: 0.4838  last_time: 0.4815  data_time: 0.0155  last_data_time: 0.0143   lr: 0.00033966  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:18:53 d2.utils.events]: \u001b[0m eta: 1:57:47  iter: 359  total_loss: 1.075  loss_cls: 0.5259  loss_box_reg: 0.514  loss_rpn_cls: 0.02915  loss_rpn_loc: 0.03074    time: 0.4838  last_time: 0.4810  data_time: 0.0156  last_data_time: 0.0146   lr: 0.00035964  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:19:04 d2.utils.events]: \u001b[0m eta: 1:57:39  iter: 379  total_loss: 1.124  loss_cls: 0.5647  loss_box_reg: 0.4654  loss_rpn_cls: 0.04341  loss_rpn_loc: 0.02463    time: 0.4838  last_time: 0.4809  data_time: 0.0159  last_data_time: 0.0145   lr: 0.00037962  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:19:15 d2.utils.events]: \u001b[0m eta: 1:57:28  iter: 399  total_loss: 1.211  loss_cls: 0.608  loss_box_reg: 0.4815  loss_rpn_cls: 0.03374  loss_rpn_loc: 0.03229    time: 0.4838  last_time: 0.4807  data_time: 0.0159  last_data_time: 0.0141   lr: 0.0003996  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:19:26 d2.utils.events]: \u001b[0m eta: 1:57:20  iter: 419  total_loss: 1.174  loss_cls: 0.5989  loss_box_reg: 0.4618  loss_rpn_cls: 0.0264  loss_rpn_loc: 0.04627    time: 0.4839  last_time: 0.4846  data_time: 0.0160  last_data_time: 0.0146   lr: 0.00041958  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:19:37 d2.utils.events]: \u001b[0m eta: 1:57:11  iter: 439  total_loss: 1.127  loss_cls: 0.586  loss_box_reg: 0.4821  loss_rpn_cls: 0.02459  loss_rpn_loc: 0.03534    time: 0.4839  last_time: 0.4874  data_time: 0.0158  last_data_time: 0.0139   lr: 0.00043956  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:19:48 d2.utils.events]: \u001b[0m eta: 1:57:01  iter: 459  total_loss: 1.082  loss_cls: 0.5296  loss_box_reg: 0.4188  loss_rpn_cls: 0.03556  loss_rpn_loc: 0.03964    time: 0.4839  last_time: 0.4878  data_time: 0.0154  last_data_time: 0.0154   lr: 0.00045954  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:19:59 d2.utils.events]: \u001b[0m eta: 1:56:50  iter: 479  total_loss: 0.9623  loss_cls: 0.5237  loss_box_reg: 0.3957  loss_rpn_cls: 0.02391  loss_rpn_loc: 0.02508    time: 0.4838  last_time: 0.4789  data_time: 0.0156  last_data_time: 0.0142   lr: 0.00047952  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:20:10 d2.utils.events]: \u001b[0m eta: 1:56:39  iter: 499  total_loss: 0.9874  loss_cls: 0.5126  loss_box_reg: 0.4009  loss_rpn_cls: 0.03393  loss_rpn_loc: 0.02495    time: 0.4837  last_time: 0.4790  data_time: 0.0160  last_data_time: 0.0144   lr: 0.0004995  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:20:21 d2.utils.events]: \u001b[0m eta: 1:56:30  iter: 519  total_loss: 0.949  loss_cls: 0.5211  loss_box_reg: 0.3441  loss_rpn_cls: 0.03434  loss_rpn_loc: 0.01997    time: 0.4837  last_time: 0.4827  data_time: 0.0156  last_data_time: 0.0149   lr: 0.00051948  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:20:32 d2.utils.events]: \u001b[0m eta: 1:56:22  iter: 539  total_loss: 0.8791  loss_cls: 0.5  loss_box_reg: 0.2976  loss_rpn_cls: 0.02483  loss_rpn_loc: 0.0308    time: 0.4837  last_time: 0.4860  data_time: 0.0160  last_data_time: 0.0163   lr: 0.00053946  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:20:43 d2.utils.events]: \u001b[0m eta: 1:56:12  iter: 559  total_loss: 0.9232  loss_cls: 0.5036  loss_box_reg: 0.3331  loss_rpn_cls: 0.03187  loss_rpn_loc: 0.03355    time: 0.4837  last_time: 0.4844  data_time: 0.0152  last_data_time: 0.0145   lr: 0.00055944  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:20:54 d2.utils.events]: \u001b[0m eta: 1:56:03  iter: 579  total_loss: 1.029  loss_cls: 0.5603  loss_box_reg: 0.4058  loss_rpn_cls: 0.01724  loss_rpn_loc: 0.02279    time: 0.4838  last_time: 0.4887  data_time: 0.0169  last_data_time: 0.0193   lr: 0.00057942  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:21:05 d2.utils.events]: \u001b[0m eta: 1:55:54  iter: 599  total_loss: 0.8614  loss_cls: 0.4885  loss_box_reg: 0.3112  loss_rpn_cls: 0.02059  loss_rpn_loc: 0.03104    time: 0.4838  last_time: 0.4831  data_time: 0.0162  last_data_time: 0.0149   lr: 0.0005994  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:21:16 d2.utils.events]: \u001b[0m eta: 1:55:44  iter: 619  total_loss: 0.8844  loss_cls: 0.4755  loss_box_reg: 0.3419  loss_rpn_cls: 0.02849  loss_rpn_loc: 0.01868    time: 0.4839  last_time: 0.4852  data_time: 0.0174  last_data_time: 0.0145   lr: 0.00061938  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:21:27 d2.utils.events]: \u001b[0m eta: 1:55:35  iter: 639  total_loss: 1.034  loss_cls: 0.5375  loss_box_reg: 0.3794  loss_rpn_cls: 0.03463  loss_rpn_loc: 0.02195    time: 0.4839  last_time: 0.4823  data_time: 0.0162  last_data_time: 0.0148   lr: 0.00063936  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:21:38 d2.utils.events]: \u001b[0m eta: 1:55:25  iter: 659  total_loss: 0.8671  loss_cls: 0.491  loss_box_reg: 0.3496  loss_rpn_cls: 0.02479  loss_rpn_loc: 0.0233    time: 0.4839  last_time: 0.4861  data_time: 0.0158  last_data_time: 0.0142   lr: 0.00065934  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:21:49 d2.utils.events]: \u001b[0m eta: 1:55:17  iter: 679  total_loss: 0.9986  loss_cls: 0.5246  loss_box_reg: 0.3831  loss_rpn_cls: 0.03095  loss_rpn_loc: 0.02711    time: 0.4839  last_time: 0.4957  data_time: 0.0162  last_data_time: 0.0255   lr: 0.00067932  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:22:00 d2.utils.events]: \u001b[0m eta: 1:55:07  iter: 699  total_loss: 0.8778  loss_cls: 0.4698  loss_box_reg: 0.3255  loss_rpn_cls: 0.04033  loss_rpn_loc: 0.03821    time: 0.4839  last_time: 0.4828  data_time: 0.0158  last_data_time: 0.0146   lr: 0.0006993  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:22:11 d2.utils.events]: \u001b[0m eta: 1:54:57  iter: 719  total_loss: 0.8064  loss_cls: 0.4761  loss_box_reg: 0.297  loss_rpn_cls: 0.02607  loss_rpn_loc: 0.01954    time: 0.4839  last_time: 0.4794  data_time: 0.0158  last_data_time: 0.0142   lr: 0.00071928  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:22:22 d2.utils.events]: \u001b[0m eta: 1:54:46  iter: 739  total_loss: 0.8063  loss_cls: 0.4581  loss_box_reg: 0.2682  loss_rpn_cls: 0.02616  loss_rpn_loc: 0.01819    time: 0.4838  last_time: 0.4802  data_time: 0.0147  last_data_time: 0.0144   lr: 0.00073926  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:22:33 d2.utils.events]: \u001b[0m eta: 1:54:36  iter: 759  total_loss: 0.9161  loss_cls: 0.4921  loss_box_reg: 0.3154  loss_rpn_cls: 0.02483  loss_rpn_loc: 0.03308    time: 0.4838  last_time: 0.4814  data_time: 0.0149  last_data_time: 0.0151   lr: 0.00075924  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:22:44 d2.utils.events]: \u001b[0m eta: 1:54:27  iter: 779  total_loss: 0.8578  loss_cls: 0.4799  loss_box_reg: 0.3076  loss_rpn_cls: 0.03294  loss_rpn_loc: 0.02319    time: 0.4838  last_time: 0.4833  data_time: 0.0160  last_data_time: 0.0148   lr: 0.00077922  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:22:54 d2.utils.events]: \u001b[0m eta: 1:54:17  iter: 799  total_loss: 0.836  loss_cls: 0.4831  loss_box_reg: 0.2915  loss_rpn_cls: 0.0266  loss_rpn_loc: 0.03302    time: 0.4838  last_time: 0.4956  data_time: 0.0159  last_data_time: 0.0177   lr: 0.0007992  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:23:05 d2.utils.events]: \u001b[0m eta: 1:54:08  iter: 819  total_loss: 0.9242  loss_cls: 0.5163  loss_box_reg: 0.3119  loss_rpn_cls: 0.01926  loss_rpn_loc: 0.02392    time: 0.4838  last_time: 0.4981  data_time: 0.0175  last_data_time: 0.0268   lr: 0.00081918  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:23:16 d2.utils.events]: \u001b[0m eta: 1:53:59  iter: 839  total_loss: 0.7905  loss_cls: 0.4485  loss_box_reg: 0.2867  loss_rpn_cls: 0.01631  loss_rpn_loc: 0.0218    time: 0.4839  last_time: 0.4977  data_time: 0.0157  last_data_time: 0.0204   lr: 0.00083916  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:23:27 d2.utils.events]: \u001b[0m eta: 1:53:49  iter: 859  total_loss: 0.8691  loss_cls: 0.4499  loss_box_reg: 0.3435  loss_rpn_cls: 0.02075  loss_rpn_loc: 0.02696    time: 0.4838  last_time: 0.4849  data_time: 0.0153  last_data_time: 0.0183   lr: 0.00085914  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:23:38 d2.utils.events]: \u001b[0m eta: 1:53:39  iter: 879  total_loss: 0.964  loss_cls: 0.4995  loss_box_reg: 0.3788  loss_rpn_cls: 0.02505  loss_rpn_loc: 0.03275    time: 0.4838  last_time: 0.4841  data_time: 0.0147  last_data_time: 0.0156   lr: 0.00087912  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:23:49 d2.utils.events]: \u001b[0m eta: 1:53:29  iter: 899  total_loss: 0.9137  loss_cls: 0.437  loss_box_reg: 0.337  loss_rpn_cls: 0.03339  loss_rpn_loc: 0.03346    time: 0.4838  last_time: 0.4836  data_time: 0.0165  last_data_time: 0.0145   lr: 0.0008991  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:24:00 d2.utils.events]: \u001b[0m eta: 1:53:19  iter: 919  total_loss: 0.8519  loss_cls: 0.5032  loss_box_reg: 0.3302  loss_rpn_cls: 0.02861  loss_rpn_loc: 0.02249    time: 0.4838  last_time: 0.4823  data_time: 0.0157  last_data_time: 0.0146   lr: 0.00091908  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:24:11 d2.utils.events]: \u001b[0m eta: 1:53:10  iter: 939  total_loss: 0.8129  loss_cls: 0.4368  loss_box_reg: 0.2935  loss_rpn_cls: 0.02162  loss_rpn_loc: 0.02173    time: 0.4838  last_time: 0.4846  data_time: 0.0161  last_data_time: 0.0179   lr: 0.00093906  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:24:22 d2.utils.events]: \u001b[0m eta: 1:53:01  iter: 959  total_loss: 0.916  loss_cls: 0.4838  loss_box_reg: 0.3367  loss_rpn_cls: 0.03369  loss_rpn_loc: 0.03468    time: 0.4839  last_time: 0.4824  data_time: 0.0163  last_data_time: 0.0145   lr: 0.00095904  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:24:33 d2.utils.events]: \u001b[0m eta: 1:52:51  iter: 979  total_loss: 0.9957  loss_cls: 0.5185  loss_box_reg: 0.3084  loss_rpn_cls: 0.02824  loss_rpn_loc: 0.02933    time: 0.4838  last_time: 0.4814  data_time: 0.0151  last_data_time: 0.0141   lr: 0.00097902  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:24:44 d2.utils.events]: \u001b[0m eta: 1:52:41  iter: 999  total_loss: 0.9214  loss_cls: 0.479  loss_box_reg: 0.3693  loss_rpn_cls: 0.02245  loss_rpn_loc: 0.03985    time: 0.4838  last_time: 0.4949  data_time: 0.0159  last_data_time: 0.0170   lr: 0.000999  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:24:55 d2.utils.events]: \u001b[0m eta: 1:52:31  iter: 1019  total_loss: 0.9069  loss_cls: 0.4619  loss_box_reg: 0.3295  loss_rpn_cls: 0.02164  loss_rpn_loc: 0.02879    time: 0.4839  last_time: 0.4933  data_time: 0.0165  last_data_time: 0.0145   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:25:06 d2.utils.events]: \u001b[0m eta: 1:52:22  iter: 1039  total_loss: 0.7291  loss_cls: 0.401  loss_box_reg: 0.255  loss_rpn_cls: 0.01808  loss_rpn_loc: 0.01256    time: 0.4839  last_time: 0.4779  data_time: 0.0160  last_data_time: 0.0143   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:25:17 d2.utils.events]: \u001b[0m eta: 1:52:12  iter: 1059  total_loss: 0.8415  loss_cls: 0.4478  loss_box_reg: 0.327  loss_rpn_cls: 0.01974  loss_rpn_loc: 0.0223    time: 0.4839  last_time: 0.4822  data_time: 0.0141  last_data_time: 0.0140   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:25:28 d2.utils.events]: \u001b[0m eta: 1:52:02  iter: 1079  total_loss: 0.737  loss_cls: 0.4283  loss_box_reg: 0.2625  loss_rpn_cls: 0.01398  loss_rpn_loc: 0.01982    time: 0.4839  last_time: 0.4826  data_time: 0.0145  last_data_time: 0.0149   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:25:39 d2.utils.events]: \u001b[0m eta: 1:51:53  iter: 1099  total_loss: 0.956  loss_cls: 0.5044  loss_box_reg: 0.364  loss_rpn_cls: 0.03616  loss_rpn_loc: 0.03232    time: 0.4838  last_time: 0.4805  data_time: 0.0148  last_data_time: 0.0139   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:25:50 d2.utils.events]: \u001b[0m eta: 1:51:43  iter: 1119  total_loss: 0.8405  loss_cls: 0.455  loss_box_reg: 0.3091  loss_rpn_cls: 0.02039  loss_rpn_loc: 0.01583    time: 0.4838  last_time: 0.4864  data_time: 0.0159  last_data_time: 0.0173   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:26:01 d2.utils.events]: \u001b[0m eta: 1:51:34  iter: 1139  total_loss: 0.8882  loss_cls: 0.4512  loss_box_reg: 0.3248  loss_rpn_cls: 0.0218  loss_rpn_loc: 0.03038    time: 0.4839  last_time: 0.4827  data_time: 0.0156  last_data_time: 0.0144   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:26:12 d2.utils.events]: \u001b[0m eta: 1:51:26  iter: 1159  total_loss: 0.8068  loss_cls: 0.4685  loss_box_reg: 0.2906  loss_rpn_cls: 0.026  loss_rpn_loc: 0.02847    time: 0.4839  last_time: 0.4831  data_time: 0.0161  last_data_time: 0.0144   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:26:23 d2.utils.events]: \u001b[0m eta: 1:51:16  iter: 1179  total_loss: 0.8379  loss_cls: 0.465  loss_box_reg: 0.287  loss_rpn_cls: 0.02084  loss_rpn_loc: 0.02697    time: 0.4839  last_time: 0.4829  data_time: 0.0154  last_data_time: 0.0150   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:26:34 d2.utils.events]: \u001b[0m eta: 1:51:07  iter: 1199  total_loss: 0.7514  loss_cls: 0.4472  loss_box_reg: 0.2659  loss_rpn_cls: 0.02976  loss_rpn_loc: 0.01933    time: 0.4839  last_time: 0.4843  data_time: 0.0156  last_data_time: 0.0179   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:26:45 d2.utils.events]: \u001b[0m eta: 1:50:57  iter: 1219  total_loss: 0.8121  loss_cls: 0.4295  loss_box_reg: 0.3189  loss_rpn_cls: 0.03407  loss_rpn_loc: 0.03849    time: 0.4839  last_time: 0.4883  data_time: 0.0165  last_data_time: 0.0168   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:26:56 d2.utils.events]: \u001b[0m eta: 1:50:48  iter: 1239  total_loss: 0.7858  loss_cls: 0.4006  loss_box_reg: 0.2884  loss_rpn_cls: 0.0242  loss_rpn_loc: 0.02381    time: 0.4839  last_time: 0.4837  data_time: 0.0154  last_data_time: 0.0156   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:27:07 d2.utils.events]: \u001b[0m eta: 1:50:38  iter: 1259  total_loss: 0.78  loss_cls: 0.404  loss_box_reg: 0.2927  loss_rpn_cls: 0.019  loss_rpn_loc: 0.02591    time: 0.4839  last_time: 0.4810  data_time: 0.0160  last_data_time: 0.0139   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:27:17 d2.utils.events]: \u001b[0m eta: 1:50:28  iter: 1279  total_loss: 0.9375  loss_cls: 0.5135  loss_box_reg: 0.3475  loss_rpn_cls: 0.03174  loss_rpn_loc: 0.04081    time: 0.4839  last_time: 0.4815  data_time: 0.0159  last_data_time: 0.0142   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:27:28 d2.utils.events]: \u001b[0m eta: 1:50:18  iter: 1299  total_loss: 0.74  loss_cls: 0.4383  loss_box_reg: 0.259  loss_rpn_cls: 0.02279  loss_rpn_loc: 0.01592    time: 0.4839  last_time: 0.4823  data_time: 0.0148  last_data_time: 0.0158   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:27:40 d2.utils.events]: \u001b[0m eta: 1:50:08  iter: 1319  total_loss: 0.9172  loss_cls: 0.472  loss_box_reg: 0.3478  loss_rpn_cls: 0.02679  loss_rpn_loc: 0.02559    time: 0.4840  last_time: 0.4846  data_time: 0.0156  last_data_time: 0.0163   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:27:51 d2.utils.events]: \u001b[0m eta: 1:49:59  iter: 1339  total_loss: 0.7367  loss_cls: 0.4313  loss_box_reg: 0.2569  loss_rpn_cls: 0.02503  loss_rpn_loc: 0.01928    time: 0.4840  last_time: 0.4809  data_time: 0.0162  last_data_time: 0.0184   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:28:01 d2.utils.events]: \u001b[0m eta: 1:49:49  iter: 1359  total_loss: 0.8191  loss_cls: 0.4198  loss_box_reg: 0.3254  loss_rpn_cls: 0.01871  loss_rpn_loc: 0.02911    time: 0.4839  last_time: 0.4856  data_time: 0.0146  last_data_time: 0.0160   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:28:12 d2.utils.events]: \u001b[0m eta: 1:49:38  iter: 1379  total_loss: 0.7593  loss_cls: 0.4201  loss_box_reg: 0.2728  loss_rpn_cls: 0.01937  loss_rpn_loc: 0.0216    time: 0.4839  last_time: 0.4815  data_time: 0.0150  last_data_time: 0.0145   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:28:23 d2.utils.events]: \u001b[0m eta: 1:49:29  iter: 1399  total_loss: 0.7502  loss_cls: 0.4002  loss_box_reg: 0.2823  loss_rpn_cls: 0.02346  loss_rpn_loc: 0.02225    time: 0.4839  last_time: 0.4785  data_time: 0.0164  last_data_time: 0.0142   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:28:34 d2.utils.events]: \u001b[0m eta: 1:49:18  iter: 1419  total_loss: 0.7839  loss_cls: 0.414  loss_box_reg: 0.2508  loss_rpn_cls: 0.03036  loss_rpn_loc: 0.03521    time: 0.4839  last_time: 0.4827  data_time: 0.0156  last_data_time: 0.0143   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:28:45 d2.utils.events]: \u001b[0m eta: 1:49:09  iter: 1439  total_loss: 0.8788  loss_cls: 0.438  loss_box_reg: 0.3563  loss_rpn_cls: 0.01751  loss_rpn_loc: 0.04256    time: 0.4839  last_time: 0.4878  data_time: 0.0153  last_data_time: 0.0186   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:28:56 d2.utils.events]: \u001b[0m eta: 1:49:00  iter: 1459  total_loss: 0.7481  loss_cls: 0.3804  loss_box_reg: 0.2897  loss_rpn_cls: 0.01717  loss_rpn_loc: 0.02654    time: 0.4839  last_time: 0.4806  data_time: 0.0157  last_data_time: 0.0143   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:29:07 d2.utils.events]: \u001b[0m eta: 1:48:52  iter: 1479  total_loss: 0.8495  loss_cls: 0.4393  loss_box_reg: 0.3651  loss_rpn_cls: 0.02188  loss_rpn_loc: 0.03017    time: 0.4839  last_time: 0.4869  data_time: 0.0161  last_data_time: 0.0145   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:29:18 d2.utils.events]: \u001b[0m eta: 1:48:42  iter: 1499  total_loss: 0.5947  loss_cls: 0.3817  loss_box_reg: 0.2281  loss_rpn_cls: 0.01931  loss_rpn_loc: 0.02187    time: 0.4840  last_time: 0.4822  data_time: 0.0168  last_data_time: 0.0151   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:29:29 d2.utils.events]: \u001b[0m eta: 1:48:32  iter: 1519  total_loss: 0.8174  loss_cls: 0.4375  loss_box_reg: 0.2726  loss_rpn_cls: 0.02737  loss_rpn_loc: 0.02343    time: 0.4840  last_time: 0.4817  data_time: 0.0160  last_data_time: 0.0161   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:29:40 d2.utils.events]: \u001b[0m eta: 1:48:22  iter: 1539  total_loss: 0.6815  loss_cls: 0.3866  loss_box_reg: 0.2538  loss_rpn_cls: 0.02112  loss_rpn_loc: 0.02395    time: 0.4840  last_time: 0.4802  data_time: 0.0157  last_data_time: 0.0167   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:29:51 d2.utils.events]: \u001b[0m eta: 1:48:13  iter: 1559  total_loss: 0.7436  loss_cls: 0.419  loss_box_reg: 0.2568  loss_rpn_cls: 0.02125  loss_rpn_loc: 0.0201    time: 0.4840  last_time: 0.4845  data_time: 0.0168  last_data_time: 0.0171   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:30:02 d2.utils.events]: \u001b[0m eta: 1:48:03  iter: 1579  total_loss: 0.7639  loss_cls: 0.4037  loss_box_reg: 0.2785  loss_rpn_cls: 0.01852  loss_rpn_loc: 0.0414    time: 0.4840  last_time: 0.4801  data_time: 0.0154  last_data_time: 0.0141   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:30:13 d2.utils.events]: \u001b[0m eta: 1:47:53  iter: 1599  total_loss: 0.9571  loss_cls: 0.5079  loss_box_reg: 0.371  loss_rpn_cls: 0.03723  loss_rpn_loc: 0.04242    time: 0.4840  last_time: 0.4860  data_time: 0.0165  last_data_time: 0.0177   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:30:24 d2.utils.events]: \u001b[0m eta: 1:47:43  iter: 1619  total_loss: 0.7225  loss_cls: 0.3933  loss_box_reg: 0.2443  loss_rpn_cls: 0.01794  loss_rpn_loc: 0.01642    time: 0.4840  last_time: 0.4837  data_time: 0.0161  last_data_time: 0.0145   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:30:35 d2.utils.events]: \u001b[0m eta: 1:47:34  iter: 1639  total_loss: 0.8076  loss_cls: 0.4319  loss_box_reg: 0.288  loss_rpn_cls: 0.02166  loss_rpn_loc: 0.0215    time: 0.4840  last_time: 0.4904  data_time: 0.0187  last_data_time: 0.0214   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:30:46 d2.utils.events]: \u001b[0m eta: 1:47:25  iter: 1659  total_loss: 0.7781  loss_cls: 0.4051  loss_box_reg: 0.2989  loss_rpn_cls: 0.02542  loss_rpn_loc: 0.02525    time: 0.4840  last_time: 0.4839  data_time: 0.0156  last_data_time: 0.0147   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:30:57 d2.utils.events]: \u001b[0m eta: 1:47:15  iter: 1679  total_loss: 0.8393  loss_cls: 0.459  loss_box_reg: 0.3103  loss_rpn_cls: 0.03112  loss_rpn_loc: 0.0149    time: 0.4841  last_time: 0.4903  data_time: 0.0159  last_data_time: 0.0215   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:31:08 d2.utils.events]: \u001b[0m eta: 1:47:05  iter: 1699  total_loss: 0.8146  loss_cls: 0.4284  loss_box_reg: 0.3083  loss_rpn_cls: 0.03576  loss_rpn_loc: 0.02674    time: 0.4841  last_time: 0.4839  data_time: 0.0174  last_data_time: 0.0144   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:31:19 d2.utils.events]: \u001b[0m eta: 1:46:56  iter: 1719  total_loss: 0.7129  loss_cls: 0.3848  loss_box_reg: 0.2506  loss_rpn_cls: 0.01659  loss_rpn_loc: 0.01677    time: 0.4841  last_time: 0.4891  data_time: 0.0158  last_data_time: 0.0206   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:31:30 d2.utils.events]: \u001b[0m eta: 1:46:48  iter: 1739  total_loss: 0.8427  loss_cls: 0.4262  loss_box_reg: 0.3301  loss_rpn_cls: 0.04456  loss_rpn_loc: 0.03954    time: 0.4841  last_time: 0.4865  data_time: 0.0151  last_data_time: 0.0181   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:31:41 d2.utils.events]: \u001b[0m eta: 1:46:38  iter: 1759  total_loss: 0.8165  loss_cls: 0.4395  loss_box_reg: 0.3001  loss_rpn_cls: 0.03086  loss_rpn_loc: 0.03204    time: 0.4841  last_time: 0.4846  data_time: 0.0156  last_data_time: 0.0175   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:31:52 d2.utils.events]: \u001b[0m eta: 1:46:28  iter: 1779  total_loss: 0.7465  loss_cls: 0.4066  loss_box_reg: 0.2939  loss_rpn_cls: 0.0218  loss_rpn_loc: 0.02657    time: 0.4841  last_time: 0.4859  data_time: 0.0150  last_data_time: 0.0176   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:32:03 d2.utils.events]: \u001b[0m eta: 1:46:18  iter: 1799  total_loss: 0.7859  loss_cls: 0.3977  loss_box_reg: 0.3279  loss_rpn_cls: 0.02572  loss_rpn_loc: 0.02924    time: 0.4841  last_time: 0.4872  data_time: 0.0154  last_data_time: 0.0197   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:32:14 d2.utils.events]: \u001b[0m eta: 1:46:08  iter: 1819  total_loss: 0.7891  loss_cls: 0.4636  loss_box_reg: 0.2934  loss_rpn_cls: 0.0215  loss_rpn_loc: 0.02439    time: 0.4841  last_time: 0.4808  data_time: 0.0156  last_data_time: 0.0145   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:32:25 d2.utils.events]: \u001b[0m eta: 1:45:59  iter: 1839  total_loss: 0.6172  loss_cls: 0.3747  loss_box_reg: 0.2129  loss_rpn_cls: 0.01588  loss_rpn_loc: 0.01418    time: 0.4841  last_time: 0.4819  data_time: 0.0157  last_data_time: 0.0150   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:32:36 d2.utils.events]: \u001b[0m eta: 1:45:50  iter: 1859  total_loss: 0.7891  loss_cls: 0.4266  loss_box_reg: 0.2742  loss_rpn_cls: 0.02071  loss_rpn_loc: 0.0429    time: 0.4841  last_time: 0.4826  data_time: 0.0154  last_data_time: 0.0142   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:32:47 d2.utils.events]: \u001b[0m eta: 1:45:41  iter: 1879  total_loss: 0.8901  loss_cls: 0.4851  loss_box_reg: 0.3005  loss_rpn_cls: 0.02363  loss_rpn_loc: 0.03541    time: 0.4841  last_time: 0.4785  data_time: 0.0157  last_data_time: 0.0156   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:32:58 d2.utils.events]: \u001b[0m eta: 1:45:31  iter: 1899  total_loss: 0.7582  loss_cls: 0.4533  loss_box_reg: 0.2872  loss_rpn_cls: 0.02187  loss_rpn_loc: 0.02307    time: 0.4841  last_time: 0.4807  data_time: 0.0174  last_data_time: 0.0146   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:33:09 d2.utils.events]: \u001b[0m eta: 1:45:22  iter: 1919  total_loss: 0.7897  loss_cls: 0.409  loss_box_reg: 0.3093  loss_rpn_cls: 0.02063  loss_rpn_loc: 0.02714    time: 0.4841  last_time: 0.4818  data_time: 0.0158  last_data_time: 0.0139   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:33:20 d2.utils.events]: \u001b[0m eta: 1:45:12  iter: 1939  total_loss: 0.7515  loss_cls: 0.3601  loss_box_reg: 0.2894  loss_rpn_cls: 0.01973  loss_rpn_loc: 0.02907    time: 0.4841  last_time: 0.4832  data_time: 0.0158  last_data_time: 0.0143   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:33:31 d2.utils.events]: \u001b[0m eta: 1:45:01  iter: 1959  total_loss: 0.6433  loss_cls: 0.3542  loss_box_reg: 0.2199  loss_rpn_cls: 0.01575  loss_rpn_loc: 0.01599    time: 0.4841  last_time: 0.4796  data_time: 0.0152  last_data_time: 0.0147   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:33:42 d2.utils.events]: \u001b[0m eta: 1:44:52  iter: 1979  total_loss: 0.7375  loss_cls: 0.4686  loss_box_reg: 0.3044  loss_rpn_cls: 0.02133  loss_rpn_loc: 0.02507    time: 0.4841  last_time: 0.4791  data_time: 0.0154  last_data_time: 0.0143   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:33:53 d2.utils.events]: \u001b[0m eta: 1:44:42  iter: 1999  total_loss: 0.8128  loss_cls: 0.4313  loss_box_reg: 0.2947  loss_rpn_cls: 0.02183  loss_rpn_loc: 0.03312    time: 0.4841  last_time: 0.4800  data_time: 0.0152  last_data_time: 0.0141   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:34:04 d2.utils.events]: \u001b[0m eta: 1:44:32  iter: 2019  total_loss: 0.7523  loss_cls: 0.4066  loss_box_reg: 0.2936  loss_rpn_cls: 0.02203  loss_rpn_loc: 0.02862    time: 0.4841  last_time: 0.4844  data_time: 0.0154  last_data_time: 0.0164   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:34:15 d2.utils.events]: \u001b[0m eta: 1:44:22  iter: 2039  total_loss: 0.7514  loss_cls: 0.417  loss_box_reg: 0.2741  loss_rpn_cls: 0.02099  loss_rpn_loc: 0.02545    time: 0.4841  last_time: 0.4818  data_time: 0.0159  last_data_time: 0.0149   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:34:26 d2.utils.events]: \u001b[0m eta: 1:44:13  iter: 2059  total_loss: 0.7873  loss_cls: 0.4084  loss_box_reg: 0.2764  loss_rpn_cls: 0.02005  loss_rpn_loc: 0.02313    time: 0.4841  last_time: 0.4825  data_time: 0.0172  last_data_time: 0.0139   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:34:37 d2.utils.events]: \u001b[0m eta: 1:44:05  iter: 2079  total_loss: 0.7504  loss_cls: 0.3956  loss_box_reg: 0.2692  loss_rpn_cls: 0.01526  loss_rpn_loc: 0.02585    time: 0.4841  last_time: 0.4845  data_time: 0.0171  last_data_time: 0.0176   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:34:48 d2.utils.events]: \u001b[0m eta: 1:43:56  iter: 2099  total_loss: 0.8251  loss_cls: 0.4463  loss_box_reg: 0.3144  loss_rpn_cls: 0.03008  loss_rpn_loc: 0.03258    time: 0.4841  last_time: 0.4806  data_time: 0.0156  last_data_time: 0.0143   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:34:59 d2.utils.events]: \u001b[0m eta: 1:43:45  iter: 2119  total_loss: 0.7752  loss_cls: 0.4096  loss_box_reg: 0.3056  loss_rpn_cls: 0.01523  loss_rpn_loc: 0.02409    time: 0.4841  last_time: 0.4886  data_time: 0.0164  last_data_time: 0.0203   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:35:10 d2.utils.events]: \u001b[0m eta: 1:43:36  iter: 2139  total_loss: 0.9216  loss_cls: 0.4891  loss_box_reg: 0.3039  loss_rpn_cls: 0.0276  loss_rpn_loc: 0.04165    time: 0.4841  last_time: 0.4841  data_time: 0.0160  last_data_time: 0.0154   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:35:21 d2.utils.events]: \u001b[0m eta: 1:43:25  iter: 2159  total_loss: 0.7422  loss_cls: 0.4067  loss_box_reg: 0.2835  loss_rpn_cls: 0.02126  loss_rpn_loc: 0.02205    time: 0.4841  last_time: 0.4871  data_time: 0.0156  last_data_time: 0.0161   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:35:32 d2.utils.events]: \u001b[0m eta: 1:43:16  iter: 2179  total_loss: 0.8149  loss_cls: 0.4326  loss_box_reg: 0.3092  loss_rpn_cls: 0.02716  loss_rpn_loc: 0.02414    time: 0.4841  last_time: 0.4870  data_time: 0.0158  last_data_time: 0.0142   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:35:43 d2.utils.events]: \u001b[0m eta: 1:43:07  iter: 2199  total_loss: 0.6408  loss_cls: 0.3812  loss_box_reg: 0.2217  loss_rpn_cls: 0.01812  loss_rpn_loc: 0.01199    time: 0.4841  last_time: 0.4812  data_time: 0.0166  last_data_time: 0.0161   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:35:54 d2.utils.events]: \u001b[0m eta: 1:42:57  iter: 2219  total_loss: 0.79  loss_cls: 0.4784  loss_box_reg: 0.2572  loss_rpn_cls: 0.03382  loss_rpn_loc: 0.02704    time: 0.4841  last_time: 0.4827  data_time: 0.0174  last_data_time: 0.0145   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:36:05 d2.utils.events]: \u001b[0m eta: 1:42:47  iter: 2239  total_loss: 0.6443  loss_cls: 0.3727  loss_box_reg: 0.2516  loss_rpn_cls: 0.01733  loss_rpn_loc: 0.02301    time: 0.4841  last_time: 0.4776  data_time: 0.0152  last_data_time: 0.0144   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:36:15 d2.utils.events]: \u001b[0m eta: 1:42:38  iter: 2259  total_loss: 0.7842  loss_cls: 0.4375  loss_box_reg: 0.2756  loss_rpn_cls: 0.0226  loss_rpn_loc: 0.02615    time: 0.4841  last_time: 0.4855  data_time: 0.0152  last_data_time: 0.0161   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:36:26 d2.utils.events]: \u001b[0m eta: 1:42:28  iter: 2279  total_loss: 0.7651  loss_cls: 0.4185  loss_box_reg: 0.3105  loss_rpn_cls: 0.01805  loss_rpn_loc: 0.01816    time: 0.4841  last_time: 0.4833  data_time: 0.0171  last_data_time: 0.0165   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:36:37 d2.utils.events]: \u001b[0m eta: 1:42:19  iter: 2299  total_loss: 0.8005  loss_cls: 0.4068  loss_box_reg: 0.2969  loss_rpn_cls: 0.02095  loss_rpn_loc: 0.02555    time: 0.4841  last_time: 0.4808  data_time: 0.0166  last_data_time: 0.0159   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:36:48 d2.utils.events]: \u001b[0m eta: 1:42:09  iter: 2319  total_loss: 0.7918  loss_cls: 0.3884  loss_box_reg: 0.3011  loss_rpn_cls: 0.01586  loss_rpn_loc: 0.02222    time: 0.4841  last_time: 0.4840  data_time: 0.0154  last_data_time: 0.0167   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:36:59 d2.utils.events]: \u001b[0m eta: 1:42:00  iter: 2339  total_loss: 0.8333  loss_cls: 0.4689  loss_box_reg: 0.3044  loss_rpn_cls: 0.02417  loss_rpn_loc: 0.03227    time: 0.4841  last_time: 0.4844  data_time: 0.0158  last_data_time: 0.0182   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:37:10 d2.utils.events]: \u001b[0m eta: 1:41:51  iter: 2359  total_loss: 0.8881  loss_cls: 0.4712  loss_box_reg: 0.3353  loss_rpn_cls: 0.03276  loss_rpn_loc: 0.02975    time: 0.4841  last_time: 0.4817  data_time: 0.0164  last_data_time: 0.0145   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:37:21 d2.utils.events]: \u001b[0m eta: 1:41:42  iter: 2379  total_loss: 0.8484  loss_cls: 0.4381  loss_box_reg: 0.3332  loss_rpn_cls: 0.02109  loss_rpn_loc: 0.02878    time: 0.4841  last_time: 0.4825  data_time: 0.0160  last_data_time: 0.0143   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:37:32 d2.utils.events]: \u001b[0m eta: 1:41:32  iter: 2399  total_loss: 0.793  loss_cls: 0.4126  loss_box_reg: 0.3367  loss_rpn_cls: 0.02422  loss_rpn_loc: 0.02368    time: 0.4841  last_time: 0.4824  data_time: 0.0156  last_data_time: 0.0150   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:37:43 d2.utils.events]: \u001b[0m eta: 1:41:23  iter: 2419  total_loss: 0.8365  loss_cls: 0.4565  loss_box_reg: 0.3138  loss_rpn_cls: 0.01908  loss_rpn_loc: 0.01815    time: 0.4841  last_time: 0.4877  data_time: 0.0170  last_data_time: 0.0150   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:37:54 d2.utils.events]: \u001b[0m eta: 1:41:13  iter: 2439  total_loss: 0.7133  loss_cls: 0.4359  loss_box_reg: 0.285  loss_rpn_cls: 0.01868  loss_rpn_loc: 0.01678    time: 0.4841  last_time: 0.4858  data_time: 0.0159  last_data_time: 0.0187   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:38:05 d2.utils.events]: \u001b[0m eta: 1:41:02  iter: 2459  total_loss: 0.746  loss_cls: 0.4072  loss_box_reg: 0.2557  loss_rpn_cls: 0.02221  loss_rpn_loc: 0.02143    time: 0.4841  last_time: 0.4810  data_time: 0.0161  last_data_time: 0.0175   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:38:16 d2.utils.events]: \u001b[0m eta: 1:40:53  iter: 2479  total_loss: 0.7384  loss_cls: 0.4152  loss_box_reg: 0.2801  loss_rpn_cls: 0.02078  loss_rpn_loc: 0.04339    time: 0.4841  last_time: 0.4818  data_time: 0.0162  last_data_time: 0.0146   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:38:27 d2.utils.events]: \u001b[0m eta: 1:40:43  iter: 2499  total_loss: 0.807  loss_cls: 0.4126  loss_box_reg: 0.2918  loss_rpn_cls: 0.01991  loss_rpn_loc: 0.02094    time: 0.4841  last_time: 0.4840  data_time: 0.0151  last_data_time: 0.0153   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:38:38 d2.utils.events]: \u001b[0m eta: 1:40:33  iter: 2519  total_loss: 0.7554  loss_cls: 0.4019  loss_box_reg: 0.3051  loss_rpn_cls: 0.02282  loss_rpn_loc: 0.03438    time: 0.4841  last_time: 0.4844  data_time: 0.0157  last_data_time: 0.0163   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:38:49 d2.utils.events]: \u001b[0m eta: 1:40:24  iter: 2539  total_loss: 0.7038  loss_cls: 0.3847  loss_box_reg: 0.2585  loss_rpn_cls: 0.01815  loss_rpn_loc: 0.01706    time: 0.4841  last_time: 0.4863  data_time: 0.0158  last_data_time: 0.0179   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:39:00 d2.utils.events]: \u001b[0m eta: 1:40:14  iter: 2559  total_loss: 0.8745  loss_cls: 0.4781  loss_box_reg: 0.3272  loss_rpn_cls: 0.02166  loss_rpn_loc: 0.03163    time: 0.4841  last_time: 0.4881  data_time: 0.0165  last_data_time: 0.0193   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:39:11 d2.utils.events]: \u001b[0m eta: 1:40:05  iter: 2579  total_loss: 0.6817  loss_cls: 0.3647  loss_box_reg: 0.3033  loss_rpn_cls: 0.02219  loss_rpn_loc: 0.028    time: 0.4841  last_time: 0.4848  data_time: 0.0152  last_data_time: 0.0158   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:39:22 d2.utils.events]: \u001b[0m eta: 1:39:55  iter: 2599  total_loss: 0.6833  loss_cls: 0.3703  loss_box_reg: 0.2582  loss_rpn_cls: 0.01545  loss_rpn_loc: 0.02795    time: 0.4841  last_time: 0.4796  data_time: 0.0155  last_data_time: 0.0143   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:39:33 d2.utils.events]: \u001b[0m eta: 1:39:45  iter: 2619  total_loss: 0.728  loss_cls: 0.3844  loss_box_reg: 0.2754  loss_rpn_cls: 0.01404  loss_rpn_loc: 0.01736    time: 0.4841  last_time: 0.4862  data_time: 0.0149  last_data_time: 0.0179   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:39:44 d2.utils.events]: \u001b[0m eta: 1:39:35  iter: 2639  total_loss: 0.7079  loss_cls: 0.3667  loss_box_reg: 0.2497  loss_rpn_cls: 0.02423  loss_rpn_loc: 0.02933    time: 0.4841  last_time: 0.4824  data_time: 0.0157  last_data_time: 0.0144   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:39:55 d2.utils.events]: \u001b[0m eta: 1:39:24  iter: 2659  total_loss: 0.7556  loss_cls: 0.4081  loss_box_reg: 0.2448  loss_rpn_cls: 0.01847  loss_rpn_loc: 0.02481    time: 0.4841  last_time: 0.4818  data_time: 0.0151  last_data_time: 0.0143   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:40:06 d2.utils.events]: \u001b[0m eta: 1:39:14  iter: 2679  total_loss: 0.8119  loss_cls: 0.3912  loss_box_reg: 0.2953  loss_rpn_cls: 0.01752  loss_rpn_loc: 0.02392    time: 0.4841  last_time: 0.4846  data_time: 0.0183  last_data_time: 0.0172   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:40:17 d2.utils.events]: \u001b[0m eta: 1:39:04  iter: 2699  total_loss: 0.8216  loss_cls: 0.4275  loss_box_reg: 0.2641  loss_rpn_cls: 0.01659  loss_rpn_loc: 0.02246    time: 0.4841  last_time: 0.4814  data_time: 0.0164  last_data_time: 0.0143   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:40:28 d2.utils.events]: \u001b[0m eta: 1:38:54  iter: 2719  total_loss: 0.7519  loss_cls: 0.3848  loss_box_reg: 0.2877  loss_rpn_cls: 0.01448  loss_rpn_loc: 0.01424    time: 0.4841  last_time: 0.4816  data_time: 0.0147  last_data_time: 0.0143   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:40:38 d2.utils.events]: \u001b[0m eta: 1:38:43  iter: 2739  total_loss: 0.7748  loss_cls: 0.4259  loss_box_reg: 0.2839  loss_rpn_cls: 0.02181  loss_rpn_loc: 0.02349    time: 0.4840  last_time: 0.4789  data_time: 0.0145  last_data_time: 0.0145   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:40:49 d2.utils.events]: \u001b[0m eta: 1:38:33  iter: 2759  total_loss: 0.6719  loss_cls: 0.3802  loss_box_reg: 0.2376  loss_rpn_cls: 0.02038  loss_rpn_loc: 0.02005    time: 0.4840  last_time: 0.4818  data_time: 0.0166  last_data_time: 0.0144   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:41:00 d2.utils.events]: \u001b[0m eta: 1:38:24  iter: 2779  total_loss: 0.7662  loss_cls: 0.4115  loss_box_reg: 0.2553  loss_rpn_cls: 0.01964  loss_rpn_loc: 0.03388    time: 0.4840  last_time: 0.4816  data_time: 0.0152  last_data_time: 0.0143   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:41:11 d2.utils.events]: \u001b[0m eta: 1:38:14  iter: 2799  total_loss: 0.6694  loss_cls: 0.4035  loss_box_reg: 0.2715  loss_rpn_cls: 0.01701  loss_rpn_loc: 0.02085    time: 0.4841  last_time: 0.4884  data_time: 0.0191  last_data_time: 0.0209   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:41:22 d2.utils.events]: \u001b[0m eta: 1:38:05  iter: 2819  total_loss: 0.6779  loss_cls: 0.3919  loss_box_reg: 0.2518  loss_rpn_cls: 0.01463  loss_rpn_loc: 0.01738    time: 0.4840  last_time: 0.4821  data_time: 0.0161  last_data_time: 0.0146   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:41:33 d2.utils.events]: \u001b[0m eta: 1:37:55  iter: 2839  total_loss: 0.7657  loss_cls: 0.4218  loss_box_reg: 0.2826  loss_rpn_cls: 0.01866  loss_rpn_loc: 0.03576    time: 0.4840  last_time: 0.4831  data_time: 0.0160  last_data_time: 0.0144   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:41:44 d2.utils.events]: \u001b[0m eta: 1:37:45  iter: 2859  total_loss: 0.8025  loss_cls: 0.396  loss_box_reg: 0.331  loss_rpn_cls: 0.02117  loss_rpn_loc: 0.03631    time: 0.4840  last_time: 0.4832  data_time: 0.0157  last_data_time: 0.0161   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:41:55 d2.utils.events]: \u001b[0m eta: 1:37:36  iter: 2879  total_loss: 0.6268  loss_cls: 0.3509  loss_box_reg: 0.2536  loss_rpn_cls: 0.01473  loss_rpn_loc: 0.01887    time: 0.4841  last_time: 0.4822  data_time: 0.0164  last_data_time: 0.0142   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:42:06 d2.utils.events]: \u001b[0m eta: 1:37:25  iter: 2899  total_loss: 0.5332  loss_cls: 0.3108  loss_box_reg: 0.1974  loss_rpn_cls: 0.009747  loss_rpn_loc: 0.01209    time: 0.4840  last_time: 0.4803  data_time: 0.0159  last_data_time: 0.0143   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:42:17 d2.utils.events]: \u001b[0m eta: 1:37:16  iter: 2919  total_loss: 0.7415  loss_cls: 0.4113  loss_box_reg: 0.2766  loss_rpn_cls: 0.01801  loss_rpn_loc: 0.03625    time: 0.4841  last_time: 0.4812  data_time: 0.0161  last_data_time: 0.0142   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:42:28 d2.utils.events]: \u001b[0m eta: 1:37:06  iter: 2939  total_loss: 0.7177  loss_cls: 0.391  loss_box_reg: 0.2254  loss_rpn_cls: 0.01843  loss_rpn_loc: 0.02268    time: 0.4840  last_time: 0.4846  data_time: 0.0155  last_data_time: 0.0169   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:42:39 d2.utils.events]: \u001b[0m eta: 1:36:57  iter: 2959  total_loss: 0.7167  loss_cls: 0.3875  loss_box_reg: 0.2645  loss_rpn_cls: 0.02078  loss_rpn_loc: 0.02387    time: 0.4840  last_time: 0.4829  data_time: 0.0162  last_data_time: 0.0145   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:42:50 d2.utils.events]: \u001b[0m eta: 1:36:47  iter: 2979  total_loss: 0.6102  loss_cls: 0.3471  loss_box_reg: 0.2335  loss_rpn_cls: 0.02065  loss_rpn_loc: 0.0292    time: 0.4840  last_time: 0.4846  data_time: 0.0150  last_data_time: 0.0148   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:43:04 d2.data.datasets.coco]: \u001b[0mLoaded 4871 images in COCO format from /data/ephemeral/home/workspace/dataset/test.json\n",
      "\u001b[32m[10/10 01:43:04 d2.data.build]: \u001b[0mDistribution of instances among all 10 categories:\n",
      "\u001b[36m|   category    | #instances   |  category   | #instances   |  category  | #instances   |\n",
      "|:-------------:|:-------------|:-----------:|:-------------|:----------:|:-------------|\n",
      "| General trash | 0            |    Paper    | 0            | Paper pack | 0            |\n",
      "|     Metal     | 0            |    Glass    | 0            |  Plastic   | 0            |\n",
      "|   Styrofoam   | 0            | Plastic bag | 0            |  Battery   | 0            |\n",
      "|   Clothing    | 0            |             |              |            |              |\n",
      "|     total     | 0            |             |              |            |              |\u001b[0m\n",
      "\u001b[32m[10/10 01:43:04 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/10 01:43:04 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[10/10 01:43:04 d2.data.common]: \u001b[0mSerializing 4871 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/10 01:43:04 d2.data.common]: \u001b[0mSerialized dataset takes 0.63 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/10 01:43:04 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[10/10 01:43:04 d2.evaluation.evaluator]: \u001b[0mStart inference on 4871 batches\n",
      "\u001b[32m[10/10 01:43:05 d2.evaluation.evaluator]: \u001b[0mInference done 11/4871. Dataloading: 0.0010 s/iter. Inference: 0.0460 s/iter. Eval: 0.0002 s/iter. Total: 0.0472 s/iter. ETA=0:03:49\n",
      "\u001b[32m[10/10 01:43:10 d2.evaluation.evaluator]: \u001b[0mInference done 117/4871. Dataloading: 0.0013 s/iter. Inference: 0.0456 s/iter. Eval: 0.0003 s/iter. Total: 0.0472 s/iter. ETA=0:03:44\n",
      "\u001b[32m[10/10 01:43:15 d2.evaluation.evaluator]: \u001b[0mInference done 221/4871. Dataloading: 0.0014 s/iter. Inference: 0.0460 s/iter. Eval: 0.0003 s/iter. Total: 0.0477 s/iter. ETA=0:03:41\n",
      "\u001b[32m[10/10 01:43:20 d2.evaluation.evaluator]: \u001b[0mInference done 323/4871. Dataloading: 0.0014 s/iter. Inference: 0.0464 s/iter. Eval: 0.0003 s/iter. Total: 0.0482 s/iter. ETA=0:03:39\n",
      "\u001b[32m[10/10 01:43:25 d2.evaluation.evaluator]: \u001b[0mInference done 429/4871. Dataloading: 0.0014 s/iter. Inference: 0.0462 s/iter. Eval: 0.0003 s/iter. Total: 0.0480 s/iter. ETA=0:03:33\n",
      "\u001b[32m[10/10 01:43:30 d2.evaluation.evaluator]: \u001b[0mInference done 534/4871. Dataloading: 0.0014 s/iter. Inference: 0.0462 s/iter. Eval: 0.0003 s/iter. Total: 0.0479 s/iter. ETA=0:03:27\n",
      "\u001b[32m[10/10 01:43:35 d2.evaluation.evaluator]: \u001b[0mInference done 637/4871. Dataloading: 0.0014 s/iter. Inference: 0.0463 s/iter. Eval: 0.0003 s/iter. Total: 0.0481 s/iter. ETA=0:03:23\n",
      "\u001b[32m[10/10 01:43:40 d2.evaluation.evaluator]: \u001b[0mInference done 740/4871. Dataloading: 0.0014 s/iter. Inference: 0.0464 s/iter. Eval: 0.0003 s/iter. Total: 0.0482 s/iter. ETA=0:03:18\n",
      "\u001b[32m[10/10 01:43:45 d2.evaluation.evaluator]: \u001b[0mInference done 849/4871. Dataloading: 0.0014 s/iter. Inference: 0.0461 s/iter. Eval: 0.0003 s/iter. Total: 0.0479 s/iter. ETA=0:03:12\n",
      "\u001b[32m[10/10 01:43:50 d2.evaluation.evaluator]: \u001b[0mInference done 954/4871. Dataloading: 0.0014 s/iter. Inference: 0.0461 s/iter. Eval: 0.0003 s/iter. Total: 0.0479 s/iter. ETA=0:03:07\n",
      "\u001b[32m[10/10 01:43:55 d2.evaluation.evaluator]: \u001b[0mInference done 1058/4871. Dataloading: 0.0014 s/iter. Inference: 0.0462 s/iter. Eval: 0.0003 s/iter. Total: 0.0479 s/iter. ETA=0:03:02\n",
      "\u001b[32m[10/10 01:44:00 d2.evaluation.evaluator]: \u001b[0mInference done 1163/4871. Dataloading: 0.0014 s/iter. Inference: 0.0462 s/iter. Eval: 0.0003 s/iter. Total: 0.0479 s/iter. ETA=0:02:57\n",
      "\u001b[32m[10/10 01:44:05 d2.evaluation.evaluator]: \u001b[0mInference done 1269/4871. Dataloading: 0.0014 s/iter. Inference: 0.0461 s/iter. Eval: 0.0003 s/iter. Total: 0.0479 s/iter. ETA=0:02:52\n",
      "\u001b[32m[10/10 01:44:10 d2.evaluation.evaluator]: \u001b[0mInference done 1374/4871. Dataloading: 0.0014 s/iter. Inference: 0.0461 s/iter. Eval: 0.0003 s/iter. Total: 0.0479 s/iter. ETA=0:02:47\n",
      "\u001b[32m[10/10 01:44:15 d2.evaluation.evaluator]: \u001b[0mInference done 1477/4871. Dataloading: 0.0014 s/iter. Inference: 0.0462 s/iter. Eval: 0.0003 s/iter. Total: 0.0480 s/iter. ETA=0:02:42\n",
      "\u001b[32m[10/10 01:44:20 d2.evaluation.evaluator]: \u001b[0mInference done 1583/4871. Dataloading: 0.0014 s/iter. Inference: 0.0462 s/iter. Eval: 0.0003 s/iter. Total: 0.0479 s/iter. ETA=0:02:37\n",
      "\u001b[32m[10/10 01:44:25 d2.evaluation.evaluator]: \u001b[0mInference done 1687/4871. Dataloading: 0.0014 s/iter. Inference: 0.0462 s/iter. Eval: 0.0003 s/iter. Total: 0.0480 s/iter. ETA=0:02:32\n",
      "\u001b[32m[10/10 01:44:30 d2.evaluation.evaluator]: \u001b[0mInference done 1791/4871. Dataloading: 0.0014 s/iter. Inference: 0.0462 s/iter. Eval: 0.0003 s/iter. Total: 0.0480 s/iter. ETA=0:02:27\n",
      "\u001b[32m[10/10 01:44:35 d2.evaluation.evaluator]: \u001b[0mInference done 1892/4871. Dataloading: 0.0015 s/iter. Inference: 0.0463 s/iter. Eval: 0.0003 s/iter. Total: 0.0480 s/iter. ETA=0:02:23\n",
      "\u001b[32m[10/10 01:44:40 d2.evaluation.evaluator]: \u001b[0mInference done 1997/4871. Dataloading: 0.0015 s/iter. Inference: 0.0463 s/iter. Eval: 0.0003 s/iter. Total: 0.0480 s/iter. ETA=0:02:18\n",
      "\u001b[32m[10/10 01:44:45 d2.evaluation.evaluator]: \u001b[0mInference done 2102/4871. Dataloading: 0.0015 s/iter. Inference: 0.0462 s/iter. Eval: 0.0003 s/iter. Total: 0.0480 s/iter. ETA=0:02:12\n",
      "\u001b[32m[10/10 01:44:51 d2.evaluation.evaluator]: \u001b[0mInference done 2208/4871. Dataloading: 0.0015 s/iter. Inference: 0.0462 s/iter. Eval: 0.0003 s/iter. Total: 0.0480 s/iter. ETA=0:02:07\n",
      "\u001b[32m[10/10 01:44:56 d2.evaluation.evaluator]: \u001b[0mInference done 2314/4871. Dataloading: 0.0015 s/iter. Inference: 0.0462 s/iter. Eval: 0.0003 s/iter. Total: 0.0480 s/iter. ETA=0:02:02\n",
      "\u001b[32m[10/10 01:45:01 d2.evaluation.evaluator]: \u001b[0mInference done 2418/4871. Dataloading: 0.0015 s/iter. Inference: 0.0462 s/iter. Eval: 0.0003 s/iter. Total: 0.0480 s/iter. ETA=0:01:57\n",
      "\u001b[32m[10/10 01:45:06 d2.evaluation.evaluator]: \u001b[0mInference done 2522/4871. Dataloading: 0.0015 s/iter. Inference: 0.0462 s/iter. Eval: 0.0003 s/iter. Total: 0.0480 s/iter. ETA=0:01:52\n",
      "\u001b[32m[10/10 01:45:11 d2.evaluation.evaluator]: \u001b[0mInference done 2627/4871. Dataloading: 0.0015 s/iter. Inference: 0.0462 s/iter. Eval: 0.0003 s/iter. Total: 0.0480 s/iter. ETA=0:01:47\n",
      "\u001b[32m[10/10 01:45:16 d2.evaluation.evaluator]: \u001b[0mInference done 2732/4871. Dataloading: 0.0015 s/iter. Inference: 0.0462 s/iter. Eval: 0.0003 s/iter. Total: 0.0480 s/iter. ETA=0:01:42\n",
      "\u001b[32m[10/10 01:45:21 d2.evaluation.evaluator]: \u001b[0mInference done 2836/4871. Dataloading: 0.0015 s/iter. Inference: 0.0462 s/iter. Eval: 0.0003 s/iter. Total: 0.0480 s/iter. ETA=0:01:37\n",
      "\u001b[32m[10/10 01:45:26 d2.evaluation.evaluator]: \u001b[0mInference done 2940/4871. Dataloading: 0.0015 s/iter. Inference: 0.0462 s/iter. Eval: 0.0003 s/iter. Total: 0.0480 s/iter. ETA=0:01:32\n",
      "\u001b[32m[10/10 01:45:31 d2.evaluation.evaluator]: \u001b[0mInference done 3044/4871. Dataloading: 0.0015 s/iter. Inference: 0.0462 s/iter. Eval: 0.0003 s/iter. Total: 0.0480 s/iter. ETA=0:01:27\n",
      "\u001b[32m[10/10 01:45:36 d2.evaluation.evaluator]: \u001b[0mInference done 3149/4871. Dataloading: 0.0015 s/iter. Inference: 0.0462 s/iter. Eval: 0.0003 s/iter. Total: 0.0480 s/iter. ETA=0:01:22\n",
      "\u001b[32m[10/10 01:45:41 d2.evaluation.evaluator]: \u001b[0mInference done 3253/4871. Dataloading: 0.0015 s/iter. Inference: 0.0462 s/iter. Eval: 0.0003 s/iter. Total: 0.0480 s/iter. ETA=0:01:17\n",
      "\u001b[32m[10/10 01:45:46 d2.evaluation.evaluator]: \u001b[0mInference done 3356/4871. Dataloading: 0.0015 s/iter. Inference: 0.0462 s/iter. Eval: 0.0003 s/iter. Total: 0.0480 s/iter. ETA=0:01:12\n",
      "\u001b[32m[10/10 01:45:51 d2.evaluation.evaluator]: \u001b[0mInference done 3460/4871. Dataloading: 0.0015 s/iter. Inference: 0.0462 s/iter. Eval: 0.0003 s/iter. Total: 0.0480 s/iter. ETA=0:01:07\n",
      "\u001b[32m[10/10 01:45:56 d2.evaluation.evaluator]: \u001b[0mInference done 3564/4871. Dataloading: 0.0015 s/iter. Inference: 0.0462 s/iter. Eval: 0.0003 s/iter. Total: 0.0480 s/iter. ETA=0:01:02\n",
      "\u001b[32m[10/10 01:46:01 d2.evaluation.evaluator]: \u001b[0mInference done 3666/4871. Dataloading: 0.0015 s/iter. Inference: 0.0463 s/iter. Eval: 0.0003 s/iter. Total: 0.0481 s/iter. ETA=0:00:57\n",
      "\u001b[32m[10/10 01:46:06 d2.evaluation.evaluator]: \u001b[0mInference done 3771/4871. Dataloading: 0.0015 s/iter. Inference: 0.0463 s/iter. Eval: 0.0003 s/iter. Total: 0.0481 s/iter. ETA=0:00:52\n",
      "\u001b[32m[10/10 01:46:11 d2.evaluation.evaluator]: \u001b[0mInference done 3872/4871. Dataloading: 0.0015 s/iter. Inference: 0.0463 s/iter. Eval: 0.0003 s/iter. Total: 0.0481 s/iter. ETA=0:00:48\n",
      "\u001b[32m[10/10 01:46:16 d2.evaluation.evaluator]: \u001b[0mInference done 3978/4871. Dataloading: 0.0015 s/iter. Inference: 0.0463 s/iter. Eval: 0.0003 s/iter. Total: 0.0481 s/iter. ETA=0:00:42\n",
      "\u001b[32m[10/10 01:46:21 d2.evaluation.evaluator]: \u001b[0mInference done 4082/4871. Dataloading: 0.0015 s/iter. Inference: 0.0463 s/iter. Eval: 0.0003 s/iter. Total: 0.0481 s/iter. ETA=0:00:37\n",
      "\u001b[32m[10/10 01:46:26 d2.evaluation.evaluator]: \u001b[0mInference done 4185/4871. Dataloading: 0.0015 s/iter. Inference: 0.0463 s/iter. Eval: 0.0003 s/iter. Total: 0.0481 s/iter. ETA=0:00:32\n",
      "\u001b[32m[10/10 01:46:31 d2.evaluation.evaluator]: \u001b[0mInference done 4288/4871. Dataloading: 0.0015 s/iter. Inference: 0.0463 s/iter. Eval: 0.0003 s/iter. Total: 0.0481 s/iter. ETA=0:00:28\n",
      "\u001b[32m[10/10 01:46:36 d2.evaluation.evaluator]: \u001b[0mInference done 4391/4871. Dataloading: 0.0015 s/iter. Inference: 0.0463 s/iter. Eval: 0.0003 s/iter. Total: 0.0481 s/iter. ETA=0:00:23\n",
      "\u001b[32m[10/10 01:46:41 d2.evaluation.evaluator]: \u001b[0mInference done 4496/4871. Dataloading: 0.0015 s/iter. Inference: 0.0463 s/iter. Eval: 0.0003 s/iter. Total: 0.0481 s/iter. ETA=0:00:18\n",
      "\u001b[32m[10/10 01:46:46 d2.evaluation.evaluator]: \u001b[0mInference done 4601/4871. Dataloading: 0.0015 s/iter. Inference: 0.0463 s/iter. Eval: 0.0003 s/iter. Total: 0.0481 s/iter. ETA=0:00:12\n",
      "\u001b[32m[10/10 01:46:51 d2.evaluation.evaluator]: \u001b[0mInference done 4704/4871. Dataloading: 0.0015 s/iter. Inference: 0.0463 s/iter. Eval: 0.0003 s/iter. Total: 0.0481 s/iter. ETA=0:00:08\n",
      "\u001b[32m[10/10 01:46:56 d2.evaluation.evaluator]: \u001b[0mInference done 4807/4871. Dataloading: 0.0015 s/iter. Inference: 0.0463 s/iter. Eval: 0.0003 s/iter. Total: 0.0481 s/iter. ETA=0:00:03\n",
      "\u001b[32m[10/10 01:46:59 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:03:54.327018 (0.048156 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/10 01:46:59 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:03:45 (0.046346 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/10 01:47:00 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/10 01:47:00 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output_eval/coco_instances_results.json\n",
      "\u001b[32m[10/10 01:47:01 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.68s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/10 01:47:02 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/10 01:47:04 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 2.02 seconds.\n",
      "\u001b[32m[10/10 01:47:04 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/10 01:47:04 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.28 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "\u001b[32m[10/10 01:47:04 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP  |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| nan  |  nan   |  nan   |  nan  |  nan  |  nan  |\n",
      "\u001b[32m[10/10 01:47:04 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[10/10 01:47:04 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category      | AP   | category    | AP   | category   | AP   |\n",
      "|:--------------|:-----|:------------|:-----|:-----------|:-----|\n",
      "| General trash | nan  | Paper       | nan  | Paper pack | nan  |\n",
      "| Metal         | nan  | Glass       | nan  | Plastic    | nan  |\n",
      "| Styrofoam     | nan  | Plastic bag | nan  | Battery    | nan  |\n",
      "| Clothing      | nan  |             |      |            |      |\n",
      "\u001b[32m[10/10 01:47:04 d2.engine.defaults]: \u001b[0mEvaluation results for coco_trash_test in csv format:\n",
      "\u001b[32m[10/10 01:47:04 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[10/10 01:47:04 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[10/10 01:47:04 d2.evaluation.testing]: \u001b[0mcopypaste: nan,nan,nan,nan,nan,nan\n",
      "\u001b[32m[10/10 01:47:04 d2.utils.events]: \u001b[0m eta: 1:36:38  iter: 2999  total_loss: 0.6488  loss_cls: 0.3341  loss_box_reg: 0.2333  loss_rpn_cls: 0.01951  loss_rpn_loc: 0.01573    time: 0.4840  last_time: 0.4819  data_time: 0.0168  last_data_time: 0.0159   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:47:16 d2.utils.events]: \u001b[0m eta: 1:36:28  iter: 3019  total_loss: 0.7262  loss_cls: 0.4259  loss_box_reg: 0.2515  loss_rpn_cls: 0.02547  loss_rpn_loc: 0.03489    time: 0.4840  last_time: 0.4846  data_time: 0.0159  last_data_time: 0.0153   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:47:28 d2.utils.events]: \u001b[0m eta: 1:36:19  iter: 3039  total_loss: 0.8069  loss_cls: 0.4053  loss_box_reg: 0.2825  loss_rpn_cls: 0.01387  loss_rpn_loc: 0.03414    time: 0.4841  last_time: 0.4888  data_time: 0.0178  last_data_time: 0.0213   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:47:40 d2.utils.events]: \u001b[0m eta: 1:36:09  iter: 3059  total_loss: 0.6981  loss_cls: 0.3686  loss_box_reg: 0.2673  loss_rpn_cls: 0.009446  loss_rpn_loc: 0.01442    time: 0.4841  last_time: 0.4853  data_time: 0.0161  last_data_time: 0.0180   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:47:53 d2.utils.events]: \u001b[0m eta: 1:35:59  iter: 3079  total_loss: 0.7551  loss_cls: 0.3964  loss_box_reg: 0.2876  loss_rpn_cls: 0.02001  loss_rpn_loc: 0.02706    time: 0.4841  last_time: 0.4816  data_time: 0.0165  last_data_time: 0.0147   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:48:05 d2.utils.events]: \u001b[0m eta: 1:35:49  iter: 3099  total_loss: 0.7662  loss_cls: 0.4525  loss_box_reg: 0.2854  loss_rpn_cls: 0.02391  loss_rpn_loc: 0.02784    time: 0.4840  last_time: 0.4889  data_time: 0.0155  last_data_time: 0.0166   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:48:17 d2.utils.events]: \u001b[0m eta: 1:35:40  iter: 3119  total_loss: 0.676  loss_cls: 0.3799  loss_box_reg: 0.2431  loss_rpn_cls: 0.02118  loss_rpn_loc: 0.03293    time: 0.4841  last_time: 0.4837  data_time: 0.0166  last_data_time: 0.0145   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:48:29 d2.utils.events]: \u001b[0m eta: 1:35:30  iter: 3139  total_loss: 0.8004  loss_cls: 0.4573  loss_box_reg: 0.331  loss_rpn_cls: 0.0235  loss_rpn_loc: 0.02077    time: 0.4840  last_time: 0.4849  data_time: 0.0165  last_data_time: 0.0155   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:48:41 d2.utils.events]: \u001b[0m eta: 1:35:21  iter: 3159  total_loss: 0.7039  loss_cls: 0.4169  loss_box_reg: 0.2687  loss_rpn_cls: 0.0187  loss_rpn_loc: 0.0187    time: 0.4840  last_time: 0.4820  data_time: 0.0161  last_data_time: 0.0146   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:48:53 d2.utils.events]: \u001b[0m eta: 1:35:11  iter: 3179  total_loss: 0.7778  loss_cls: 0.4251  loss_box_reg: 0.2819  loss_rpn_cls: 0.02997  loss_rpn_loc: 0.05123    time: 0.4840  last_time: 0.4820  data_time: 0.0159  last_data_time: 0.0159   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:49:05 d2.utils.events]: \u001b[0m eta: 1:35:01  iter: 3199  total_loss: 0.5877  loss_cls: 0.3499  loss_box_reg: 0.2126  loss_rpn_cls: 0.02097  loss_rpn_loc: 0.01362    time: 0.4840  last_time: 0.4875  data_time: 0.0160  last_data_time: 0.0194   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:49:17 d2.utils.events]: \u001b[0m eta: 1:34:51  iter: 3219  total_loss: 0.6874  loss_cls: 0.3839  loss_box_reg: 0.2431  loss_rpn_cls: 0.02122  loss_rpn_loc: 0.0309    time: 0.4840  last_time: 0.4807  data_time: 0.0155  last_data_time: 0.0151   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:49:29 d2.utils.events]: \u001b[0m eta: 1:34:41  iter: 3239  total_loss: 0.6715  loss_cls: 0.3966  loss_box_reg: 0.2594  loss_rpn_cls: 0.02159  loss_rpn_loc: 0.02842    time: 0.4840  last_time: 0.4786  data_time: 0.0161  last_data_time: 0.0152   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:49:41 d2.utils.events]: \u001b[0m eta: 1:34:32  iter: 3259  total_loss: 0.7704  loss_cls: 0.4023  loss_box_reg: 0.2743  loss_rpn_cls: 0.02592  loss_rpn_loc: 0.03879    time: 0.4840  last_time: 0.4810  data_time: 0.0164  last_data_time: 0.0159   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:49:53 d2.utils.events]: \u001b[0m eta: 1:34:21  iter: 3279  total_loss: 0.7443  loss_cls: 0.3904  loss_box_reg: 0.2627  loss_rpn_cls: 0.01923  loss_rpn_loc: 0.0169    time: 0.4840  last_time: 0.4798  data_time: 0.0153  last_data_time: 0.0144   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:50:05 d2.utils.events]: \u001b[0m eta: 1:34:11  iter: 3299  total_loss: 0.788  loss_cls: 0.4092  loss_box_reg: 0.2727  loss_rpn_cls: 0.01441  loss_rpn_loc: 0.01803    time: 0.4840  last_time: 0.4905  data_time: 0.0161  last_data_time: 0.0233   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:50:17 d2.utils.events]: \u001b[0m eta: 1:34:02  iter: 3319  total_loss: 0.721  loss_cls: 0.4034  loss_box_reg: 0.2722  loss_rpn_cls: 0.02071  loss_rpn_loc: 0.02397    time: 0.4840  last_time: 0.4864  data_time: 0.0161  last_data_time: 0.0152   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:50:30 d2.utils.events]: \u001b[0m eta: 1:33:52  iter: 3339  total_loss: 0.6232  loss_cls: 0.3766  loss_box_reg: 0.2011  loss_rpn_cls: 0.01314  loss_rpn_loc: 0.01658    time: 0.4840  last_time: 0.4854  data_time: 0.0152  last_data_time: 0.0161   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:50:42 d2.utils.events]: \u001b[0m eta: 1:33:43  iter: 3359  total_loss: 0.6795  loss_cls: 0.3619  loss_box_reg: 0.2589  loss_rpn_cls: 0.01717  loss_rpn_loc: 0.01325    time: 0.4840  last_time: 0.4828  data_time: 0.0162  last_data_time: 0.0159   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:50:54 d2.utils.events]: \u001b[0m eta: 1:33:33  iter: 3379  total_loss: 0.7309  loss_cls: 0.402  loss_box_reg: 0.2579  loss_rpn_cls: 0.01654  loss_rpn_loc: 0.01742    time: 0.4840  last_time: 0.4829  data_time: 0.0161  last_data_time: 0.0147   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:51:06 d2.utils.events]: \u001b[0m eta: 1:33:24  iter: 3399  total_loss: 0.7352  loss_cls: 0.402  loss_box_reg: 0.2542  loss_rpn_cls: 0.01589  loss_rpn_loc: 0.02461    time: 0.4840  last_time: 0.4842  data_time: 0.0160  last_data_time: 0.0187   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:51:18 d2.utils.events]: \u001b[0m eta: 1:33:14  iter: 3419  total_loss: 0.5917  loss_cls: 0.3111  loss_box_reg: 0.2464  loss_rpn_cls: 0.01709  loss_rpn_loc: 0.01552    time: 0.4840  last_time: 0.4893  data_time: 0.0165  last_data_time: 0.0152   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:51:30 d2.utils.events]: \u001b[0m eta: 1:33:05  iter: 3439  total_loss: 0.7496  loss_cls: 0.4034  loss_box_reg: 0.306  loss_rpn_cls: 0.0159  loss_rpn_loc: 0.01869    time: 0.4840  last_time: 0.4819  data_time: 0.0165  last_data_time: 0.0150   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:51:42 d2.utils.events]: \u001b[0m eta: 1:32:55  iter: 3459  total_loss: 0.6835  loss_cls: 0.3568  loss_box_reg: 0.2374  loss_rpn_cls: 0.02515  loss_rpn_loc: 0.01773    time: 0.4840  last_time: 0.4821  data_time: 0.0157  last_data_time: 0.0143   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:51:54 d2.utils.events]: \u001b[0m eta: 1:32:45  iter: 3479  total_loss: 0.6439  loss_cls: 0.3361  loss_box_reg: 0.2529  loss_rpn_cls: 0.01957  loss_rpn_loc: 0.02212    time: 0.4840  last_time: 0.4881  data_time: 0.0154  last_data_time: 0.0148   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:52:06 d2.utils.events]: \u001b[0m eta: 1:32:35  iter: 3499  total_loss: 0.7481  loss_cls: 0.3963  loss_box_reg: 0.3081  loss_rpn_cls: 0.02619  loss_rpn_loc: 0.03204    time: 0.4840  last_time: 0.4826  data_time: 0.0150  last_data_time: 0.0147   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:52:19 d2.utils.events]: \u001b[0m eta: 1:32:26  iter: 3519  total_loss: 0.6185  loss_cls: 0.3247  loss_box_reg: 0.2262  loss_rpn_cls: 0.02074  loss_rpn_loc: 0.03458    time: 0.4840  last_time: 0.4840  data_time: 0.0159  last_data_time: 0.0165   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:52:31 d2.utils.events]: \u001b[0m eta: 1:32:17  iter: 3539  total_loss: 0.7998  loss_cls: 0.4208  loss_box_reg: 0.2935  loss_rpn_cls: 0.02453  loss_rpn_loc: 0.03073    time: 0.4840  last_time: 0.4813  data_time: 0.0165  last_data_time: 0.0148   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:52:43 d2.utils.events]: \u001b[0m eta: 1:32:07  iter: 3559  total_loss: 0.7077  loss_cls: 0.3754  loss_box_reg: 0.2886  loss_rpn_cls: 0.01546  loss_rpn_loc: 0.0234    time: 0.4840  last_time: 0.4848  data_time: 0.0171  last_data_time: 0.0152   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:52:55 d2.utils.events]: \u001b[0m eta: 1:31:57  iter: 3579  total_loss: 0.6899  loss_cls: 0.406  loss_box_reg: 0.2544  loss_rpn_cls: 0.01692  loss_rpn_loc: 0.02294    time: 0.4840  last_time: 0.4792  data_time: 0.0164  last_data_time: 0.0142   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:53:07 d2.utils.events]: \u001b[0m eta: 1:31:47  iter: 3599  total_loss: 0.7331  loss_cls: 0.4139  loss_box_reg: 0.2499  loss_rpn_cls: 0.01612  loss_rpn_loc: 0.0352    time: 0.4840  last_time: 0.4845  data_time: 0.0155  last_data_time: 0.0150   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:53:19 d2.utils.events]: \u001b[0m eta: 1:31:37  iter: 3619  total_loss: 0.6949  loss_cls: 0.3901  loss_box_reg: 0.2543  loss_rpn_cls: 0.01817  loss_rpn_loc: 0.02616    time: 0.4840  last_time: 0.4826  data_time: 0.0150  last_data_time: 0.0142   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:53:31 d2.utils.events]: \u001b[0m eta: 1:31:28  iter: 3639  total_loss: 0.6339  loss_cls: 0.373  loss_box_reg: 0.2549  loss_rpn_cls: 0.01282  loss_rpn_loc: 0.0136    time: 0.4840  last_time: 0.4896  data_time: 0.0167  last_data_time: 0.0197   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:53:43 d2.utils.events]: \u001b[0m eta: 1:31:18  iter: 3659  total_loss: 0.7568  loss_cls: 0.4257  loss_box_reg: 0.243  loss_rpn_cls: 0.02676  loss_rpn_loc: 0.03192    time: 0.4840  last_time: 0.4816  data_time: 0.0155  last_data_time: 0.0148   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:53:55 d2.utils.events]: \u001b[0m eta: 1:31:09  iter: 3679  total_loss: 0.7124  loss_cls: 0.3761  loss_box_reg: 0.2831  loss_rpn_cls: 0.01536  loss_rpn_loc: 0.03091    time: 0.4840  last_time: 0.4908  data_time: 0.0165  last_data_time: 0.0214   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:54:07 d2.utils.events]: \u001b[0m eta: 1:30:59  iter: 3699  total_loss: 0.6036  loss_cls: 0.3267  loss_box_reg: 0.2296  loss_rpn_cls: 0.01617  loss_rpn_loc: 0.0218    time: 0.4840  last_time: 0.4929  data_time: 0.0159  last_data_time: 0.0216   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:54:20 d2.utils.events]: \u001b[0m eta: 1:30:50  iter: 3719  total_loss: 0.7048  loss_cls: 0.4133  loss_box_reg: 0.257  loss_rpn_cls: 0.0179  loss_rpn_loc: 0.02554    time: 0.4840  last_time: 0.4819  data_time: 0.0158  last_data_time: 0.0150   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:54:32 d2.utils.events]: \u001b[0m eta: 1:30:42  iter: 3739  total_loss: 0.6383  loss_cls: 0.3564  loss_box_reg: 0.2409  loss_rpn_cls: 0.01407  loss_rpn_loc: 0.03424    time: 0.4840  last_time: 0.4879  data_time: 0.0159  last_data_time: 0.0177   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:54:44 d2.utils.events]: \u001b[0m eta: 1:30:33  iter: 3759  total_loss: 0.6608  loss_cls: 0.3417  loss_box_reg: 0.2369  loss_rpn_cls: 0.01259  loss_rpn_loc: 0.01875    time: 0.4840  last_time: 0.4878  data_time: 0.0160  last_data_time: 0.0186   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:54:56 d2.utils.events]: \u001b[0m eta: 1:30:24  iter: 3779  total_loss: 0.4877  loss_cls: 0.3226  loss_box_reg: 0.1904  loss_rpn_cls: 0.01129  loss_rpn_loc: 0.0111    time: 0.4840  last_time: 0.4800  data_time: 0.0164  last_data_time: 0.0144   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:55:08 d2.utils.events]: \u001b[0m eta: 1:30:14  iter: 3799  total_loss: 0.7982  loss_cls: 0.3976  loss_box_reg: 0.2864  loss_rpn_cls: 0.01786  loss_rpn_loc: 0.03806    time: 0.4840  last_time: 0.4844  data_time: 0.0171  last_data_time: 0.0150   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:55:20 d2.utils.events]: \u001b[0m eta: 1:30:05  iter: 3819  total_loss: 0.7331  loss_cls: 0.3409  loss_box_reg: 0.2826  loss_rpn_cls: 0.02189  loss_rpn_loc: 0.0314    time: 0.4841  last_time: 0.4879  data_time: 0.0200  last_data_time: 0.0191   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:55:32 d2.utils.events]: \u001b[0m eta: 1:29:56  iter: 3839  total_loss: 0.6466  loss_cls: 0.3286  loss_box_reg: 0.255  loss_rpn_cls: 0.02027  loss_rpn_loc: 0.03055    time: 0.4841  last_time: 0.4859  data_time: 0.0166  last_data_time: 0.0164   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:55:45 d2.utils.events]: \u001b[0m eta: 1:29:46  iter: 3859  total_loss: 0.6103  loss_cls: 0.3115  loss_box_reg: 0.2279  loss_rpn_cls: 0.0136  loss_rpn_loc: 0.02115    time: 0.4841  last_time: 0.4832  data_time: 0.0161  last_data_time: 0.0154   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:55:57 d2.utils.events]: \u001b[0m eta: 1:29:37  iter: 3879  total_loss: 0.6981  loss_cls: 0.3666  loss_box_reg: 0.2903  loss_rpn_cls: 0.01816  loss_rpn_loc: 0.02638    time: 0.4841  last_time: 0.4847  data_time: 0.0164  last_data_time: 0.0172   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:56:09 d2.utils.events]: \u001b[0m eta: 1:29:27  iter: 3899  total_loss: 0.6744  loss_cls: 0.3656  loss_box_reg: 0.2753  loss_rpn_cls: 0.03135  loss_rpn_loc: 0.02249    time: 0.4841  last_time: 0.4924  data_time: 0.0161  last_data_time: 0.0239   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:56:21 d2.utils.events]: \u001b[0m eta: 1:29:18  iter: 3919  total_loss: 0.7076  loss_cls: 0.3344  loss_box_reg: 0.2581  loss_rpn_cls: 0.0209  loss_rpn_loc: 0.03759    time: 0.4841  last_time: 0.4842  data_time: 0.0158  last_data_time: 0.0140   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:56:33 d2.utils.events]: \u001b[0m eta: 1:29:08  iter: 3939  total_loss: 0.7576  loss_cls: 0.392  loss_box_reg: 0.3017  loss_rpn_cls: 0.0188  loss_rpn_loc: 0.02175    time: 0.4841  last_time: 0.4844  data_time: 0.0165  last_data_time: 0.0173   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:56:45 d2.utils.events]: \u001b[0m eta: 1:28:59  iter: 3959  total_loss: 0.6607  loss_cls: 0.3599  loss_box_reg: 0.2634  loss_rpn_cls: 0.0117  loss_rpn_loc: 0.02246    time: 0.4841  last_time: 0.4831  data_time: 0.0168  last_data_time: 0.0154   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:56:57 d2.utils.events]: \u001b[0m eta: 1:28:49  iter: 3979  total_loss: 0.6895  loss_cls: 0.3558  loss_box_reg: 0.2593  loss_rpn_cls: 0.02294  loss_rpn_loc: 0.02232    time: 0.4841  last_time: 0.4817  data_time: 0.0163  last_data_time: 0.0141   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:57:09 d2.utils.events]: \u001b[0m eta: 1:28:40  iter: 3999  total_loss: 0.7063  loss_cls: 0.3797  loss_box_reg: 0.2505  loss_rpn_cls: 0.02038  loss_rpn_loc: 0.02679    time: 0.4841  last_time: 0.4845  data_time: 0.0160  last_data_time: 0.0164   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:57:22 d2.utils.events]: \u001b[0m eta: 1:28:30  iter: 4019  total_loss: 0.8116  loss_cls: 0.4431  loss_box_reg: 0.2962  loss_rpn_cls: 0.02499  loss_rpn_loc: 0.02954    time: 0.4841  last_time: 0.4833  data_time: 0.0152  last_data_time: 0.0144   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:57:34 d2.utils.events]: \u001b[0m eta: 1:28:20  iter: 4039  total_loss: 0.7083  loss_cls: 0.3458  loss_box_reg: 0.2458  loss_rpn_cls: 0.01863  loss_rpn_loc: 0.0256    time: 0.4841  last_time: 0.4829  data_time: 0.0148  last_data_time: 0.0151   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:57:46 d2.utils.events]: \u001b[0m eta: 1:28:10  iter: 4059  total_loss: 0.6823  loss_cls: 0.3726  loss_box_reg: 0.2762  loss_rpn_cls: 0.01854  loss_rpn_loc: 0.02712    time: 0.4842  last_time: 0.4826  data_time: 0.0156  last_data_time: 0.0151   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:57:58 d2.utils.events]: \u001b[0m eta: 1:28:01  iter: 4079  total_loss: 0.6644  loss_cls: 0.3586  loss_box_reg: 0.2606  loss_rpn_cls: 0.02167  loss_rpn_loc: 0.02904    time: 0.4842  last_time: 0.4870  data_time: 0.0156  last_data_time: 0.0140   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:58:10 d2.utils.events]: \u001b[0m eta: 1:27:51  iter: 4099  total_loss: 0.6663  loss_cls: 0.4277  loss_box_reg: 0.2398  loss_rpn_cls: 0.01462  loss_rpn_loc: 0.01972    time: 0.4842  last_time: 0.4780  data_time: 0.0161  last_data_time: 0.0145   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:58:22 d2.utils.events]: \u001b[0m eta: 1:27:41  iter: 4119  total_loss: 0.6499  loss_cls: 0.3604  loss_box_reg: 0.264  loss_rpn_cls: 0.01622  loss_rpn_loc: 0.02449    time: 0.4842  last_time: 0.4825  data_time: 0.0170  last_data_time: 0.0143   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:58:34 d2.utils.events]: \u001b[0m eta: 1:27:32  iter: 4139  total_loss: 0.6906  loss_cls: 0.3434  loss_box_reg: 0.2769  loss_rpn_cls: 0.01918  loss_rpn_loc: 0.03329    time: 0.4842  last_time: 0.4920  data_time: 0.0156  last_data_time: 0.0151   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:58:47 d2.utils.events]: \u001b[0m eta: 1:27:22  iter: 4159  total_loss: 0.6718  loss_cls: 0.3476  loss_box_reg: 0.2305  loss_rpn_cls: 0.01476  loss_rpn_loc: 0.02775    time: 0.4842  last_time: 0.4825  data_time: 0.0158  last_data_time: 0.0151   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:58:59 d2.utils.events]: \u001b[0m eta: 1:27:13  iter: 4179  total_loss: 0.6724  loss_cls: 0.3801  loss_box_reg: 0.248  loss_rpn_cls: 0.02235  loss_rpn_loc: 0.02422    time: 0.4842  last_time: 0.4844  data_time: 0.0154  last_data_time: 0.0168   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:59:11 d2.utils.events]: \u001b[0m eta: 1:27:04  iter: 4199  total_loss: 0.6136  loss_cls: 0.3169  loss_box_reg: 0.2525  loss_rpn_cls: 0.01382  loss_rpn_loc: 0.01396    time: 0.4842  last_time: 0.4854  data_time: 0.0158  last_data_time: 0.0166   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:59:23 d2.utils.events]: \u001b[0m eta: 1:26:54  iter: 4219  total_loss: 0.556  loss_cls: 0.2961  loss_box_reg: 0.2423  loss_rpn_cls: 0.01504  loss_rpn_loc: 0.02188    time: 0.4842  last_time: 0.4811  data_time: 0.0164  last_data_time: 0.0148   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:59:35 d2.utils.events]: \u001b[0m eta: 1:26:45  iter: 4239  total_loss: 0.6282  loss_cls: 0.2907  loss_box_reg: 0.2411  loss_rpn_cls: 0.01804  loss_rpn_loc: 0.02318    time: 0.4842  last_time: 0.4855  data_time: 0.0163  last_data_time: 0.0145   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:59:47 d2.utils.events]: \u001b[0m eta: 1:26:35  iter: 4259  total_loss: 0.6262  loss_cls: 0.342  loss_box_reg: 0.2388  loss_rpn_cls: 0.02008  loss_rpn_loc: 0.02812    time: 0.4842  last_time: 0.4815  data_time: 0.0158  last_data_time: 0.0143   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 01:59:59 d2.utils.events]: \u001b[0m eta: 1:26:26  iter: 4279  total_loss: 0.5578  loss_cls: 0.3113  loss_box_reg: 0.1938  loss_rpn_cls: 0.01459  loss_rpn_loc: 0.02343    time: 0.4842  last_time: 0.4789  data_time: 0.0153  last_data_time: 0.0147   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:00:11 d2.utils.events]: \u001b[0m eta: 1:26:16  iter: 4299  total_loss: 0.8592  loss_cls: 0.4075  loss_box_reg: 0.3262  loss_rpn_cls: 0.0271  loss_rpn_loc: 0.03264    time: 0.4842  last_time: 0.4851  data_time: 0.0151  last_data_time: 0.0156   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:00:24 d2.utils.events]: \u001b[0m eta: 1:26:06  iter: 4319  total_loss: 0.5694  loss_cls: 0.2939  loss_box_reg: 0.225  loss_rpn_cls: 0.01589  loss_rpn_loc: 0.0189    time: 0.4842  last_time: 0.4839  data_time: 0.0158  last_data_time: 0.0144   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:00:36 d2.utils.events]: \u001b[0m eta: 1:25:57  iter: 4339  total_loss: 0.7645  loss_cls: 0.3934  loss_box_reg: 0.2752  loss_rpn_cls: 0.02417  loss_rpn_loc: 0.03657    time: 0.4842  last_time: 0.4813  data_time: 0.0164  last_data_time: 0.0143   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:00:48 d2.utils.events]: \u001b[0m eta: 1:25:47  iter: 4359  total_loss: 0.5887  loss_cls: 0.3013  loss_box_reg: 0.2257  loss_rpn_cls: 0.01722  loss_rpn_loc: 0.02133    time: 0.4842  last_time: 0.4824  data_time: 0.0162  last_data_time: 0.0140   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:01:00 d2.utils.events]: \u001b[0m eta: 1:25:37  iter: 4379  total_loss: 0.5605  loss_cls: 0.3617  loss_box_reg: 0.2298  loss_rpn_cls: 0.0144  loss_rpn_loc: 0.01488    time: 0.4842  last_time: 0.4861  data_time: 0.0155  last_data_time: 0.0142   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:01:12 d2.utils.events]: \u001b[0m eta: 1:25:27  iter: 4399  total_loss: 0.563  loss_cls: 0.3193  loss_box_reg: 0.1918  loss_rpn_cls: 0.007838  loss_rpn_loc: 0.0202    time: 0.4842  last_time: 0.4801  data_time: 0.0155  last_data_time: 0.0158   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:01:24 d2.utils.events]: \u001b[0m eta: 1:25:17  iter: 4419  total_loss: 0.6495  loss_cls: 0.353  loss_box_reg: 0.2783  loss_rpn_cls: 0.01769  loss_rpn_loc: 0.02092    time: 0.4842  last_time: 0.4808  data_time: 0.0158  last_data_time: 0.0141   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:01:36 d2.utils.events]: \u001b[0m eta: 1:25:08  iter: 4439  total_loss: 0.7191  loss_cls: 0.3794  loss_box_reg: 0.2264  loss_rpn_cls: 0.0166  loss_rpn_loc: 0.02671    time: 0.4842  last_time: 0.4853  data_time: 0.0158  last_data_time: 0.0154   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:01:48 d2.utils.events]: \u001b[0m eta: 1:24:58  iter: 4459  total_loss: 0.6126  loss_cls: 0.3281  loss_box_reg: 0.1827  loss_rpn_cls: 0.02284  loss_rpn_loc: 0.03871    time: 0.4842  last_time: 0.4852  data_time: 0.0161  last_data_time: 0.0155   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:02:00 d2.utils.events]: \u001b[0m eta: 1:24:49  iter: 4479  total_loss: 0.6777  loss_cls: 0.3468  loss_box_reg: 0.2398  loss_rpn_cls: 0.0141  loss_rpn_loc: 0.02071    time: 0.4842  last_time: 0.4884  data_time: 0.0173  last_data_time: 0.0203   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:02:12 d2.utils.events]: \u001b[0m eta: 1:24:39  iter: 4499  total_loss: 0.6252  loss_cls: 0.3132  loss_box_reg: 0.2369  loss_rpn_cls: 0.01281  loss_rpn_loc: 0.01288    time: 0.4842  last_time: 0.4856  data_time: 0.0157  last_data_time: 0.0167   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:02:25 d2.utils.events]: \u001b[0m eta: 1:24:30  iter: 4519  total_loss: 0.7369  loss_cls: 0.3675  loss_box_reg: 0.2859  loss_rpn_cls: 0.01792  loss_rpn_loc: 0.0255    time: 0.4842  last_time: 0.4834  data_time: 0.0169  last_data_time: 0.0148   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:02:37 d2.utils.events]: \u001b[0m eta: 1:24:20  iter: 4539  total_loss: 0.6437  loss_cls: 0.3032  loss_box_reg: 0.2796  loss_rpn_cls: 0.02532  loss_rpn_loc: 0.01948    time: 0.4842  last_time: 0.4854  data_time: 0.0162  last_data_time: 0.0147   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:02:49 d2.utils.events]: \u001b[0m eta: 1:24:10  iter: 4559  total_loss: 0.7788  loss_cls: 0.3992  loss_box_reg: 0.3112  loss_rpn_cls: 0.02198  loss_rpn_loc: 0.0397    time: 0.4842  last_time: 0.4882  data_time: 0.0153  last_data_time: 0.0199   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:03:01 d2.utils.events]: \u001b[0m eta: 1:24:00  iter: 4579  total_loss: 0.7209  loss_cls: 0.3748  loss_box_reg: 0.2461  loss_rpn_cls: 0.02175  loss_rpn_loc: 0.02875    time: 0.4842  last_time: 0.4823  data_time: 0.0158  last_data_time: 0.0147   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:03:13 d2.utils.events]: \u001b[0m eta: 1:23:51  iter: 4599  total_loss: 0.6842  loss_cls: 0.3478  loss_box_reg: 0.2714  loss_rpn_cls: 0.023  loss_rpn_loc: 0.02692    time: 0.4842  last_time: 0.4857  data_time: 0.0166  last_data_time: 0.0176   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:03:25 d2.utils.events]: \u001b[0m eta: 1:23:41  iter: 4619  total_loss: 0.6668  loss_cls: 0.4283  loss_box_reg: 0.228  loss_rpn_cls: 0.012  loss_rpn_loc: 0.009684    time: 0.4842  last_time: 0.4839  data_time: 0.0172  last_data_time: 0.0152   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:03:37 d2.utils.events]: \u001b[0m eta: 1:23:32  iter: 4639  total_loss: 0.6381  loss_cls: 0.3258  loss_box_reg: 0.2368  loss_rpn_cls: 0.009257  loss_rpn_loc: 0.01849    time: 0.4842  last_time: 0.4805  data_time: 0.0162  last_data_time: 0.0143   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:03:49 d2.utils.events]: \u001b[0m eta: 1:23:22  iter: 4659  total_loss: 0.7283  loss_cls: 0.378  loss_box_reg: 0.3041  loss_rpn_cls: 0.01707  loss_rpn_loc: 0.03052    time: 0.4842  last_time: 0.4860  data_time: 0.0173  last_data_time: 0.0178   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:04:01 d2.utils.events]: \u001b[0m eta: 1:23:12  iter: 4679  total_loss: 0.7168  loss_cls: 0.4149  loss_box_reg: 0.2765  loss_rpn_cls: 0.01724  loss_rpn_loc: 0.01353    time: 0.4842  last_time: 0.4811  data_time: 0.0157  last_data_time: 0.0162   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:04:14 d2.utils.events]: \u001b[0m eta: 1:23:02  iter: 4699  total_loss: 0.7211  loss_cls: 0.4189  loss_box_reg: 0.2495  loss_rpn_cls: 0.01917  loss_rpn_loc: 0.02099    time: 0.4842  last_time: 0.4854  data_time: 0.0166  last_data_time: 0.0166   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:04:26 d2.utils.events]: \u001b[0m eta: 1:22:53  iter: 4719  total_loss: 0.7247  loss_cls: 0.3782  loss_box_reg: 0.2498  loss_rpn_cls: 0.01419  loss_rpn_loc: 0.02706    time: 0.4842  last_time: 0.4942  data_time: 0.0155  last_data_time: 0.0176   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:04:38 d2.utils.events]: \u001b[0m eta: 1:22:44  iter: 4739  total_loss: 0.671  loss_cls: 0.3596  loss_box_reg: 0.264  loss_rpn_cls: 0.01609  loss_rpn_loc: 0.01652    time: 0.4842  last_time: 0.4899  data_time: 0.0161  last_data_time: 0.0158   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:04:50 d2.utils.events]: \u001b[0m eta: 1:22:34  iter: 4759  total_loss: 0.6538  loss_cls: 0.3276  loss_box_reg: 0.2543  loss_rpn_cls: 0.02483  loss_rpn_loc: 0.02844    time: 0.4842  last_time: 0.4807  data_time: 0.0155  last_data_time: 0.0143   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:05:02 d2.utils.events]: \u001b[0m eta: 1:22:24  iter: 4779  total_loss: 0.5799  loss_cls: 0.3308  loss_box_reg: 0.2432  loss_rpn_cls: 0.01296  loss_rpn_loc: 0.01875    time: 0.4842  last_time: 0.4795  data_time: 0.0149  last_data_time: 0.0142   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:05:14 d2.utils.events]: \u001b[0m eta: 1:22:14  iter: 4799  total_loss: 0.6737  loss_cls: 0.3537  loss_box_reg: 0.2374  loss_rpn_cls: 0.02176  loss_rpn_loc: 0.03011    time: 0.4842  last_time: 0.4837  data_time: 0.0151  last_data_time: 0.0170   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:05:26 d2.utils.events]: \u001b[0m eta: 1:22:03  iter: 4819  total_loss: 0.5904  loss_cls: 0.3  loss_box_reg: 0.2271  loss_rpn_cls: 0.01412  loss_rpn_loc: 0.01718    time: 0.4842  last_time: 0.4917  data_time: 0.0150  last_data_time: 0.0143   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:05:38 d2.utils.events]: \u001b[0m eta: 1:21:53  iter: 4839  total_loss: 0.7108  loss_cls: 0.3645  loss_box_reg: 0.2883  loss_rpn_cls: 0.01713  loss_rpn_loc: 0.02599    time: 0.4842  last_time: 0.4842  data_time: 0.0152  last_data_time: 0.0151   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:05:50 d2.utils.events]: \u001b[0m eta: 1:21:42  iter: 4859  total_loss: 0.7467  loss_cls: 0.4034  loss_box_reg: 0.2581  loss_rpn_cls: 0.01334  loss_rpn_loc: 0.02414    time: 0.4842  last_time: 0.4822  data_time: 0.0154  last_data_time: 0.0147   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:06:02 d2.utils.events]: \u001b[0m eta: 1:21:33  iter: 4879  total_loss: 0.6776  loss_cls: 0.3288  loss_box_reg: 0.2435  loss_rpn_cls: 0.0139  loss_rpn_loc: 0.0207    time: 0.4842  last_time: 0.4809  data_time: 0.0159  last_data_time: 0.0142   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:06:14 d2.utils.events]: \u001b[0m eta: 1:21:23  iter: 4899  total_loss: 0.8089  loss_cls: 0.413  loss_box_reg: 0.3253  loss_rpn_cls: 0.02173  loss_rpn_loc: 0.04276    time: 0.4842  last_time: 0.4876  data_time: 0.0158  last_data_time: 0.0194   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:06:27 d2.utils.events]: \u001b[0m eta: 1:21:13  iter: 4919  total_loss: 0.5475  loss_cls: 0.2968  loss_box_reg: 0.2571  loss_rpn_cls: 0.01695  loss_rpn_loc: 0.01493    time: 0.4842  last_time: 0.4871  data_time: 0.0173  last_data_time: 0.0188   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:06:39 d2.utils.events]: \u001b[0m eta: 1:21:04  iter: 4939  total_loss: 0.6262  loss_cls: 0.3018  loss_box_reg: 0.2813  loss_rpn_cls: 0.01643  loss_rpn_loc: 0.03259    time: 0.4842  last_time: 0.4862  data_time: 0.0169  last_data_time: 0.0190   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:06:51 d2.utils.events]: \u001b[0m eta: 1:20:54  iter: 4959  total_loss: 0.5786  loss_cls: 0.292  loss_box_reg: 0.2229  loss_rpn_cls: 0.01367  loss_rpn_loc: 0.02881    time: 0.4842  last_time: 0.4827  data_time: 0.0157  last_data_time: 0.0143   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:07:03 d2.utils.events]: \u001b[0m eta: 1:20:44  iter: 4979  total_loss: 0.4509  loss_cls: 0.2574  loss_box_reg: 0.1686  loss_rpn_cls: 0.008546  loss_rpn_loc: 0.01093    time: 0.4842  last_time: 0.4830  data_time: 0.0168  last_data_time: 0.0151   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:07:15 d2.utils.events]: \u001b[0m eta: 1:20:34  iter: 4999  total_loss: 0.4802  loss_cls: 0.2723  loss_box_reg: 0.2167  loss_rpn_cls: 0.01098  loss_rpn_loc: 0.01228    time: 0.4843  last_time: 0.4823  data_time: 0.0160  last_data_time: 0.0143   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:07:27 d2.utils.events]: \u001b[0m eta: 1:20:25  iter: 5019  total_loss: 0.8021  loss_cls: 0.4215  loss_box_reg: 0.3074  loss_rpn_cls: 0.01227  loss_rpn_loc: 0.02718    time: 0.4843  last_time: 0.4823  data_time: 0.0165  last_data_time: 0.0143   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:07:39 d2.utils.events]: \u001b[0m eta: 1:20:16  iter: 5039  total_loss: 0.6209  loss_cls: 0.3278  loss_box_reg: 0.2631  loss_rpn_cls: 0.01946  loss_rpn_loc: 0.03434    time: 0.4843  last_time: 0.4905  data_time: 0.0158  last_data_time: 0.0221   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:07:51 d2.utils.events]: \u001b[0m eta: 1:20:06  iter: 5059  total_loss: 0.5531  loss_cls: 0.2981  loss_box_reg: 0.226  loss_rpn_cls: 0.01525  loss_rpn_loc: 0.01714    time: 0.4843  last_time: 0.4874  data_time: 0.0153  last_data_time: 0.0156   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:08:04 d2.utils.events]: \u001b[0m eta: 1:19:56  iter: 5079  total_loss: 0.6243  loss_cls: 0.3139  loss_box_reg: 0.2347  loss_rpn_cls: 0.01598  loss_rpn_loc: 0.02817    time: 0.4843  last_time: 0.4856  data_time: 0.0152  last_data_time: 0.0146   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:08:16 d2.utils.events]: \u001b[0m eta: 1:19:47  iter: 5099  total_loss: 0.5918  loss_cls: 0.328  loss_box_reg: 0.218  loss_rpn_cls: 0.01423  loss_rpn_loc: 0.02048    time: 0.4843  last_time: 0.4949  data_time: 0.0153  last_data_time: 0.0150   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:08:28 d2.utils.events]: \u001b[0m eta: 1:19:37  iter: 5119  total_loss: 0.6699  loss_cls: 0.374  loss_box_reg: 0.2431  loss_rpn_cls: 0.01169  loss_rpn_loc: 0.02566    time: 0.4843  last_time: 0.4863  data_time: 0.0158  last_data_time: 0.0182   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:08:40 d2.utils.events]: \u001b[0m eta: 1:19:27  iter: 5139  total_loss: 0.6809  loss_cls: 0.3255  loss_box_reg: 0.2565  loss_rpn_cls: 0.01514  loss_rpn_loc: 0.02212    time: 0.4843  last_time: 0.4987  data_time: 0.0175  last_data_time: 0.0215   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:08:52 d2.utils.events]: \u001b[0m eta: 1:19:18  iter: 5159  total_loss: 0.5866  loss_cls: 0.3255  loss_box_reg: 0.2437  loss_rpn_cls: 0.01168  loss_rpn_loc: 0.01802    time: 0.4843  last_time: 0.4866  data_time: 0.0160  last_data_time: 0.0171   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:09:04 d2.utils.events]: \u001b[0m eta: 1:19:08  iter: 5179  total_loss: 0.6534  loss_cls: 0.3275  loss_box_reg: 0.2551  loss_rpn_cls: 0.01571  loss_rpn_loc: 0.01751    time: 0.4843  last_time: 0.5027  data_time: 0.0159  last_data_time: 0.0192   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:09:16 d2.utils.events]: \u001b[0m eta: 1:18:59  iter: 5199  total_loss: 0.707  loss_cls: 0.3682  loss_box_reg: 0.277  loss_rpn_cls: 0.01809  loss_rpn_loc: 0.02061    time: 0.4843  last_time: 0.4830  data_time: 0.0151  last_data_time: 0.0154   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:09:28 d2.utils.events]: \u001b[0m eta: 1:18:50  iter: 5219  total_loss: 0.6395  loss_cls: 0.3527  loss_box_reg: 0.2648  loss_rpn_cls: 0.0163  loss_rpn_loc: 0.02818    time: 0.4843  last_time: 0.4851  data_time: 0.0164  last_data_time: 0.0185   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:09:41 d2.utils.events]: \u001b[0m eta: 1:18:41  iter: 5239  total_loss: 0.6014  loss_cls: 0.3175  loss_box_reg: 0.2135  loss_rpn_cls: 0.02367  loss_rpn_loc: 0.03527    time: 0.4843  last_time: 0.4861  data_time: 0.0160  last_data_time: 0.0149   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:09:53 d2.utils.events]: \u001b[0m eta: 1:18:31  iter: 5259  total_loss: 0.6255  loss_cls: 0.311  loss_box_reg: 0.2476  loss_rpn_cls: 0.02235  loss_rpn_loc: 0.03459    time: 0.4843  last_time: 0.4838  data_time: 0.0165  last_data_time: 0.0160   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:10:05 d2.utils.events]: \u001b[0m eta: 1:18:22  iter: 5279  total_loss: 0.6107  loss_cls: 0.3404  loss_box_reg: 0.2204  loss_rpn_cls: 0.01899  loss_rpn_loc: 0.02728    time: 0.4843  last_time: 0.4864  data_time: 0.0163  last_data_time: 0.0183   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:10:17 d2.utils.events]: \u001b[0m eta: 1:18:12  iter: 5299  total_loss: 0.7098  loss_cls: 0.3691  loss_box_reg: 0.2726  loss_rpn_cls: 0.02842  loss_rpn_loc: 0.04228    time: 0.4843  last_time: 0.4922  data_time: 0.0165  last_data_time: 0.0238   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:10:29 d2.utils.events]: \u001b[0m eta: 1:18:03  iter: 5319  total_loss: 0.5371  loss_cls: 0.3054  loss_box_reg: 0.1954  loss_rpn_cls: 0.01418  loss_rpn_loc: 0.01551    time: 0.4843  last_time: 0.4829  data_time: 0.0155  last_data_time: 0.0148   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:10:41 d2.utils.events]: \u001b[0m eta: 1:17:53  iter: 5339  total_loss: 0.6434  loss_cls: 0.3386  loss_box_reg: 0.2633  loss_rpn_cls: 0.01382  loss_rpn_loc: 0.01606    time: 0.4843  last_time: 0.4828  data_time: 0.0168  last_data_time: 0.0149   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:10:54 d2.utils.events]: \u001b[0m eta: 1:17:44  iter: 5359  total_loss: 0.6081  loss_cls: 0.366  loss_box_reg: 0.2094  loss_rpn_cls: 0.0176  loss_rpn_loc: 0.02952    time: 0.4843  last_time: 0.4856  data_time: 0.0162  last_data_time: 0.0172   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:11:06 d2.utils.events]: \u001b[0m eta: 1:17:34  iter: 5379  total_loss: 0.615  loss_cls: 0.3385  loss_box_reg: 0.217  loss_rpn_cls: 0.0205  loss_rpn_loc: 0.02518    time: 0.4843  last_time: 0.4831  data_time: 0.0161  last_data_time: 0.0144   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:11:18 d2.utils.events]: \u001b[0m eta: 1:17:24  iter: 5399  total_loss: 0.6725  loss_cls: 0.326  loss_box_reg: 0.2682  loss_rpn_cls: 0.01598  loss_rpn_loc: 0.02787    time: 0.4843  last_time: 0.4836  data_time: 0.0150  last_data_time: 0.0163   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:11:30 d2.utils.events]: \u001b[0m eta: 1:17:15  iter: 5419  total_loss: 0.6737  loss_cls: 0.3457  loss_box_reg: 0.2653  loss_rpn_cls: 0.01432  loss_rpn_loc: 0.02292    time: 0.4843  last_time: 0.4830  data_time: 0.0156  last_data_time: 0.0143   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:11:42 d2.utils.events]: \u001b[0m eta: 1:17:05  iter: 5439  total_loss: 0.6661  loss_cls: 0.3482  loss_box_reg: 0.2805  loss_rpn_cls: 0.01712  loss_rpn_loc: 0.01928    time: 0.4843  last_time: 0.4848  data_time: 0.0164  last_data_time: 0.0167   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:11:54 d2.utils.events]: \u001b[0m eta: 1:16:56  iter: 5459  total_loss: 0.7114  loss_cls: 0.3541  loss_box_reg: 0.2972  loss_rpn_cls: 0.01442  loss_rpn_loc: 0.02695    time: 0.4843  last_time: 0.4851  data_time: 0.0167  last_data_time: 0.0145   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:12:06 d2.utils.events]: \u001b[0m eta: 1:16:46  iter: 5479  total_loss: 0.7428  loss_cls: 0.3424  loss_box_reg: 0.287  loss_rpn_cls: 0.02342  loss_rpn_loc: 0.03088    time: 0.4844  last_time: 0.4886  data_time: 0.0160  last_data_time: 0.0155   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:12:18 d2.utils.events]: \u001b[0m eta: 1:16:37  iter: 5499  total_loss: 0.6535  loss_cls: 0.3367  loss_box_reg: 0.2508  loss_rpn_cls: 0.02214  loss_rpn_loc: 0.02446    time: 0.4844  last_time: 0.4870  data_time: 0.0159  last_data_time: 0.0147   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:12:30 d2.utils.events]: \u001b[0m eta: 1:16:27  iter: 5519  total_loss: 0.6179  loss_cls: 0.3536  loss_box_reg: 0.275  loss_rpn_cls: 0.02066  loss_rpn_loc: 0.02187    time: 0.4844  last_time: 0.4864  data_time: 0.0164  last_data_time: 0.0172   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:12:43 d2.utils.events]: \u001b[0m eta: 1:16:17  iter: 5539  total_loss: 0.6365  loss_cls: 0.3438  loss_box_reg: 0.2437  loss_rpn_cls: 0.01177  loss_rpn_loc: 0.02419    time: 0.4844  last_time: 0.4896  data_time: 0.0152  last_data_time: 0.0160   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:12:55 d2.utils.events]: \u001b[0m eta: 1:16:08  iter: 5559  total_loss: 0.6105  loss_cls: 0.3423  loss_box_reg: 0.2209  loss_rpn_cls: 0.01622  loss_rpn_loc: 0.01572    time: 0.4844  last_time: 0.4830  data_time: 0.0159  last_data_time: 0.0148   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:13:07 d2.utils.events]: \u001b[0m eta: 1:15:59  iter: 5579  total_loss: 0.7129  loss_cls: 0.3458  loss_box_reg: 0.2591  loss_rpn_cls: 0.02706  loss_rpn_loc: 0.041    time: 0.4844  last_time: 0.4866  data_time: 0.0170  last_data_time: 0.0214   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:13:19 d2.utils.events]: \u001b[0m eta: 1:15:49  iter: 5599  total_loss: 0.6179  loss_cls: 0.3469  loss_box_reg: 0.2356  loss_rpn_cls: 0.01628  loss_rpn_loc: 0.02194    time: 0.4844  last_time: 0.4830  data_time: 0.0161  last_data_time: 0.0151   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:13:31 d2.utils.events]: \u001b[0m eta: 1:15:40  iter: 5619  total_loss: 0.6679  loss_cls: 0.3291  loss_box_reg: 0.2479  loss_rpn_cls: 0.01682  loss_rpn_loc: 0.01978    time: 0.4844  last_time: 0.4828  data_time: 0.0152  last_data_time: 0.0149   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:13:43 d2.utils.events]: \u001b[0m eta: 1:15:30  iter: 5639  total_loss: 0.655  loss_cls: 0.3581  loss_box_reg: 0.2545  loss_rpn_cls: 0.01713  loss_rpn_loc: 0.02004    time: 0.4844  last_time: 0.4839  data_time: 0.0171  last_data_time: 0.0141   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:13:55 d2.utils.events]: \u001b[0m eta: 1:15:21  iter: 5659  total_loss: 0.6776  loss_cls: 0.3583  loss_box_reg: 0.2256  loss_rpn_cls: 0.01629  loss_rpn_loc: 0.03424    time: 0.4844  last_time: 0.4830  data_time: 0.0158  last_data_time: 0.0149   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:14:07 d2.utils.events]: \u001b[0m eta: 1:15:11  iter: 5679  total_loss: 0.6911  loss_cls: 0.3316  loss_box_reg: 0.2353  loss_rpn_cls: 0.01551  loss_rpn_loc: 0.02778    time: 0.4844  last_time: 0.4834  data_time: 0.0155  last_data_time: 0.0150   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:14:20 d2.utils.events]: \u001b[0m eta: 1:15:01  iter: 5699  total_loss: 0.6415  loss_cls: 0.335  loss_box_reg: 0.2453  loss_rpn_cls: 0.01664  loss_rpn_loc: 0.01844    time: 0.4844  last_time: 0.4877  data_time: 0.0166  last_data_time: 0.0163   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:14:32 d2.utils.events]: \u001b[0m eta: 1:14:51  iter: 5719  total_loss: 0.5704  loss_cls: 0.3253  loss_box_reg: 0.2259  loss_rpn_cls: 0.01274  loss_rpn_loc: 0.01311    time: 0.4844  last_time: 0.4879  data_time: 0.0160  last_data_time: 0.0200   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:14:44 d2.utils.events]: \u001b[0m eta: 1:14:41  iter: 5739  total_loss: 0.5685  loss_cls: 0.2997  loss_box_reg: 0.2439  loss_rpn_cls: 0.009684  loss_rpn_loc: 0.01704    time: 0.4844  last_time: 0.4810  data_time: 0.0162  last_data_time: 0.0151   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:14:56 d2.utils.events]: \u001b[0m eta: 1:14:32  iter: 5759  total_loss: 0.589  loss_cls: 0.3274  loss_box_reg: 0.2302  loss_rpn_cls: 0.01267  loss_rpn_loc: 0.02587    time: 0.4844  last_time: 0.4865  data_time: 0.0162  last_data_time: 0.0173   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:15:08 d2.utils.events]: \u001b[0m eta: 1:14:22  iter: 5779  total_loss: 0.5504  loss_cls: 0.2701  loss_box_reg: 0.2086  loss_rpn_cls: 0.01723  loss_rpn_loc: 0.02739    time: 0.4844  last_time: 0.4836  data_time: 0.0159  last_data_time: 0.0173   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:15:20 d2.utils.events]: \u001b[0m eta: 1:14:13  iter: 5799  total_loss: 0.6606  loss_cls: 0.3579  loss_box_reg: 0.2419  loss_rpn_cls: 0.02131  loss_rpn_loc: 0.02535    time: 0.4844  last_time: 0.4916  data_time: 0.0174  last_data_time: 0.0236   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:15:32 d2.utils.events]: \u001b[0m eta: 1:14:03  iter: 5819  total_loss: 0.5664  loss_cls: 0.2918  loss_box_reg: 0.2301  loss_rpn_cls: 0.01578  loss_rpn_loc: 0.01666    time: 0.4844  last_time: 0.4799  data_time: 0.0173  last_data_time: 0.0146   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:15:44 d2.utils.events]: \u001b[0m eta: 1:13:54  iter: 5839  total_loss: 0.5853  loss_cls: 0.2969  loss_box_reg: 0.2344  loss_rpn_cls: 0.01853  loss_rpn_loc: 0.024    time: 0.4844  last_time: 0.4829  data_time: 0.0165  last_data_time: 0.0145   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:15:56 d2.utils.events]: \u001b[0m eta: 1:13:45  iter: 5859  total_loss: 0.5776  loss_cls: 0.2913  loss_box_reg: 0.2353  loss_rpn_cls: 0.01658  loss_rpn_loc: 0.02722    time: 0.4844  last_time: 0.4814  data_time: 0.0152  last_data_time: 0.0144   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:16:09 d2.utils.events]: \u001b[0m eta: 1:13:35  iter: 5879  total_loss: 0.6798  loss_cls: 0.3503  loss_box_reg: 0.2769  loss_rpn_cls: 0.01604  loss_rpn_loc: 0.02127    time: 0.4844  last_time: 0.4795  data_time: 0.0157  last_data_time: 0.0143   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:16:21 d2.utils.events]: \u001b[0m eta: 1:13:25  iter: 5899  total_loss: 0.5145  loss_cls: 0.2692  loss_box_reg: 0.201  loss_rpn_cls: 0.01283  loss_rpn_loc: 0.01396    time: 0.4844  last_time: 0.4832  data_time: 0.0156  last_data_time: 0.0153   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:16:33 d2.utils.events]: \u001b[0m eta: 1:13:15  iter: 5919  total_loss: 0.6187  loss_cls: 0.3278  loss_box_reg: 0.2003  loss_rpn_cls: 0.01571  loss_rpn_loc: 0.0266    time: 0.4844  last_time: 0.4861  data_time: 0.0159  last_data_time: 0.0144   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:16:45 d2.utils.events]: \u001b[0m eta: 1:13:06  iter: 5939  total_loss: 0.7029  loss_cls: 0.3867  loss_box_reg: 0.2607  loss_rpn_cls: 0.01264  loss_rpn_loc: 0.01798    time: 0.4844  last_time: 0.4872  data_time: 0.0169  last_data_time: 0.0143   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:16:57 d2.utils.events]: \u001b[0m eta: 1:12:56  iter: 5959  total_loss: 0.6818  loss_cls: 0.3669  loss_box_reg: 0.264  loss_rpn_cls: 0.0161  loss_rpn_loc: 0.02547    time: 0.4844  last_time: 0.4864  data_time: 0.0169  last_data_time: 0.0173   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:17:09 d2.utils.events]: \u001b[0m eta: 1:12:47  iter: 5979  total_loss: 0.6445  loss_cls: 0.3472  loss_box_reg: 0.2657  loss_rpn_cls: 0.01792  loss_rpn_loc: 0.02016    time: 0.4844  last_time: 0.4811  data_time: 0.0161  last_data_time: 0.0144   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:17:25 d2.data.datasets.coco]: \u001b[0mLoaded 4871 images in COCO format from /data/ephemeral/home/workspace/dataset/test.json\n",
      "\u001b[32m[10/10 02:17:25 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/10 02:17:25 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[10/10 02:17:25 d2.data.common]: \u001b[0mSerializing 4871 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/10 02:17:25 d2.data.common]: \u001b[0mSerialized dataset takes 0.63 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/10 02:17:25 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[10/10 02:17:25 d2.evaluation.evaluator]: \u001b[0mStart inference on 4871 batches\n",
      "\u001b[32m[10/10 02:17:26 d2.evaluation.evaluator]: \u001b[0mInference done 11/4871. Dataloading: 0.0013 s/iter. Inference: 0.0472 s/iter. Eval: 0.0003 s/iter. Total: 0.0487 s/iter. ETA=0:03:56\n",
      "\u001b[32m[10/10 02:17:31 d2.evaluation.evaluator]: \u001b[0mInference done 118/4871. Dataloading: 0.0014 s/iter. Inference: 0.0453 s/iter. Eval: 0.0002 s/iter. Total: 0.0470 s/iter. ETA=0:03:43\n",
      "\u001b[32m[10/10 02:17:36 d2.evaluation.evaluator]: \u001b[0mInference done 220/4871. Dataloading: 0.0013 s/iter. Inference: 0.0464 s/iter. Eval: 0.0002 s/iter. Total: 0.0481 s/iter. ETA=0:03:43\n",
      "\u001b[32m[10/10 02:17:41 d2.evaluation.evaluator]: \u001b[0mInference done 323/4871. Dataloading: 0.0014 s/iter. Inference: 0.0466 s/iter. Eval: 0.0003 s/iter. Total: 0.0484 s/iter. ETA=0:03:39\n",
      "\u001b[32m[10/10 02:17:46 d2.evaluation.evaluator]: \u001b[0mInference done 429/4871. Dataloading: 0.0014 s/iter. Inference: 0.0464 s/iter. Eval: 0.0003 s/iter. Total: 0.0481 s/iter. ETA=0:03:33\n",
      "\u001b[32m[10/10 02:17:51 d2.evaluation.evaluator]: \u001b[0mInference done 532/4871. Dataloading: 0.0014 s/iter. Inference: 0.0465 s/iter. Eval: 0.0003 s/iter. Total: 0.0482 s/iter. ETA=0:03:29\n",
      "\u001b[32m[10/10 02:17:56 d2.evaluation.evaluator]: \u001b[0mInference done 635/4871. Dataloading: 0.0014 s/iter. Inference: 0.0465 s/iter. Eval: 0.0003 s/iter. Total: 0.0483 s/iter. ETA=0:03:24\n",
      "\u001b[32m[10/10 02:18:01 d2.evaluation.evaluator]: \u001b[0mInference done 738/4871. Dataloading: 0.0015 s/iter. Inference: 0.0465 s/iter. Eval: 0.0003 s/iter. Total: 0.0483 s/iter. ETA=0:03:19\n",
      "\u001b[32m[10/10 02:18:06 d2.evaluation.evaluator]: \u001b[0mInference done 844/4871. Dataloading: 0.0014 s/iter. Inference: 0.0464 s/iter. Eval: 0.0003 s/iter. Total: 0.0482 s/iter. ETA=0:03:14\n",
      "\u001b[32m[10/10 02:18:11 d2.evaluation.evaluator]: \u001b[0mInference done 946/4871. Dataloading: 0.0015 s/iter. Inference: 0.0465 s/iter. Eval: 0.0003 s/iter. Total: 0.0483 s/iter. ETA=0:03:09\n",
      "\u001b[32m[10/10 02:18:16 d2.evaluation.evaluator]: \u001b[0mInference done 1044/4871. Dataloading: 0.0015 s/iter. Inference: 0.0467 s/iter. Eval: 0.0003 s/iter. Total: 0.0486 s/iter. ETA=0:03:05\n",
      "\u001b[32m[10/10 02:18:21 d2.evaluation.evaluator]: \u001b[0mInference done 1146/4871. Dataloading: 0.0015 s/iter. Inference: 0.0468 s/iter. Eval: 0.0003 s/iter. Total: 0.0486 s/iter. ETA=0:03:01\n",
      "\u001b[32m[10/10 02:18:26 d2.evaluation.evaluator]: \u001b[0mInference done 1250/4871. Dataloading: 0.0015 s/iter. Inference: 0.0468 s/iter. Eval: 0.0003 s/iter. Total: 0.0486 s/iter. ETA=0:02:55\n",
      "\u001b[32m[10/10 02:18:31 d2.evaluation.evaluator]: \u001b[0mInference done 1352/4871. Dataloading: 0.0015 s/iter. Inference: 0.0468 s/iter. Eval: 0.0003 s/iter. Total: 0.0486 s/iter. ETA=0:02:51\n",
      "\u001b[32m[10/10 02:18:36 d2.evaluation.evaluator]: \u001b[0mInference done 1455/4871. Dataloading: 0.0015 s/iter. Inference: 0.0468 s/iter. Eval: 0.0003 s/iter. Total: 0.0486 s/iter. ETA=0:02:46\n",
      "\u001b[32m[10/10 02:18:41 d2.evaluation.evaluator]: \u001b[0mInference done 1558/4871. Dataloading: 0.0015 s/iter. Inference: 0.0468 s/iter. Eval: 0.0003 s/iter. Total: 0.0486 s/iter. ETA=0:02:41\n",
      "\u001b[32m[10/10 02:18:46 d2.evaluation.evaluator]: \u001b[0mInference done 1659/4871. Dataloading: 0.0015 s/iter. Inference: 0.0469 s/iter. Eval: 0.0003 s/iter. Total: 0.0487 s/iter. ETA=0:02:36\n",
      "\u001b[32m[10/10 02:18:51 d2.evaluation.evaluator]: \u001b[0mInference done 1761/4871. Dataloading: 0.0015 s/iter. Inference: 0.0469 s/iter. Eval: 0.0003 s/iter. Total: 0.0487 s/iter. ETA=0:02:31\n",
      "\u001b[32m[10/10 02:18:56 d2.evaluation.evaluator]: \u001b[0mInference done 1860/4871. Dataloading: 0.0015 s/iter. Inference: 0.0470 s/iter. Eval: 0.0003 s/iter. Total: 0.0488 s/iter. ETA=0:02:27\n",
      "\u001b[32m[10/10 02:19:01 d2.evaluation.evaluator]: \u001b[0mInference done 1962/4871. Dataloading: 0.0015 s/iter. Inference: 0.0470 s/iter. Eval: 0.0003 s/iter. Total: 0.0489 s/iter. ETA=0:02:22\n",
      "\u001b[32m[10/10 02:19:06 d2.evaluation.evaluator]: \u001b[0mInference done 2063/4871. Dataloading: 0.0015 s/iter. Inference: 0.0471 s/iter. Eval: 0.0003 s/iter. Total: 0.0489 s/iter. ETA=0:02:17\n",
      "\u001b[32m[10/10 02:19:11 d2.evaluation.evaluator]: \u001b[0mInference done 2166/4871. Dataloading: 0.0015 s/iter. Inference: 0.0471 s/iter. Eval: 0.0003 s/iter. Total: 0.0489 s/iter. ETA=0:02:12\n",
      "\u001b[32m[10/10 02:19:16 d2.evaluation.evaluator]: \u001b[0mInference done 2270/4871. Dataloading: 0.0015 s/iter. Inference: 0.0471 s/iter. Eval: 0.0003 s/iter. Total: 0.0489 s/iter. ETA=0:02:07\n",
      "\u001b[32m[10/10 02:19:21 d2.evaluation.evaluator]: \u001b[0mInference done 2374/4871. Dataloading: 0.0015 s/iter. Inference: 0.0470 s/iter. Eval: 0.0003 s/iter. Total: 0.0489 s/iter. ETA=0:02:02\n",
      "\u001b[32m[10/10 02:19:26 d2.evaluation.evaluator]: \u001b[0mInference done 2477/4871. Dataloading: 0.0015 s/iter. Inference: 0.0470 s/iter. Eval: 0.0003 s/iter. Total: 0.0489 s/iter. ETA=0:01:56\n",
      "\u001b[32m[10/10 02:19:31 d2.evaluation.evaluator]: \u001b[0mInference done 2579/4871. Dataloading: 0.0015 s/iter. Inference: 0.0470 s/iter. Eval: 0.0003 s/iter. Total: 0.0489 s/iter. ETA=0:01:52\n",
      "\u001b[32m[10/10 02:19:36 d2.evaluation.evaluator]: \u001b[0mInference done 2679/4871. Dataloading: 0.0015 s/iter. Inference: 0.0471 s/iter. Eval: 0.0003 s/iter. Total: 0.0489 s/iter. ETA=0:01:47\n",
      "\u001b[32m[10/10 02:19:41 d2.evaluation.evaluator]: \u001b[0mInference done 2782/4871. Dataloading: 0.0015 s/iter. Inference: 0.0471 s/iter. Eval: 0.0003 s/iter. Total: 0.0489 s/iter. ETA=0:01:42\n",
      "\u001b[32m[10/10 02:19:46 d2.evaluation.evaluator]: \u001b[0mInference done 2883/4871. Dataloading: 0.0015 s/iter. Inference: 0.0471 s/iter. Eval: 0.0003 s/iter. Total: 0.0490 s/iter. ETA=0:01:37\n",
      "\u001b[32m[10/10 02:19:51 d2.evaluation.evaluator]: \u001b[0mInference done 2984/4871. Dataloading: 0.0015 s/iter. Inference: 0.0471 s/iter. Eval: 0.0003 s/iter. Total: 0.0490 s/iter. ETA=0:01:32\n",
      "\u001b[32m[10/10 02:19:56 d2.evaluation.evaluator]: \u001b[0mInference done 3079/4871. Dataloading: 0.0015 s/iter. Inference: 0.0472 s/iter. Eval: 0.0003 s/iter. Total: 0.0491 s/iter. ETA=0:01:27\n",
      "\u001b[32m[10/10 02:20:01 d2.evaluation.evaluator]: \u001b[0mInference done 3179/4871. Dataloading: 0.0015 s/iter. Inference: 0.0473 s/iter. Eval: 0.0003 s/iter. Total: 0.0491 s/iter. ETA=0:01:23\n",
      "\u001b[32m[10/10 02:20:06 d2.evaluation.evaluator]: \u001b[0mInference done 3281/4871. Dataloading: 0.0015 s/iter. Inference: 0.0473 s/iter. Eval: 0.0003 s/iter. Total: 0.0491 s/iter. ETA=0:01:18\n",
      "\u001b[32m[10/10 02:20:11 d2.evaluation.evaluator]: \u001b[0mInference done 3382/4871. Dataloading: 0.0016 s/iter. Inference: 0.0473 s/iter. Eval: 0.0003 s/iter. Total: 0.0492 s/iter. ETA=0:01:13\n",
      "\u001b[32m[10/10 02:20:17 d2.evaluation.evaluator]: \u001b[0mInference done 3483/4871. Dataloading: 0.0016 s/iter. Inference: 0.0473 s/iter. Eval: 0.0003 s/iter. Total: 0.0492 s/iter. ETA=0:01:08\n",
      "\u001b[32m[10/10 02:20:22 d2.evaluation.evaluator]: \u001b[0mInference done 3584/4871. Dataloading: 0.0016 s/iter. Inference: 0.0473 s/iter. Eval: 0.0003 s/iter. Total: 0.0492 s/iter. ETA=0:01:03\n",
      "\u001b[32m[10/10 02:20:27 d2.evaluation.evaluator]: \u001b[0mInference done 3683/4871. Dataloading: 0.0016 s/iter. Inference: 0.0473 s/iter. Eval: 0.0003 s/iter. Total: 0.0492 s/iter. ETA=0:00:58\n",
      "\u001b[32m[10/10 02:20:32 d2.evaluation.evaluator]: \u001b[0mInference done 3784/4871. Dataloading: 0.0016 s/iter. Inference: 0.0473 s/iter. Eval: 0.0003 s/iter. Total: 0.0492 s/iter. ETA=0:00:53\n",
      "\u001b[32m[10/10 02:20:37 d2.evaluation.evaluator]: \u001b[0mInference done 3884/4871. Dataloading: 0.0016 s/iter. Inference: 0.0474 s/iter. Eval: 0.0003 s/iter. Total: 0.0493 s/iter. ETA=0:00:48\n",
      "\u001b[32m[10/10 02:20:42 d2.evaluation.evaluator]: \u001b[0mInference done 3983/4871. Dataloading: 0.0016 s/iter. Inference: 0.0474 s/iter. Eval: 0.0003 s/iter. Total: 0.0493 s/iter. ETA=0:00:43\n",
      "\u001b[32m[10/10 02:20:47 d2.evaluation.evaluator]: \u001b[0mInference done 4084/4871. Dataloading: 0.0016 s/iter. Inference: 0.0474 s/iter. Eval: 0.0003 s/iter. Total: 0.0493 s/iter. ETA=0:00:38\n",
      "\u001b[32m[10/10 02:20:52 d2.evaluation.evaluator]: \u001b[0mInference done 4185/4871. Dataloading: 0.0016 s/iter. Inference: 0.0474 s/iter. Eval: 0.0003 s/iter. Total: 0.0493 s/iter. ETA=0:00:33\n",
      "\u001b[32m[10/10 02:20:57 d2.evaluation.evaluator]: \u001b[0mInference done 4281/4871. Dataloading: 0.0016 s/iter. Inference: 0.0475 s/iter. Eval: 0.0003 s/iter. Total: 0.0494 s/iter. ETA=0:00:29\n",
      "\u001b[32m[10/10 02:21:02 d2.evaluation.evaluator]: \u001b[0mInference done 4384/4871. Dataloading: 0.0016 s/iter. Inference: 0.0475 s/iter. Eval: 0.0003 s/iter. Total: 0.0494 s/iter. ETA=0:00:24\n",
      "\u001b[32m[10/10 02:21:07 d2.evaluation.evaluator]: \u001b[0mInference done 4489/4871. Dataloading: 0.0016 s/iter. Inference: 0.0475 s/iter. Eval: 0.0003 s/iter. Total: 0.0494 s/iter. ETA=0:00:18\n",
      "\u001b[32m[10/10 02:21:12 d2.evaluation.evaluator]: \u001b[0mInference done 4590/4871. Dataloading: 0.0016 s/iter. Inference: 0.0475 s/iter. Eval: 0.0003 s/iter. Total: 0.0494 s/iter. ETA=0:00:13\n",
      "\u001b[32m[10/10 02:21:17 d2.evaluation.evaluator]: \u001b[0mInference done 4693/4871. Dataloading: 0.0016 s/iter. Inference: 0.0474 s/iter. Eval: 0.0003 s/iter. Total: 0.0494 s/iter. ETA=0:00:08\n",
      "\u001b[32m[10/10 02:21:22 d2.evaluation.evaluator]: \u001b[0mInference done 4796/4871. Dataloading: 0.0016 s/iter. Inference: 0.0474 s/iter. Eval: 0.0003 s/iter. Total: 0.0494 s/iter. ETA=0:00:03\n",
      "\u001b[32m[10/10 02:21:26 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:04:00.104356 (0.049343 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/10 02:21:26 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:03:50 (0.047425 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/10 02:21:26 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/10 02:21:27 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output_eval/coco_instances_results.json\n",
      "\u001b[32m[10/10 02:21:27 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.65s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/10 02:21:28 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/10 02:21:30 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 2.04 seconds.\n",
      "\u001b[32m[10/10 02:21:30 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/10 02:21:30 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.25 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "\u001b[32m[10/10 02:21:30 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP  |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| nan  |  nan   |  nan   |  nan  |  nan  |  nan  |\n",
      "\u001b[32m[10/10 02:21:30 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[10/10 02:21:30 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category      | AP   | category    | AP   | category   | AP   |\n",
      "|:--------------|:-----|:------------|:-----|:-----------|:-----|\n",
      "| General trash | nan  | Paper       | nan  | Paper pack | nan  |\n",
      "| Metal         | nan  | Glass       | nan  | Plastic    | nan  |\n",
      "| Styrofoam     | nan  | Plastic bag | nan  | Battery    | nan  |\n",
      "| Clothing      | nan  |             |      |            |      |\n",
      "\u001b[32m[10/10 02:21:30 d2.engine.defaults]: \u001b[0mEvaluation results for coco_trash_test in csv format:\n",
      "\u001b[32m[10/10 02:21:30 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[10/10 02:21:30 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[10/10 02:21:30 d2.evaluation.testing]: \u001b[0mcopypaste: nan,nan,nan,nan,nan,nan\n",
      "\u001b[32m[10/10 02:21:31 d2.utils.events]: \u001b[0m eta: 1:12:37  iter: 5999  total_loss: 0.6685  loss_cls: 0.3386  loss_box_reg: 0.2868  loss_rpn_cls: 0.02116  loss_rpn_loc: 0.02376    time: 0.4844  last_time: 0.4889  data_time: 0.0151  last_data_time: 0.0154   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:21:43 d2.utils.events]: \u001b[0m eta: 1:12:28  iter: 6019  total_loss: 0.7458  loss_cls: 0.3839  loss_box_reg: 0.2699  loss_rpn_cls: 0.0208  loss_rpn_loc: 0.03376    time: 0.4844  last_time: 0.4803  data_time: 0.0167  last_data_time: 0.0168   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:21:55 d2.utils.events]: \u001b[0m eta: 1:12:18  iter: 6039  total_loss: 0.6525  loss_cls: 0.3349  loss_box_reg: 0.271  loss_rpn_cls: 0.02244  loss_rpn_loc: 0.01875    time: 0.4844  last_time: 0.4860  data_time: 0.0157  last_data_time: 0.0171   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:22:07 d2.utils.events]: \u001b[0m eta: 1:12:08  iter: 6059  total_loss: 0.6487  loss_cls: 0.3448  loss_box_reg: 0.2678  loss_rpn_cls: 0.01852  loss_rpn_loc: 0.0472    time: 0.4844  last_time: 0.4901  data_time: 0.0152  last_data_time: 0.0151   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:22:19 d2.utils.events]: \u001b[0m eta: 1:11:59  iter: 6079  total_loss: 0.591  loss_cls: 0.3291  loss_box_reg: 0.2336  loss_rpn_cls: 0.01274  loss_rpn_loc: 0.0169    time: 0.4844  last_time: 0.4796  data_time: 0.0153  last_data_time: 0.0145   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:22:31 d2.utils.events]: \u001b[0m eta: 1:11:50  iter: 6099  total_loss: 0.652  loss_cls: 0.3163  loss_box_reg: 0.259  loss_rpn_cls: 0.01359  loss_rpn_loc: 0.01978    time: 0.4844  last_time: 0.4872  data_time: 0.0153  last_data_time: 0.0202   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:22:43 d2.utils.events]: \u001b[0m eta: 1:11:40  iter: 6119  total_loss: 0.586  loss_cls: 0.2824  loss_box_reg: 0.2357  loss_rpn_cls: 0.01325  loss_rpn_loc: 0.01979    time: 0.4844  last_time: 0.4851  data_time: 0.0165  last_data_time: 0.0151   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:22:55 d2.utils.events]: \u001b[0m eta: 1:11:30  iter: 6139  total_loss: 0.5575  loss_cls: 0.2957  loss_box_reg: 0.2158  loss_rpn_cls: 0.01346  loss_rpn_loc: 0.01597    time: 0.4844  last_time: 0.4818  data_time: 0.0155  last_data_time: 0.0147   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:23:08 d2.utils.events]: \u001b[0m eta: 1:11:21  iter: 6159  total_loss: 0.6272  loss_cls: 0.3058  loss_box_reg: 0.2648  loss_rpn_cls: 0.01587  loss_rpn_loc: 0.02365    time: 0.4844  last_time: 0.4889  data_time: 0.0167  last_data_time: 0.0151   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:23:20 d2.utils.events]: \u001b[0m eta: 1:11:11  iter: 6179  total_loss: 0.5511  loss_cls: 0.3101  loss_box_reg: 0.2212  loss_rpn_cls: 0.01354  loss_rpn_loc: 0.0204    time: 0.4844  last_time: 0.4882  data_time: 0.0158  last_data_time: 0.0184   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:23:32 d2.utils.events]: \u001b[0m eta: 1:11:01  iter: 6199  total_loss: 0.7218  loss_cls: 0.3888  loss_box_reg: 0.2563  loss_rpn_cls: 0.0191  loss_rpn_loc: 0.02742    time: 0.4844  last_time: 0.4872  data_time: 0.0180  last_data_time: 0.0168   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:23:44 d2.utils.events]: \u001b[0m eta: 1:10:51  iter: 6219  total_loss: 0.5891  loss_cls: 0.3022  loss_box_reg: 0.242  loss_rpn_cls: 0.01508  loss_rpn_loc: 0.01935    time: 0.4844  last_time: 0.4829  data_time: 0.0158  last_data_time: 0.0146   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:23:56 d2.utils.events]: \u001b[0m eta: 1:10:41  iter: 6239  total_loss: 0.5042  loss_cls: 0.2848  loss_box_reg: 0.1968  loss_rpn_cls: 0.01428  loss_rpn_loc: 0.02654    time: 0.4844  last_time: 0.4886  data_time: 0.0161  last_data_time: 0.0200   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:24:08 d2.utils.events]: \u001b[0m eta: 1:10:31  iter: 6259  total_loss: 0.5696  loss_cls: 0.2969  loss_box_reg: 0.2288  loss_rpn_cls: 0.009033  loss_rpn_loc: 0.03394    time: 0.4844  last_time: 0.4846  data_time: 0.0158  last_data_time: 0.0157   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:24:20 d2.utils.events]: \u001b[0m eta: 1:10:21  iter: 6279  total_loss: 0.6224  loss_cls: 0.3374  loss_box_reg: 0.2421  loss_rpn_cls: 0.01917  loss_rpn_loc: 0.03166    time: 0.4844  last_time: 0.4895  data_time: 0.0164  last_data_time: 0.0191   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:24:33 d2.utils.events]: \u001b[0m eta: 1:10:12  iter: 6299  total_loss: 0.6623  loss_cls: 0.339  loss_box_reg: 0.2962  loss_rpn_cls: 0.01358  loss_rpn_loc: 0.03023    time: 0.4844  last_time: 0.4837  data_time: 0.0161  last_data_time: 0.0150   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:24:45 d2.utils.events]: \u001b[0m eta: 1:10:02  iter: 6319  total_loss: 0.5859  loss_cls: 0.2992  loss_box_reg: 0.2615  loss_rpn_cls: 0.01659  loss_rpn_loc: 0.02626    time: 0.4845  last_time: 0.4897  data_time: 0.0166  last_data_time: 0.0192   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:24:57 d2.utils.events]: \u001b[0m eta: 1:09:53  iter: 6339  total_loss: 0.7435  loss_cls: 0.3685  loss_box_reg: 0.2974  loss_rpn_cls: 0.01608  loss_rpn_loc: 0.03106    time: 0.4845  last_time: 0.4854  data_time: 0.0166  last_data_time: 0.0173   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:25:09 d2.utils.events]: \u001b[0m eta: 1:09:43  iter: 6359  total_loss: 0.6186  loss_cls: 0.3505  loss_box_reg: 0.2297  loss_rpn_cls: 0.01362  loss_rpn_loc: 0.01759    time: 0.4845  last_time: 0.4868  data_time: 0.0159  last_data_time: 0.0185   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:25:21 d2.utils.events]: \u001b[0m eta: 1:09:34  iter: 6379  total_loss: 0.669  loss_cls: 0.3265  loss_box_reg: 0.2572  loss_rpn_cls: 0.01441  loss_rpn_loc: 0.02436    time: 0.4845  last_time: 0.4834  data_time: 0.0164  last_data_time: 0.0155   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:25:33 d2.utils.events]: \u001b[0m eta: 1:09:24  iter: 6399  total_loss: 0.6139  loss_cls: 0.3367  loss_box_reg: 0.2227  loss_rpn_cls: 0.007744  loss_rpn_loc: 0.02161    time: 0.4845  last_time: 0.4846  data_time: 0.0162  last_data_time: 0.0150   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:25:45 d2.utils.events]: \u001b[0m eta: 1:09:15  iter: 6419  total_loss: 0.5149  loss_cls: 0.2794  loss_box_reg: 0.1957  loss_rpn_cls: 0.009991  loss_rpn_loc: 0.01111    time: 0.4845  last_time: 0.4839  data_time: 0.0155  last_data_time: 0.0148   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:25:57 d2.utils.events]: \u001b[0m eta: 1:09:05  iter: 6439  total_loss: 0.6896  loss_cls: 0.3855  loss_box_reg: 0.2694  loss_rpn_cls: 0.01503  loss_rpn_loc: 0.02239    time: 0.4845  last_time: 0.4840  data_time: 0.0165  last_data_time: 0.0151   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:26:10 d2.utils.events]: \u001b[0m eta: 1:08:55  iter: 6459  total_loss: 0.5861  loss_cls: 0.2828  loss_box_reg: 0.2452  loss_rpn_cls: 0.01333  loss_rpn_loc: 0.01633    time: 0.4845  last_time: 0.4882  data_time: 0.0180  last_data_time: 0.0163   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:26:22 d2.utils.events]: \u001b[0m eta: 1:08:46  iter: 6479  total_loss: 0.6031  loss_cls: 0.3306  loss_box_reg: 0.2122  loss_rpn_cls: 0.01168  loss_rpn_loc: 0.02178    time: 0.4845  last_time: 0.4840  data_time: 0.0158  last_data_time: 0.0151   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:26:34 d2.utils.events]: \u001b[0m eta: 1:08:36  iter: 6499  total_loss: 0.5342  loss_cls: 0.2717  loss_box_reg: 0.2004  loss_rpn_cls: 0.007371  loss_rpn_loc: 0.01815    time: 0.4845  last_time: 0.4839  data_time: 0.0167  last_data_time: 0.0152   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:26:46 d2.utils.events]: \u001b[0m eta: 1:08:27  iter: 6519  total_loss: 0.5764  loss_cls: 0.2775  loss_box_reg: 0.2539  loss_rpn_cls: 0.01179  loss_rpn_loc: 0.02374    time: 0.4845  last_time: 0.4794  data_time: 0.0152  last_data_time: 0.0146   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:26:58 d2.utils.events]: \u001b[0m eta: 1:08:17  iter: 6539  total_loss: 0.5531  loss_cls: 0.3197  loss_box_reg: 0.1993  loss_rpn_cls: 0.01271  loss_rpn_loc: 0.02105    time: 0.4845  last_time: 0.4835  data_time: 0.0163  last_data_time: 0.0153   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:27:10 d2.utils.events]: \u001b[0m eta: 1:08:08  iter: 6559  total_loss: 0.5472  loss_cls: 0.3306  loss_box_reg: 0.209  loss_rpn_cls: 0.009253  loss_rpn_loc: 0.01452    time: 0.4845  last_time: 0.4805  data_time: 0.0153  last_data_time: 0.0150   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:27:22 d2.utils.events]: \u001b[0m eta: 1:07:57  iter: 6579  total_loss: 0.6385  loss_cls: 0.3202  loss_box_reg: 0.235  loss_rpn_cls: 0.02144  loss_rpn_loc: 0.03409    time: 0.4845  last_time: 0.4783  data_time: 0.0155  last_data_time: 0.0146   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:27:34 d2.utils.events]: \u001b[0m eta: 1:07:48  iter: 6599  total_loss: 0.6293  loss_cls: 0.3192  loss_box_reg: 0.2492  loss_rpn_cls: 0.0161  loss_rpn_loc: 0.03396    time: 0.4845  last_time: 0.4844  data_time: 0.0163  last_data_time: 0.0157   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:27:46 d2.utils.events]: \u001b[0m eta: 1:07:38  iter: 6619  total_loss: 0.5715  loss_cls: 0.2942  loss_box_reg: 0.2113  loss_rpn_cls: 0.009442  loss_rpn_loc: 0.02308    time: 0.4845  last_time: 0.4845  data_time: 0.0165  last_data_time: 0.0171   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:27:59 d2.utils.events]: \u001b[0m eta: 1:07:28  iter: 6639  total_loss: 0.6331  loss_cls: 0.3196  loss_box_reg: 0.2614  loss_rpn_cls: 0.02064  loss_rpn_loc: 0.02568    time: 0.4845  last_time: 0.4835  data_time: 0.0162  last_data_time: 0.0149   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:28:11 d2.utils.events]: \u001b[0m eta: 1:07:18  iter: 6659  total_loss: 0.5801  loss_cls: 0.2881  loss_box_reg: 0.2469  loss_rpn_cls: 0.01456  loss_rpn_loc: 0.02455    time: 0.4845  last_time: 0.4827  data_time: 0.0157  last_data_time: 0.0151   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:28:23 d2.utils.events]: \u001b[0m eta: 1:07:09  iter: 6679  total_loss: 0.6568  loss_cls: 0.3485  loss_box_reg: 0.2386  loss_rpn_cls: 0.01847  loss_rpn_loc: 0.03539    time: 0.4845  last_time: 0.4843  data_time: 0.0163  last_data_time: 0.0188   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:28:35 d2.utils.events]: \u001b[0m eta: 1:06:59  iter: 6699  total_loss: 0.6259  loss_cls: 0.2682  loss_box_reg: 0.2219  loss_rpn_cls: 0.01477  loss_rpn_loc: 0.02262    time: 0.4845  last_time: 0.4836  data_time: 0.0154  last_data_time: 0.0145   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:28:47 d2.utils.events]: \u001b[0m eta: 1:06:50  iter: 6719  total_loss: 0.5025  loss_cls: 0.2849  loss_box_reg: 0.2025  loss_rpn_cls: 0.01379  loss_rpn_loc: 0.02207    time: 0.4845  last_time: 0.4814  data_time: 0.0168  last_data_time: 0.0148   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:28:59 d2.utils.events]: \u001b[0m eta: 1:06:40  iter: 6739  total_loss: 0.7444  loss_cls: 0.3699  loss_box_reg: 0.2865  loss_rpn_cls: 0.01728  loss_rpn_loc: 0.02963    time: 0.4845  last_time: 0.4849  data_time: 0.0166  last_data_time: 0.0157   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:29:11 d2.utils.events]: \u001b[0m eta: 1:06:31  iter: 6759  total_loss: 0.5004  loss_cls: 0.3098  loss_box_reg: 0.1968  loss_rpn_cls: 0.00843  loss_rpn_loc: 0.01206    time: 0.4845  last_time: 0.4837  data_time: 0.0172  last_data_time: 0.0158   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:29:23 d2.utils.events]: \u001b[0m eta: 1:06:21  iter: 6779  total_loss: 0.5908  loss_cls: 0.3387  loss_box_reg: 0.2603  loss_rpn_cls: 0.01007  loss_rpn_loc: 0.02328    time: 0.4845  last_time: 0.4875  data_time: 0.0175  last_data_time: 0.0183   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:29:36 d2.utils.events]: \u001b[0m eta: 1:06:12  iter: 6799  total_loss: 0.6516  loss_cls: 0.3316  loss_box_reg: 0.2774  loss_rpn_cls: 0.0203  loss_rpn_loc: 0.03022    time: 0.4845  last_time: 0.4872  data_time: 0.0168  last_data_time: 0.0152   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:29:48 d2.utils.events]: \u001b[0m eta: 1:06:02  iter: 6819  total_loss: 0.5397  loss_cls: 0.2779  loss_box_reg: 0.2217  loss_rpn_cls: 0.01338  loss_rpn_loc: 0.01751    time: 0.4845  last_time: 0.4835  data_time: 0.0161  last_data_time: 0.0155   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:30:00 d2.utils.events]: \u001b[0m eta: 1:05:52  iter: 6839  total_loss: 0.5397  loss_cls: 0.2671  loss_box_reg: 0.2294  loss_rpn_cls: 0.01257  loss_rpn_loc: 0.02145    time: 0.4845  last_time: 0.4817  data_time: 0.0166  last_data_time: 0.0177   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:30:12 d2.utils.events]: \u001b[0m eta: 1:05:43  iter: 6859  total_loss: 0.6336  loss_cls: 0.279  loss_box_reg: 0.2608  loss_rpn_cls: 0.01726  loss_rpn_loc: 0.02844    time: 0.4845  last_time: 0.4825  data_time: 0.0163  last_data_time: 0.0153   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:30:24 d2.utils.events]: \u001b[0m eta: 1:05:34  iter: 6879  total_loss: 0.6649  loss_cls: 0.3471  loss_box_reg: 0.2572  loss_rpn_cls: 0.02193  loss_rpn_loc: 0.02683    time: 0.4845  last_time: 0.4885  data_time: 0.0169  last_data_time: 0.0195   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:30:36 d2.utils.events]: \u001b[0m eta: 1:05:25  iter: 6899  total_loss: 0.5895  loss_cls: 0.3001  loss_box_reg: 0.2304  loss_rpn_cls: 0.01095  loss_rpn_loc: 0.01874    time: 0.4845  last_time: 0.4811  data_time: 0.0165  last_data_time: 0.0149   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:30:48 d2.utils.events]: \u001b[0m eta: 1:05:15  iter: 6919  total_loss: 0.6401  loss_cls: 0.3827  loss_box_reg: 0.2433  loss_rpn_cls: 0.0142  loss_rpn_loc: 0.01581    time: 0.4845  last_time: 0.4947  data_time: 0.0168  last_data_time: 0.0159   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:31:01 d2.utils.events]: \u001b[0m eta: 1:05:05  iter: 6939  total_loss: 0.536  loss_cls: 0.2642  loss_box_reg: 0.2224  loss_rpn_cls: 0.01292  loss_rpn_loc: 0.01458    time: 0.4845  last_time: 0.4972  data_time: 0.0159  last_data_time: 0.0273   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:31:13 d2.utils.events]: \u001b[0m eta: 1:04:55  iter: 6959  total_loss: 0.5819  loss_cls: 0.3364  loss_box_reg: 0.2227  loss_rpn_cls: 0.0141  loss_rpn_loc: 0.02428    time: 0.4845  last_time: 0.4832  data_time: 0.0159  last_data_time: 0.0148   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:31:25 d2.utils.events]: \u001b[0m eta: 1:04:45  iter: 6979  total_loss: 0.5411  loss_cls: 0.2869  loss_box_reg: 0.2241  loss_rpn_cls: 0.01495  loss_rpn_loc: 0.0215    time: 0.4845  last_time: 0.4882  data_time: 0.0155  last_data_time: 0.0181   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:31:37 d2.utils.events]: \u001b[0m eta: 1:04:36  iter: 6999  total_loss: 0.7037  loss_cls: 0.346  loss_box_reg: 0.2974  loss_rpn_cls: 0.01889  loss_rpn_loc: 0.0218    time: 0.4845  last_time: 0.4901  data_time: 0.0167  last_data_time: 0.0212   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:31:49 d2.utils.events]: \u001b[0m eta: 1:04:26  iter: 7019  total_loss: 0.6382  loss_cls: 0.3427  loss_box_reg: 0.2382  loss_rpn_cls: 0.0172  loss_rpn_loc: 0.01854    time: 0.4845  last_time: 0.4832  data_time: 0.0163  last_data_time: 0.0149   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:32:01 d2.utils.events]: \u001b[0m eta: 1:04:16  iter: 7039  total_loss: 0.5872  loss_cls: 0.3025  loss_box_reg: 0.2226  loss_rpn_cls: 0.01269  loss_rpn_loc: 0.02186    time: 0.4845  last_time: 0.4862  data_time: 0.0156  last_data_time: 0.0172   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:32:13 d2.utils.events]: \u001b[0m eta: 1:04:06  iter: 7059  total_loss: 0.651  loss_cls: 0.3424  loss_box_reg: 0.2478  loss_rpn_cls: 0.01687  loss_rpn_loc: 0.03123    time: 0.4845  last_time: 0.4875  data_time: 0.0170  last_data_time: 0.0215   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:32:25 d2.utils.events]: \u001b[0m eta: 1:03:56  iter: 7079  total_loss: 0.5594  loss_cls: 0.3095  loss_box_reg: 0.1912  loss_rpn_cls: 0.01448  loss_rpn_loc: 0.02596    time: 0.4845  last_time: 0.4861  data_time: 0.0160  last_data_time: 0.0171   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:32:37 d2.utils.events]: \u001b[0m eta: 1:03:46  iter: 7099  total_loss: 0.6131  loss_cls: 0.3381  loss_box_reg: 0.1931  loss_rpn_cls: 0.01417  loss_rpn_loc: 0.01925    time: 0.4845  last_time: 0.4858  data_time: 0.0156  last_data_time: 0.0147   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:32:50 d2.utils.events]: \u001b[0m eta: 1:03:37  iter: 7119  total_loss: 0.5973  loss_cls: 0.3118  loss_box_reg: 0.2123  loss_rpn_cls: 0.01855  loss_rpn_loc: 0.03184    time: 0.4845  last_time: 0.4869  data_time: 0.0161  last_data_time: 0.0148   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:33:02 d2.utils.events]: \u001b[0m eta: 1:03:27  iter: 7139  total_loss: 0.5832  loss_cls: 0.284  loss_box_reg: 0.2393  loss_rpn_cls: 0.01925  loss_rpn_loc: 0.01868    time: 0.4845  last_time: 0.4816  data_time: 0.0163  last_data_time: 0.0146   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:33:14 d2.utils.events]: \u001b[0m eta: 1:03:17  iter: 7159  total_loss: 0.5443  loss_cls: 0.2864  loss_box_reg: 0.2021  loss_rpn_cls: 0.01152  loss_rpn_loc: 0.02243    time: 0.4845  last_time: 0.4864  data_time: 0.0162  last_data_time: 0.0163   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:33:26 d2.utils.events]: \u001b[0m eta: 1:03:08  iter: 7179  total_loss: 0.6561  loss_cls: 0.3364  loss_box_reg: 0.2399  loss_rpn_cls: 0.0222  loss_rpn_loc: 0.02982    time: 0.4845  last_time: 0.4782  data_time: 0.0153  last_data_time: 0.0147   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:33:38 d2.utils.events]: \u001b[0m eta: 1:02:58  iter: 7199  total_loss: 0.5693  loss_cls: 0.3068  loss_box_reg: 0.2635  loss_rpn_cls: 0.01707  loss_rpn_loc: 0.02076    time: 0.4845  last_time: 0.4930  data_time: 0.0158  last_data_time: 0.0171   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:33:50 d2.utils.events]: \u001b[0m eta: 1:02:48  iter: 7219  total_loss: 0.5722  loss_cls: 0.303  loss_box_reg: 0.232  loss_rpn_cls: 0.01302  loss_rpn_loc: 0.01472    time: 0.4845  last_time: 0.4835  data_time: 0.0166  last_data_time: 0.0167   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:34:02 d2.utils.events]: \u001b[0m eta: 1:02:39  iter: 7239  total_loss: 0.5593  loss_cls: 0.2767  loss_box_reg: 0.251  loss_rpn_cls: 0.01494  loss_rpn_loc: 0.02008    time: 0.4845  last_time: 0.4844  data_time: 0.0170  last_data_time: 0.0168   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:34:14 d2.utils.events]: \u001b[0m eta: 1:02:29  iter: 7259  total_loss: 0.6768  loss_cls: 0.3222  loss_box_reg: 0.2656  loss_rpn_cls: 0.02016  loss_rpn_loc: 0.02887    time: 0.4845  last_time: 0.4838  data_time: 0.0160  last_data_time: 0.0149   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:34:26 d2.utils.events]: \u001b[0m eta: 1:02:19  iter: 7279  total_loss: 0.5727  loss_cls: 0.3381  loss_box_reg: 0.2253  loss_rpn_cls: 0.0129  loss_rpn_loc: 0.02836    time: 0.4845  last_time: 0.4875  data_time: 0.0159  last_data_time: 0.0167   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:34:39 d2.utils.events]: \u001b[0m eta: 1:02:10  iter: 7299  total_loss: 0.633  loss_cls: 0.2949  loss_box_reg: 0.285  loss_rpn_cls: 0.01644  loss_rpn_loc: 0.03192    time: 0.4845  last_time: 0.4830  data_time: 0.0169  last_data_time: 0.0165   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:34:51 d2.utils.events]: \u001b[0m eta: 1:02:00  iter: 7319  total_loss: 0.6622  loss_cls: 0.3225  loss_box_reg: 0.2608  loss_rpn_cls: 0.01929  loss_rpn_loc: 0.02798    time: 0.4845  last_time: 0.4881  data_time: 0.0154  last_data_time: 0.0150   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:35:03 d2.utils.events]: \u001b[0m eta: 1:01:50  iter: 7339  total_loss: 0.5472  loss_cls: 0.2645  loss_box_reg: 0.2329  loss_rpn_cls: 0.01649  loss_rpn_loc: 0.02698    time: 0.4845  last_time: 0.4879  data_time: 0.0164  last_data_time: 0.0144   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:35:15 d2.utils.events]: \u001b[0m eta: 1:01:40  iter: 7359  total_loss: 0.5778  loss_cls: 0.3094  loss_box_reg: 0.2238  loss_rpn_cls: 0.01305  loss_rpn_loc: 0.0213    time: 0.4845  last_time: 0.4841  data_time: 0.0158  last_data_time: 0.0156   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:35:27 d2.utils.events]: \u001b[0m eta: 1:01:31  iter: 7379  total_loss: 0.5589  loss_cls: 0.2976  loss_box_reg: 0.2232  loss_rpn_cls: 0.01207  loss_rpn_loc: 0.02227    time: 0.4845  last_time: 0.4807  data_time: 0.0153  last_data_time: 0.0159   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:35:39 d2.utils.events]: \u001b[0m eta: 1:01:21  iter: 7399  total_loss: 0.6372  loss_cls: 0.3314  loss_box_reg: 0.2754  loss_rpn_cls: 0.01457  loss_rpn_loc: 0.02178    time: 0.4845  last_time: 0.4823  data_time: 0.0158  last_data_time: 0.0145   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:35:51 d2.utils.events]: \u001b[0m eta: 1:01:11  iter: 7419  total_loss: 0.6343  loss_cls: 0.3364  loss_box_reg: 0.2681  loss_rpn_cls: 0.01666  loss_rpn_loc: 0.04078    time: 0.4845  last_time: 0.4947  data_time: 0.0175  last_data_time: 0.0259   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:36:03 d2.utils.events]: \u001b[0m eta: 1:01:01  iter: 7439  total_loss: 0.6197  loss_cls: 0.3006  loss_box_reg: 0.2474  loss_rpn_cls: 0.01463  loss_rpn_loc: 0.02881    time: 0.4845  last_time: 0.4845  data_time: 0.0169  last_data_time: 0.0206   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:36:16 d2.utils.events]: \u001b[0m eta: 1:00:52  iter: 7459  total_loss: 0.5815  loss_cls: 0.2809  loss_box_reg: 0.2116  loss_rpn_cls: 0.009  loss_rpn_loc: 0.01774    time: 0.4845  last_time: 0.4845  data_time: 0.0177  last_data_time: 0.0150   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:36:28 d2.utils.events]: \u001b[0m eta: 1:00:42  iter: 7479  total_loss: 0.6087  loss_cls: 0.3376  loss_box_reg: 0.2542  loss_rpn_cls: 0.008999  loss_rpn_loc: 0.01369    time: 0.4845  last_time: 0.4846  data_time: 0.0170  last_data_time: 0.0145   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:36:40 d2.utils.events]: \u001b[0m eta: 1:00:32  iter: 7499  total_loss: 0.6276  loss_cls: 0.2875  loss_box_reg: 0.277  loss_rpn_cls: 0.01621  loss_rpn_loc: 0.03614    time: 0.4845  last_time: 0.4831  data_time: 0.0153  last_data_time: 0.0143   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:36:52 d2.utils.events]: \u001b[0m eta: 1:00:23  iter: 7519  total_loss: 0.4665  loss_cls: 0.2222  loss_box_reg: 0.1795  loss_rpn_cls: 0.01222  loss_rpn_loc: 0.01333    time: 0.4846  last_time: 0.4826  data_time: 0.0184  last_data_time: 0.0162   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:37:04 d2.utils.events]: \u001b[0m eta: 1:00:13  iter: 7539  total_loss: 0.6663  loss_cls: 0.3291  loss_box_reg: 0.2884  loss_rpn_cls: 0.01959  loss_rpn_loc: 0.02804    time: 0.4846  last_time: 0.4843  data_time: 0.0173  last_data_time: 0.0162   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:37:16 d2.utils.events]: \u001b[0m eta: 1:00:03  iter: 7559  total_loss: 0.6852  loss_cls: 0.3426  loss_box_reg: 0.2711  loss_rpn_cls: 0.01495  loss_rpn_loc: 0.0316    time: 0.4846  last_time: 0.4876  data_time: 0.0164  last_data_time: 0.0163   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:37:28 d2.utils.events]: \u001b[0m eta: 0:59:54  iter: 7579  total_loss: 0.6222  loss_cls: 0.3185  loss_box_reg: 0.2225  loss_rpn_cls: 0.01435  loss_rpn_loc: 0.02263    time: 0.4846  last_time: 0.4928  data_time: 0.0173  last_data_time: 0.0257   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:37:40 d2.utils.events]: \u001b[0m eta: 0:59:44  iter: 7599  total_loss: 0.498  loss_cls: 0.2663  loss_box_reg: 0.2484  loss_rpn_cls: 0.01146  loss_rpn_loc: 0.02786    time: 0.4846  last_time: 0.4800  data_time: 0.0154  last_data_time: 0.0144   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:37:53 d2.utils.events]: \u001b[0m eta: 0:59:34  iter: 7619  total_loss: 0.5063  loss_cls: 0.2367  loss_box_reg: 0.2045  loss_rpn_cls: 0.01275  loss_rpn_loc: 0.02699    time: 0.4846  last_time: 0.4825  data_time: 0.0158  last_data_time: 0.0165   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:38:05 d2.utils.events]: \u001b[0m eta: 0:59:25  iter: 7639  total_loss: 0.6225  loss_cls: 0.2952  loss_box_reg: 0.2284  loss_rpn_cls: 0.01258  loss_rpn_loc: 0.0221    time: 0.4846  last_time: 0.4882  data_time: 0.0167  last_data_time: 0.0183   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:38:17 d2.utils.events]: \u001b[0m eta: 0:59:15  iter: 7659  total_loss: 0.5175  loss_cls: 0.3093  loss_box_reg: 0.2219  loss_rpn_cls: 0.01433  loss_rpn_loc: 0.01701    time: 0.4846  last_time: 0.4859  data_time: 0.0156  last_data_time: 0.0141   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:38:29 d2.utils.events]: \u001b[0m eta: 0:59:06  iter: 7679  total_loss: 0.553  loss_cls: 0.2823  loss_box_reg: 0.2227  loss_rpn_cls: 0.01229  loss_rpn_loc: 0.01541    time: 0.4846  last_time: 0.4819  data_time: 0.0157  last_data_time: 0.0144   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:38:41 d2.utils.events]: \u001b[0m eta: 0:58:56  iter: 7699  total_loss: 0.5427  loss_cls: 0.2833  loss_box_reg: 0.2387  loss_rpn_cls: 0.01223  loss_rpn_loc: 0.01341    time: 0.4846  last_time: 0.4874  data_time: 0.0164  last_data_time: 0.0169   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:38:53 d2.utils.events]: \u001b[0m eta: 0:58:46  iter: 7719  total_loss: 0.5722  loss_cls: 0.2729  loss_box_reg: 0.259  loss_rpn_cls: 0.02144  loss_rpn_loc: 0.02482    time: 0.4846  last_time: 0.4851  data_time: 0.0168  last_data_time: 0.0184   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:39:05 d2.utils.events]: \u001b[0m eta: 0:58:37  iter: 7739  total_loss: 0.6665  loss_cls: 0.3447  loss_box_reg: 0.2397  loss_rpn_cls: 0.01766  loss_rpn_loc: 0.03095    time: 0.4846  last_time: 0.4790  data_time: 0.0158  last_data_time: 0.0147   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:39:17 d2.utils.events]: \u001b[0m eta: 0:58:27  iter: 7759  total_loss: 0.584  loss_cls: 0.366  loss_box_reg: 0.2182  loss_rpn_cls: 0.0138  loss_rpn_loc: 0.01427    time: 0.4846  last_time: 0.4872  data_time: 0.0156  last_data_time: 0.0171   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:39:30 d2.utils.events]: \u001b[0m eta: 0:58:17  iter: 7779  total_loss: 0.4827  loss_cls: 0.2571  loss_box_reg: 0.2048  loss_rpn_cls: 0.01126  loss_rpn_loc: 0.02139    time: 0.4846  last_time: 0.4850  data_time: 0.0178  last_data_time: 0.0160   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:39:42 d2.utils.events]: \u001b[0m eta: 0:58:07  iter: 7799  total_loss: 0.5537  loss_cls: 0.274  loss_box_reg: 0.2396  loss_rpn_cls: 0.01761  loss_rpn_loc: 0.02967    time: 0.4846  last_time: 0.4836  data_time: 0.0153  last_data_time: 0.0157   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:39:54 d2.utils.events]: \u001b[0m eta: 0:57:57  iter: 7819  total_loss: 0.5742  loss_cls: 0.3023  loss_box_reg: 0.2151  loss_rpn_cls: 0.01163  loss_rpn_loc: 0.02279    time: 0.4846  last_time: 0.4796  data_time: 0.0166  last_data_time: 0.0147   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:40:06 d2.utils.events]: \u001b[0m eta: 0:57:48  iter: 7839  total_loss: 0.5659  loss_cls: 0.3088  loss_box_reg: 0.2223  loss_rpn_cls: 0.02027  loss_rpn_loc: 0.03066    time: 0.4846  last_time: 0.4841  data_time: 0.0158  last_data_time: 0.0152   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:40:18 d2.utils.events]: \u001b[0m eta: 0:57:38  iter: 7859  total_loss: 0.5118  loss_cls: 0.262  loss_box_reg: 0.193  loss_rpn_cls: 0.01282  loss_rpn_loc: 0.02177    time: 0.4846  last_time: 0.4857  data_time: 0.0160  last_data_time: 0.0150   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:40:30 d2.utils.events]: \u001b[0m eta: 0:57:29  iter: 7879  total_loss: 0.6252  loss_cls: 0.3218  loss_box_reg: 0.2585  loss_rpn_cls: 0.01512  loss_rpn_loc: 0.0325    time: 0.4846  last_time: 0.4943  data_time: 0.0162  last_data_time: 0.0152   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:40:42 d2.utils.events]: \u001b[0m eta: 0:57:19  iter: 7899  total_loss: 0.5389  loss_cls: 0.2805  loss_box_reg: 0.2022  loss_rpn_cls: 0.01138  loss_rpn_loc: 0.0211    time: 0.4846  last_time: 0.4882  data_time: 0.0151  last_data_time: 0.0175   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:40:55 d2.utils.events]: \u001b[0m eta: 0:57:09  iter: 7919  total_loss: 0.6011  loss_cls: 0.2902  loss_box_reg: 0.2281  loss_rpn_cls: 0.01662  loss_rpn_loc: 0.02743    time: 0.4846  last_time: 0.4869  data_time: 0.0174  last_data_time: 0.0149   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:41:07 d2.utils.events]: \u001b[0m eta: 0:57:00  iter: 7939  total_loss: 0.5905  loss_cls: 0.2857  loss_box_reg: 0.2365  loss_rpn_cls: 0.01321  loss_rpn_loc: 0.0322    time: 0.4846  last_time: 0.4821  data_time: 0.0174  last_data_time: 0.0144   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:41:19 d2.utils.events]: \u001b[0m eta: 0:56:50  iter: 7959  total_loss: 0.4487  loss_cls: 0.2281  loss_box_reg: 0.2217  loss_rpn_cls: 0.01471  loss_rpn_loc: 0.01507    time: 0.4846  last_time: 0.4846  data_time: 0.0153  last_data_time: 0.0152   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:41:31 d2.utils.events]: \u001b[0m eta: 0:56:40  iter: 7979  total_loss: 0.5784  loss_cls: 0.3034  loss_box_reg: 0.1999  loss_rpn_cls: 0.01449  loss_rpn_loc: 0.02111    time: 0.4846  last_time: 0.4817  data_time: 0.0166  last_data_time: 0.0145   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:41:43 d2.utils.events]: \u001b[0m eta: 0:56:31  iter: 7999  total_loss: 0.4822  loss_cls: 0.2454  loss_box_reg: 0.1995  loss_rpn_cls: 0.006566  loss_rpn_loc: 0.01114    time: 0.4846  last_time: 0.4826  data_time: 0.0159  last_data_time: 0.0146   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:41:55 d2.utils.events]: \u001b[0m eta: 0:56:21  iter: 8019  total_loss: 0.6026  loss_cls: 0.3303  loss_box_reg: 0.2016  loss_rpn_cls: 0.01531  loss_rpn_loc: 0.03895    time: 0.4846  last_time: 0.4834  data_time: 0.0162  last_data_time: 0.0144   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:42:07 d2.utils.events]: \u001b[0m eta: 0:56:12  iter: 8039  total_loss: 0.6172  loss_cls: 0.2956  loss_box_reg: 0.2486  loss_rpn_cls: 0.01592  loss_rpn_loc: 0.0263    time: 0.4846  last_time: 0.4813  data_time: 0.0157  last_data_time: 0.0146   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:42:19 d2.utils.events]: \u001b[0m eta: 0:56:02  iter: 8059  total_loss: 0.6688  loss_cls: 0.3296  loss_box_reg: 0.2665  loss_rpn_cls: 0.01479  loss_rpn_loc: 0.03143    time: 0.4846  last_time: 0.4853  data_time: 0.0159  last_data_time: 0.0149   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:42:31 d2.utils.events]: \u001b[0m eta: 0:55:52  iter: 8079  total_loss: 0.581  loss_cls: 0.2848  loss_box_reg: 0.2274  loss_rpn_cls: 0.01108  loss_rpn_loc: 0.01518    time: 0.4846  last_time: 0.4852  data_time: 0.0157  last_data_time: 0.0145   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:42:44 d2.utils.events]: \u001b[0m eta: 0:55:42  iter: 8099  total_loss: 0.4737  loss_cls: 0.2471  loss_box_reg: 0.1977  loss_rpn_cls: 0.009689  loss_rpn_loc: 0.02498    time: 0.4846  last_time: 0.4792  data_time: 0.0161  last_data_time: 0.0145   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:42:56 d2.utils.events]: \u001b[0m eta: 0:55:33  iter: 8119  total_loss: 0.5877  loss_cls: 0.3132  loss_box_reg: 0.2201  loss_rpn_cls: 0.01558  loss_rpn_loc: 0.0254    time: 0.4846  last_time: 0.4826  data_time: 0.0164  last_data_time: 0.0157   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:43:08 d2.utils.events]: \u001b[0m eta: 0:55:23  iter: 8139  total_loss: 0.5823  loss_cls: 0.3124  loss_box_reg: 0.2335  loss_rpn_cls: 0.01167  loss_rpn_loc: 0.02756    time: 0.4846  last_time: 0.4781  data_time: 0.0156  last_data_time: 0.0144   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:43:20 d2.utils.events]: \u001b[0m eta: 0:55:13  iter: 8159  total_loss: 0.5435  loss_cls: 0.3036  loss_box_reg: 0.1999  loss_rpn_cls: 0.01072  loss_rpn_loc: 0.01452    time: 0.4846  last_time: 0.4839  data_time: 0.0157  last_data_time: 0.0150   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:43:32 d2.utils.events]: \u001b[0m eta: 0:55:03  iter: 8179  total_loss: 0.5838  loss_cls: 0.3345  loss_box_reg: 0.2171  loss_rpn_cls: 0.0103  loss_rpn_loc: 0.0124    time: 0.4846  last_time: 0.4809  data_time: 0.0162  last_data_time: 0.0145   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:43:44 d2.utils.events]: \u001b[0m eta: 0:54:53  iter: 8199  total_loss: 0.5523  loss_cls: 0.305  loss_box_reg: 0.2105  loss_rpn_cls: 0.01335  loss_rpn_loc: 0.02137    time: 0.4846  last_time: 0.4793  data_time: 0.0157  last_data_time: 0.0151   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:43:56 d2.utils.events]: \u001b[0m eta: 0:54:43  iter: 8219  total_loss: 0.6142  loss_cls: 0.312  loss_box_reg: 0.2275  loss_rpn_cls: 0.01531  loss_rpn_loc: 0.02617    time: 0.4846  last_time: 0.4789  data_time: 0.0159  last_data_time: 0.0141   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:44:08 d2.utils.events]: \u001b[0m eta: 0:54:33  iter: 8239  total_loss: 0.5211  loss_cls: 0.2892  loss_box_reg: 0.2044  loss_rpn_cls: 0.01584  loss_rpn_loc: 0.01702    time: 0.4846  last_time: 0.4835  data_time: 0.0156  last_data_time: 0.0159   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:44:20 d2.utils.events]: \u001b[0m eta: 0:54:23  iter: 8259  total_loss: 0.562  loss_cls: 0.2714  loss_box_reg: 0.236  loss_rpn_cls: 0.01266  loss_rpn_loc: 0.02537    time: 0.4846  last_time: 0.4834  data_time: 0.0162  last_data_time: 0.0158   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:44:32 d2.utils.events]: \u001b[0m eta: 0:54:13  iter: 8279  total_loss: 0.4556  loss_cls: 0.2304  loss_box_reg: 0.2241  loss_rpn_cls: 0.01137  loss_rpn_loc: 0.0145    time: 0.4846  last_time: 0.4804  data_time: 0.0165  last_data_time: 0.0146   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:44:44 d2.utils.events]: \u001b[0m eta: 0:54:03  iter: 8299  total_loss: 0.4842  loss_cls: 0.2437  loss_box_reg: 0.1939  loss_rpn_cls: 0.008212  loss_rpn_loc: 0.01131    time: 0.4846  last_time: 0.4943  data_time: 0.0163  last_data_time: 0.0279   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:44:56 d2.utils.events]: \u001b[0m eta: 0:53:54  iter: 8319  total_loss: 0.5735  loss_cls: 0.2762  loss_box_reg: 0.2257  loss_rpn_cls: 0.01163  loss_rpn_loc: 0.02347    time: 0.4846  last_time: 0.4830  data_time: 0.0165  last_data_time: 0.0149   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:45:09 d2.utils.events]: \u001b[0m eta: 0:53:44  iter: 8339  total_loss: 0.5212  loss_cls: 0.253  loss_box_reg: 0.2059  loss_rpn_cls: 0.01285  loss_rpn_loc: 0.02822    time: 0.4846  last_time: 0.4833  data_time: 0.0159  last_data_time: 0.0147   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:45:21 d2.utils.events]: \u001b[0m eta: 0:53:35  iter: 8359  total_loss: 0.6443  loss_cls: 0.3354  loss_box_reg: 0.2287  loss_rpn_cls: 0.01663  loss_rpn_loc: 0.02469    time: 0.4846  last_time: 0.4860  data_time: 0.0159  last_data_time: 0.0183   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:45:33 d2.utils.events]: \u001b[0m eta: 0:53:25  iter: 8379  total_loss: 0.4641  loss_cls: 0.2599  loss_box_reg: 0.1652  loss_rpn_cls: 0.008948  loss_rpn_loc: 0.01255    time: 0.4846  last_time: 0.4825  data_time: 0.0152  last_data_time: 0.0147   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:45:45 d2.utils.events]: \u001b[0m eta: 0:53:15  iter: 8399  total_loss: 0.5655  loss_cls: 0.2918  loss_box_reg: 0.2106  loss_rpn_cls: 0.008803  loss_rpn_loc: 0.02393    time: 0.4846  last_time: 0.4822  data_time: 0.0164  last_data_time: 0.0144   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:45:57 d2.utils.events]: \u001b[0m eta: 0:53:05  iter: 8419  total_loss: 0.5855  loss_cls: 0.2934  loss_box_reg: 0.2265  loss_rpn_cls: 0.01106  loss_rpn_loc: 0.02795    time: 0.4846  last_time: 0.4818  data_time: 0.0151  last_data_time: 0.0149   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:46:09 d2.utils.events]: \u001b[0m eta: 0:52:56  iter: 8439  total_loss: 0.6242  loss_cls: 0.3046  loss_box_reg: 0.2032  loss_rpn_cls: 0.02084  loss_rpn_loc: 0.02331    time: 0.4846  last_time: 0.4959  data_time: 0.0170  last_data_time: 0.0264   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:46:21 d2.utils.events]: \u001b[0m eta: 0:52:46  iter: 8459  total_loss: 0.5859  loss_cls: 0.2842  loss_box_reg: 0.2205  loss_rpn_cls: 0.0112  loss_rpn_loc: 0.02056    time: 0.4846  last_time: 0.4835  data_time: 0.0162  last_data_time: 0.0145   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:46:33 d2.utils.events]: \u001b[0m eta: 0:52:36  iter: 8479  total_loss: 0.6073  loss_cls: 0.3035  loss_box_reg: 0.2416  loss_rpn_cls: 0.01336  loss_rpn_loc: 0.01344    time: 0.4846  last_time: 0.4823  data_time: 0.0164  last_data_time: 0.0145   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:46:45 d2.utils.events]: \u001b[0m eta: 0:52:26  iter: 8499  total_loss: 0.545  loss_cls: 0.2895  loss_box_reg: 0.1955  loss_rpn_cls: 0.0102  loss_rpn_loc: 0.03027    time: 0.4846  last_time: 0.4849  data_time: 0.0151  last_data_time: 0.0142   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:46:58 d2.utils.events]: \u001b[0m eta: 0:52:16  iter: 8519  total_loss: 0.6166  loss_cls: 0.3249  loss_box_reg: 0.2556  loss_rpn_cls: 0.01415  loss_rpn_loc: 0.01996    time: 0.4846  last_time: 0.4856  data_time: 0.0159  last_data_time: 0.0152   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:47:10 d2.utils.events]: \u001b[0m eta: 0:52:06  iter: 8539  total_loss: 0.616  loss_cls: 0.3077  loss_box_reg: 0.2535  loss_rpn_cls: 0.01559  loss_rpn_loc: 0.03449    time: 0.4846  last_time: 0.4894  data_time: 0.0163  last_data_time: 0.0154   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:47:22 d2.utils.events]: \u001b[0m eta: 0:51:57  iter: 8559  total_loss: 0.4522  loss_cls: 0.2398  loss_box_reg: 0.1872  loss_rpn_cls: 0.01276  loss_rpn_loc: 0.01432    time: 0.4846  last_time: 0.4877  data_time: 0.0171  last_data_time: 0.0215   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:47:34 d2.utils.events]: \u001b[0m eta: 0:51:47  iter: 8579  total_loss: 0.6232  loss_cls: 0.2943  loss_box_reg: 0.2299  loss_rpn_cls: 0.0128  loss_rpn_loc: 0.02336    time: 0.4846  last_time: 0.4872  data_time: 0.0176  last_data_time: 0.0180   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:47:46 d2.utils.events]: \u001b[0m eta: 0:51:38  iter: 8599  total_loss: 0.4754  loss_cls: 0.2362  loss_box_reg: 0.1975  loss_rpn_cls: 0.01359  loss_rpn_loc: 0.01541    time: 0.4846  last_time: 0.4826  data_time: 0.0157  last_data_time: 0.0146   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:47:58 d2.utils.events]: \u001b[0m eta: 0:51:28  iter: 8619  total_loss: 0.5015  loss_cls: 0.2532  loss_box_reg: 0.2078  loss_rpn_cls: 0.0167  loss_rpn_loc: 0.01942    time: 0.4846  last_time: 0.4920  data_time: 0.0167  last_data_time: 0.0194   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:48:10 d2.utils.events]: \u001b[0m eta: 0:51:19  iter: 8639  total_loss: 0.4995  loss_cls: 0.2574  loss_box_reg: 0.2151  loss_rpn_cls: 0.01274  loss_rpn_loc: 0.02085    time: 0.4846  last_time: 0.4821  data_time: 0.0177  last_data_time: 0.0145   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:48:23 d2.utils.events]: \u001b[0m eta: 0:51:09  iter: 8659  total_loss: 0.5426  loss_cls: 0.2584  loss_box_reg: 0.2219  loss_rpn_cls: 0.0167  loss_rpn_loc: 0.03107    time: 0.4846  last_time: 0.4836  data_time: 0.0157  last_data_time: 0.0163   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:48:35 d2.utils.events]: \u001b[0m eta: 0:50:59  iter: 8679  total_loss: 0.6129  loss_cls: 0.2701  loss_box_reg: 0.2161  loss_rpn_cls: 0.009251  loss_rpn_loc: 0.01771    time: 0.4846  last_time: 0.4820  data_time: 0.0161  last_data_time: 0.0147   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:48:47 d2.utils.events]: \u001b[0m eta: 0:50:49  iter: 8699  total_loss: 0.5572  loss_cls: 0.2957  loss_box_reg: 0.2318  loss_rpn_cls: 0.01668  loss_rpn_loc: 0.02997    time: 0.4846  last_time: 0.4816  data_time: 0.0160  last_data_time: 0.0142   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:48:59 d2.utils.events]: \u001b[0m eta: 0:50:39  iter: 8719  total_loss: 0.4499  loss_cls: 0.2473  loss_box_reg: 0.1774  loss_rpn_cls: 0.01068  loss_rpn_loc: 0.01079    time: 0.4846  last_time: 0.4877  data_time: 0.0161  last_data_time: 0.0147   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:49:11 d2.utils.events]: \u001b[0m eta: 0:50:30  iter: 8739  total_loss: 0.4418  loss_cls: 0.203  loss_box_reg: 0.1974  loss_rpn_cls: 0.009583  loss_rpn_loc: 0.015    time: 0.4846  last_time: 0.4855  data_time: 0.0164  last_data_time: 0.0151   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:49:23 d2.utils.events]: \u001b[0m eta: 0:50:20  iter: 8759  total_loss: 0.4956  loss_cls: 0.2527  loss_box_reg: 0.1896  loss_rpn_cls: 0.01532  loss_rpn_loc: 0.01509    time: 0.4846  last_time: 0.4836  data_time: 0.0162  last_data_time: 0.0153   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:49:35 d2.utils.events]: \u001b[0m eta: 0:50:11  iter: 8779  total_loss: 0.5571  loss_cls: 0.2822  loss_box_reg: 0.2121  loss_rpn_cls: 0.01686  loss_rpn_loc: 0.02596    time: 0.4846  last_time: 0.4838  data_time: 0.0154  last_data_time: 0.0148   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:49:47 d2.utils.events]: \u001b[0m eta: 0:50:01  iter: 8799  total_loss: 0.4371  loss_cls: 0.2288  loss_box_reg: 0.1915  loss_rpn_cls: 0.009202  loss_rpn_loc: 0.01534    time: 0.4846  last_time: 0.4884  data_time: 0.0168  last_data_time: 0.0208   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:50:00 d2.utils.events]: \u001b[0m eta: 0:49:52  iter: 8819  total_loss: 0.5965  loss_cls: 0.2985  loss_box_reg: 0.2125  loss_rpn_cls: 0.01275  loss_rpn_loc: 0.02205    time: 0.4846  last_time: 0.4959  data_time: 0.0174  last_data_time: 0.0194   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:50:12 d2.utils.events]: \u001b[0m eta: 0:49:42  iter: 8839  total_loss: 0.57  loss_cls: 0.2943  loss_box_reg: 0.2319  loss_rpn_cls: 0.01284  loss_rpn_loc: 0.02572    time: 0.4846  last_time: 0.4881  data_time: 0.0182  last_data_time: 0.0188   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:50:24 d2.utils.events]: \u001b[0m eta: 0:49:33  iter: 8859  total_loss: 0.5339  loss_cls: 0.2822  loss_box_reg: 0.2076  loss_rpn_cls: 0.01251  loss_rpn_loc: 0.02002    time: 0.4846  last_time: 0.4843  data_time: 0.0154  last_data_time: 0.0148   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:50:36 d2.utils.events]: \u001b[0m eta: 0:49:23  iter: 8879  total_loss: 0.4891  loss_cls: 0.2512  loss_box_reg: 0.1992  loss_rpn_cls: 0.01298  loss_rpn_loc: 0.02145    time: 0.4846  last_time: 0.4884  data_time: 0.0171  last_data_time: 0.0146   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:50:48 d2.utils.events]: \u001b[0m eta: 0:49:13  iter: 8899  total_loss: 0.5134  loss_cls: 0.2601  loss_box_reg: 0.1951  loss_rpn_cls: 0.01129  loss_rpn_loc: 0.01994    time: 0.4846  last_time: 0.4827  data_time: 0.0157  last_data_time: 0.0148   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:51:01 d2.utils.events]: \u001b[0m eta: 0:49:03  iter: 8919  total_loss: 0.6278  loss_cls: 0.2984  loss_box_reg: 0.2151  loss_rpn_cls: 0.01366  loss_rpn_loc: 0.03191    time: 0.4847  last_time: 0.4990  data_time: 0.0161  last_data_time: 0.0149   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:51:13 d2.utils.events]: \u001b[0m eta: 0:48:53  iter: 8939  total_loss: 0.4525  loss_cls: 0.237  loss_box_reg: 0.1742  loss_rpn_cls: 0.008599  loss_rpn_loc: 0.02476    time: 0.4847  last_time: 0.4833  data_time: 0.0167  last_data_time: 0.0150   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:51:25 d2.utils.events]: \u001b[0m eta: 0:48:44  iter: 8959  total_loss: 0.5346  loss_cls: 0.2883  loss_box_reg: 0.1866  loss_rpn_cls: 0.009093  loss_rpn_loc: 0.02429    time: 0.4847  last_time: 0.4839  data_time: 0.0161  last_data_time: 0.0149   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:51:37 d2.utils.events]: \u001b[0m eta: 0:48:34  iter: 8979  total_loss: 0.5574  loss_cls: 0.2963  loss_box_reg: 0.203  loss_rpn_cls: 0.01281  loss_rpn_loc: 0.02076    time: 0.4847  last_time: 0.4894  data_time: 0.0157  last_data_time: 0.0173   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:51:53 d2.data.datasets.coco]: \u001b[0mLoaded 4871 images in COCO format from /data/ephemeral/home/workspace/dataset/test.json\n",
      "\u001b[32m[10/10 02:51:53 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/10 02:51:53 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[10/10 02:51:53 d2.data.common]: \u001b[0mSerializing 4871 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/10 02:51:53 d2.data.common]: \u001b[0mSerialized dataset takes 0.63 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/10 02:51:53 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[10/10 02:51:53 d2.evaluation.evaluator]: \u001b[0mStart inference on 4871 batches\n",
      "\u001b[32m[10/10 02:51:54 d2.evaluation.evaluator]: \u001b[0mInference done 11/4871. Dataloading: 0.0011 s/iter. Inference: 0.0458 s/iter. Eval: 0.0003 s/iter. Total: 0.0471 s/iter. ETA=0:03:49\n",
      "\u001b[32m[10/10 02:51:59 d2.evaluation.evaluator]: \u001b[0mInference done 115/4871. Dataloading: 0.0014 s/iter. Inference: 0.0463 s/iter. Eval: 0.0003 s/iter. Total: 0.0481 s/iter. ETA=0:03:48\n",
      "\u001b[32m[10/10 02:52:04 d2.evaluation.evaluator]: \u001b[0mInference done 220/4871. Dataloading: 0.0014 s/iter. Inference: 0.0463 s/iter. Eval: 0.0003 s/iter. Total: 0.0480 s/iter. ETA=0:03:43\n",
      "\u001b[32m[10/10 02:52:09 d2.evaluation.evaluator]: \u001b[0mInference done 323/4871. Dataloading: 0.0014 s/iter. Inference: 0.0465 s/iter. Eval: 0.0003 s/iter. Total: 0.0482 s/iter. ETA=0:03:39\n",
      "\u001b[32m[10/10 02:52:14 d2.evaluation.evaluator]: \u001b[0mInference done 426/4871. Dataloading: 0.0014 s/iter. Inference: 0.0466 s/iter. Eval: 0.0003 s/iter. Total: 0.0483 s/iter. ETA=0:03:34\n",
      "\u001b[32m[10/10 02:52:19 d2.evaluation.evaluator]: \u001b[0mInference done 528/4871. Dataloading: 0.0015 s/iter. Inference: 0.0467 s/iter. Eval: 0.0003 s/iter. Total: 0.0485 s/iter. ETA=0:03:30\n",
      "\u001b[32m[10/10 02:52:24 d2.evaluation.evaluator]: \u001b[0mInference done 631/4871. Dataloading: 0.0015 s/iter. Inference: 0.0467 s/iter. Eval: 0.0003 s/iter. Total: 0.0485 s/iter. ETA=0:03:25\n",
      "\u001b[32m[10/10 02:52:29 d2.evaluation.evaluator]: \u001b[0mInference done 728/4871. Dataloading: 0.0015 s/iter. Inference: 0.0471 s/iter. Eval: 0.0003 s/iter. Total: 0.0489 s/iter. ETA=0:03:22\n",
      "\u001b[32m[10/10 02:52:34 d2.evaluation.evaluator]: \u001b[0mInference done 831/4871. Dataloading: 0.0015 s/iter. Inference: 0.0471 s/iter. Eval: 0.0003 s/iter. Total: 0.0489 s/iter. ETA=0:03:17\n",
      "\u001b[32m[10/10 02:52:39 d2.evaluation.evaluator]: \u001b[0mInference done 933/4871. Dataloading: 0.0015 s/iter. Inference: 0.0471 s/iter. Eval: 0.0003 s/iter. Total: 0.0490 s/iter. ETA=0:03:12\n",
      "\u001b[32m[10/10 02:52:44 d2.evaluation.evaluator]: \u001b[0mInference done 1036/4871. Dataloading: 0.0015 s/iter. Inference: 0.0471 s/iter. Eval: 0.0003 s/iter. Total: 0.0489 s/iter. ETA=0:03:07\n",
      "\u001b[32m[10/10 02:52:49 d2.evaluation.evaluator]: \u001b[0mInference done 1138/4871. Dataloading: 0.0015 s/iter. Inference: 0.0471 s/iter. Eval: 0.0003 s/iter. Total: 0.0489 s/iter. ETA=0:03:02\n",
      "\u001b[32m[10/10 02:52:54 d2.evaluation.evaluator]: \u001b[0mInference done 1241/4871. Dataloading: 0.0015 s/iter. Inference: 0.0470 s/iter. Eval: 0.0003 s/iter. Total: 0.0489 s/iter. ETA=0:02:57\n",
      "\u001b[32m[10/10 02:52:59 d2.evaluation.evaluator]: \u001b[0mInference done 1347/4871. Dataloading: 0.0015 s/iter. Inference: 0.0469 s/iter. Eval: 0.0003 s/iter. Total: 0.0488 s/iter. ETA=0:02:51\n",
      "\u001b[32m[10/10 02:53:04 d2.evaluation.evaluator]: \u001b[0mInference done 1450/4871. Dataloading: 0.0015 s/iter. Inference: 0.0469 s/iter. Eval: 0.0003 s/iter. Total: 0.0488 s/iter. ETA=0:02:46\n",
      "\u001b[32m[10/10 02:53:09 d2.evaluation.evaluator]: \u001b[0mInference done 1554/4871. Dataloading: 0.0015 s/iter. Inference: 0.0469 s/iter. Eval: 0.0003 s/iter. Total: 0.0488 s/iter. ETA=0:02:41\n",
      "\u001b[32m[10/10 02:53:14 d2.evaluation.evaluator]: \u001b[0mInference done 1658/4871. Dataloading: 0.0015 s/iter. Inference: 0.0469 s/iter. Eval: 0.0003 s/iter. Total: 0.0487 s/iter. ETA=0:02:36\n",
      "\u001b[32m[10/10 02:53:19 d2.evaluation.evaluator]: \u001b[0mInference done 1763/4871. Dataloading: 0.0015 s/iter. Inference: 0.0468 s/iter. Eval: 0.0003 s/iter. Total: 0.0487 s/iter. ETA=0:02:31\n",
      "\u001b[32m[10/10 02:53:24 d2.evaluation.evaluator]: \u001b[0mInference done 1866/4871. Dataloading: 0.0015 s/iter. Inference: 0.0468 s/iter. Eval: 0.0003 s/iter. Total: 0.0487 s/iter. ETA=0:02:26\n",
      "\u001b[32m[10/10 02:53:29 d2.evaluation.evaluator]: \u001b[0mInference done 1970/4871. Dataloading: 0.0015 s/iter. Inference: 0.0468 s/iter. Eval: 0.0003 s/iter. Total: 0.0487 s/iter. ETA=0:02:21\n",
      "\u001b[32m[10/10 02:53:34 d2.evaluation.evaluator]: \u001b[0mInference done 2071/4871. Dataloading: 0.0015 s/iter. Inference: 0.0469 s/iter. Eval: 0.0003 s/iter. Total: 0.0487 s/iter. ETA=0:02:16\n",
      "\u001b[32m[10/10 02:53:39 d2.evaluation.evaluator]: \u001b[0mInference done 2172/4871. Dataloading: 0.0015 s/iter. Inference: 0.0469 s/iter. Eval: 0.0003 s/iter. Total: 0.0488 s/iter. ETA=0:02:11\n",
      "\u001b[32m[10/10 02:53:44 d2.evaluation.evaluator]: \u001b[0mInference done 2277/4871. Dataloading: 0.0015 s/iter. Inference: 0.0469 s/iter. Eval: 0.0003 s/iter. Total: 0.0487 s/iter. ETA=0:02:06\n",
      "\u001b[32m[10/10 02:53:49 d2.evaluation.evaluator]: \u001b[0mInference done 2381/4871. Dataloading: 0.0015 s/iter. Inference: 0.0469 s/iter. Eval: 0.0003 s/iter. Total: 0.0487 s/iter. ETA=0:02:01\n",
      "\u001b[32m[10/10 02:53:54 d2.evaluation.evaluator]: \u001b[0mInference done 2480/4871. Dataloading: 0.0015 s/iter. Inference: 0.0469 s/iter. Eval: 0.0003 s/iter. Total: 0.0488 s/iter. ETA=0:01:56\n",
      "\u001b[32m[10/10 02:53:59 d2.evaluation.evaluator]: \u001b[0mInference done 2578/4871. Dataloading: 0.0015 s/iter. Inference: 0.0470 s/iter. Eval: 0.0003 s/iter. Total: 0.0489 s/iter. ETA=0:01:52\n",
      "\u001b[32m[10/10 02:54:04 d2.evaluation.evaluator]: \u001b[0mInference done 2680/4871. Dataloading: 0.0015 s/iter. Inference: 0.0470 s/iter. Eval: 0.0003 s/iter. Total: 0.0489 s/iter. ETA=0:01:47\n",
      "\u001b[32m[10/10 02:54:09 d2.evaluation.evaluator]: \u001b[0mInference done 2782/4871. Dataloading: 0.0015 s/iter. Inference: 0.0471 s/iter. Eval: 0.0003 s/iter. Total: 0.0489 s/iter. ETA=0:01:42\n",
      "\u001b[32m[10/10 02:54:14 d2.evaluation.evaluator]: \u001b[0mInference done 2884/4871. Dataloading: 0.0015 s/iter. Inference: 0.0471 s/iter. Eval: 0.0003 s/iter. Total: 0.0489 s/iter. ETA=0:01:37\n",
      "\u001b[32m[10/10 02:54:19 d2.evaluation.evaluator]: \u001b[0mInference done 2987/4871. Dataloading: 0.0015 s/iter. Inference: 0.0471 s/iter. Eval: 0.0003 s/iter. Total: 0.0489 s/iter. ETA=0:01:32\n",
      "\u001b[32m[10/10 02:54:24 d2.evaluation.evaluator]: \u001b[0mInference done 3090/4871. Dataloading: 0.0015 s/iter. Inference: 0.0471 s/iter. Eval: 0.0003 s/iter. Total: 0.0489 s/iter. ETA=0:01:27\n",
      "\u001b[32m[10/10 02:54:29 d2.evaluation.evaluator]: \u001b[0mInference done 3196/4871. Dataloading: 0.0015 s/iter. Inference: 0.0470 s/iter. Eval: 0.0003 s/iter. Total: 0.0489 s/iter. ETA=0:01:21\n",
      "\u001b[32m[10/10 02:54:34 d2.evaluation.evaluator]: \u001b[0mInference done 3299/4871. Dataloading: 0.0015 s/iter. Inference: 0.0470 s/iter. Eval: 0.0003 s/iter. Total: 0.0489 s/iter. ETA=0:01:16\n",
      "\u001b[32m[10/10 02:54:39 d2.evaluation.evaluator]: \u001b[0mInference done 3401/4871. Dataloading: 0.0015 s/iter. Inference: 0.0470 s/iter. Eval: 0.0003 s/iter. Total: 0.0489 s/iter. ETA=0:01:11\n",
      "\u001b[32m[10/10 02:54:45 d2.evaluation.evaluator]: \u001b[0mInference done 3503/4871. Dataloading: 0.0015 s/iter. Inference: 0.0470 s/iter. Eval: 0.0003 s/iter. Total: 0.0489 s/iter. ETA=0:01:06\n",
      "\u001b[32m[10/10 02:54:50 d2.evaluation.evaluator]: \u001b[0mInference done 3608/4871. Dataloading: 0.0015 s/iter. Inference: 0.0470 s/iter. Eval: 0.0003 s/iter. Total: 0.0489 s/iter. ETA=0:01:01\n",
      "\u001b[32m[10/10 02:54:55 d2.evaluation.evaluator]: \u001b[0mInference done 3716/4871. Dataloading: 0.0015 s/iter. Inference: 0.0470 s/iter. Eval: 0.0003 s/iter. Total: 0.0488 s/iter. ETA=0:00:56\n",
      "\u001b[32m[10/10 02:55:00 d2.evaluation.evaluator]: \u001b[0mInference done 3821/4871. Dataloading: 0.0015 s/iter. Inference: 0.0469 s/iter. Eval: 0.0003 s/iter. Total: 0.0488 s/iter. ETA=0:00:51\n",
      "\u001b[32m[10/10 02:55:05 d2.evaluation.evaluator]: \u001b[0mInference done 3926/4871. Dataloading: 0.0015 s/iter. Inference: 0.0469 s/iter. Eval: 0.0003 s/iter. Total: 0.0487 s/iter. ETA=0:00:46\n",
      "\u001b[32m[10/10 02:55:10 d2.evaluation.evaluator]: \u001b[0mInference done 4029/4871. Dataloading: 0.0015 s/iter. Inference: 0.0469 s/iter. Eval: 0.0003 s/iter. Total: 0.0487 s/iter. ETA=0:00:41\n",
      "\u001b[32m[10/10 02:55:15 d2.evaluation.evaluator]: \u001b[0mInference done 4138/4871. Dataloading: 0.0015 s/iter. Inference: 0.0468 s/iter. Eval: 0.0003 s/iter. Total: 0.0487 s/iter. ETA=0:00:35\n",
      "\u001b[32m[10/10 02:55:20 d2.evaluation.evaluator]: \u001b[0mInference done 4243/4871. Dataloading: 0.0015 s/iter. Inference: 0.0468 s/iter. Eval: 0.0003 s/iter. Total: 0.0487 s/iter. ETA=0:00:30\n",
      "\u001b[32m[10/10 02:55:25 d2.evaluation.evaluator]: \u001b[0mInference done 4348/4871. Dataloading: 0.0015 s/iter. Inference: 0.0468 s/iter. Eval: 0.0003 s/iter. Total: 0.0486 s/iter. ETA=0:00:25\n",
      "\u001b[32m[10/10 02:55:30 d2.evaluation.evaluator]: \u001b[0mInference done 4451/4871. Dataloading: 0.0015 s/iter. Inference: 0.0468 s/iter. Eval: 0.0003 s/iter. Total: 0.0486 s/iter. ETA=0:00:20\n",
      "\u001b[32m[10/10 02:55:35 d2.evaluation.evaluator]: \u001b[0mInference done 4549/4871. Dataloading: 0.0015 s/iter. Inference: 0.0468 s/iter. Eval: 0.0003 s/iter. Total: 0.0487 s/iter. ETA=0:00:15\n",
      "\u001b[32m[10/10 02:55:40 d2.evaluation.evaluator]: \u001b[0mInference done 4653/4871. Dataloading: 0.0015 s/iter. Inference: 0.0468 s/iter. Eval: 0.0003 s/iter. Total: 0.0487 s/iter. ETA=0:00:10\n",
      "\u001b[32m[10/10 02:55:45 d2.evaluation.evaluator]: \u001b[0mInference done 4755/4871. Dataloading: 0.0015 s/iter. Inference: 0.0468 s/iter. Eval: 0.0003 s/iter. Total: 0.0487 s/iter. ETA=0:00:05\n",
      "\u001b[32m[10/10 02:55:50 d2.evaluation.evaluator]: \u001b[0mInference done 4858/4871. Dataloading: 0.0015 s/iter. Inference: 0.0468 s/iter. Eval: 0.0003 s/iter. Total: 0.0487 s/iter. ETA=0:00:00\n",
      "\u001b[32m[10/10 02:55:51 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:03:57.029341 (0.048711 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/10 02:55:51 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:03:47 (0.046808 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/10 02:55:51 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/10 02:55:51 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output_eval/coco_instances_results.json\n",
      "\u001b[32m[10/10 02:55:52 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.42s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/10 02:55:53 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/10 02:55:55 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 2.15 seconds.\n",
      "\u001b[32m[10/10 02:55:55 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/10 02:55:55 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.24 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "\u001b[32m[10/10 02:55:55 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP  |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| nan  |  nan   |  nan   |  nan  |  nan  |  nan  |\n",
      "\u001b[32m[10/10 02:55:55 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[10/10 02:55:55 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category      | AP   | category    | AP   | category   | AP   |\n",
      "|:--------------|:-----|:------------|:-----|:-----------|:-----|\n",
      "| General trash | nan  | Paper       | nan  | Paper pack | nan  |\n",
      "| Metal         | nan  | Glass       | nan  | Plastic    | nan  |\n",
      "| Styrofoam     | nan  | Plastic bag | nan  | Battery    | nan  |\n",
      "| Clothing      | nan  |             |      |            |      |\n",
      "\u001b[32m[10/10 02:55:55 d2.engine.defaults]: \u001b[0mEvaluation results for coco_trash_test in csv format:\n",
      "\u001b[32m[10/10 02:55:55 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[10/10 02:55:55 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[10/10 02:55:55 d2.evaluation.testing]: \u001b[0mcopypaste: nan,nan,nan,nan,nan,nan\n",
      "\u001b[32m[10/10 02:55:55 d2.utils.events]: \u001b[0m eta: 0:48:25  iter: 8999  total_loss: 0.5305  loss_cls: 0.2842  loss_box_reg: 0.2118  loss_rpn_cls: 0.02299  loss_rpn_loc: 0.0211    time: 0.4847  last_time: 0.4820  data_time: 0.0163  last_data_time: 0.0145   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:56:07 d2.utils.events]: \u001b[0m eta: 0:48:15  iter: 9019  total_loss: 0.587  loss_cls: 0.2631  loss_box_reg: 0.2264  loss_rpn_cls: 0.01273  loss_rpn_loc: 0.03583    time: 0.4847  last_time: 0.4832  data_time: 0.0171  last_data_time: 0.0145   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:56:20 d2.utils.events]: \u001b[0m eta: 0:48:05  iter: 9039  total_loss: 0.5219  loss_cls: 0.25  loss_box_reg: 0.2049  loss_rpn_cls: 0.01179  loss_rpn_loc: 0.01838    time: 0.4847  last_time: 0.4842  data_time: 0.0154  last_data_time: 0.0147   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:56:32 d2.utils.events]: \u001b[0m eta: 0:47:56  iter: 9059  total_loss: 0.4886  loss_cls: 0.2542  loss_box_reg: 0.1945  loss_rpn_cls: 0.01319  loss_rpn_loc: 0.02224    time: 0.4847  last_time: 0.4863  data_time: 0.0170  last_data_time: 0.0186   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:56:44 d2.utils.events]: \u001b[0m eta: 0:47:46  iter: 9079  total_loss: 0.6446  loss_cls: 0.3508  loss_box_reg: 0.2435  loss_rpn_cls: 0.01452  loss_rpn_loc: 0.0352    time: 0.4847  last_time: 0.4934  data_time: 0.0162  last_data_time: 0.0150   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:56:56 d2.utils.events]: \u001b[0m eta: 0:47:36  iter: 9099  total_loss: 0.4569  loss_cls: 0.2416  loss_box_reg: 0.1945  loss_rpn_cls: 0.01403  loss_rpn_loc: 0.01225    time: 0.4847  last_time: 0.4822  data_time: 0.0170  last_data_time: 0.0148   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:57:08 d2.utils.events]: \u001b[0m eta: 0:47:27  iter: 9119  total_loss: 0.5716  loss_cls: 0.3071  loss_box_reg: 0.2249  loss_rpn_cls: 0.01558  loss_rpn_loc: 0.03466    time: 0.4847  last_time: 0.4839  data_time: 0.0161  last_data_time: 0.0184   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:57:20 d2.utils.events]: \u001b[0m eta: 0:47:17  iter: 9139  total_loss: 0.5423  loss_cls: 0.3104  loss_box_reg: 0.2129  loss_rpn_cls: 0.01901  loss_rpn_loc: 0.01669    time: 0.4847  last_time: 0.4826  data_time: 0.0159  last_data_time: 0.0142   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:57:32 d2.utils.events]: \u001b[0m eta: 0:47:08  iter: 9159  total_loss: 0.5523  loss_cls: 0.2652  loss_box_reg: 0.2081  loss_rpn_cls: 0.01099  loss_rpn_loc: 0.0267    time: 0.4847  last_time: 0.4827  data_time: 0.0164  last_data_time: 0.0146   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:57:44 d2.utils.events]: \u001b[0m eta: 0:46:58  iter: 9179  total_loss: 0.3944  loss_cls: 0.2366  loss_box_reg: 0.1641  loss_rpn_cls: 0.008353  loss_rpn_loc: 0.01583    time: 0.4847  last_time: 0.4894  data_time: 0.0166  last_data_time: 0.0210   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:57:57 d2.utils.events]: \u001b[0m eta: 0:46:49  iter: 9199  total_loss: 0.5375  loss_cls: 0.2711  loss_box_reg: 0.2387  loss_rpn_cls: 0.01335  loss_rpn_loc: 0.02499    time: 0.4847  last_time: 0.4911  data_time: 0.0166  last_data_time: 0.0208   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:58:09 d2.utils.events]: \u001b[0m eta: 0:46:39  iter: 9219  total_loss: 0.4888  loss_cls: 0.2843  loss_box_reg: 0.1835  loss_rpn_cls: 0.01114  loss_rpn_loc: 0.03073    time: 0.4847  last_time: 0.4878  data_time: 0.0172  last_data_time: 0.0185   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:58:21 d2.utils.events]: \u001b[0m eta: 0:46:30  iter: 9239  total_loss: 0.5381  loss_cls: 0.274  loss_box_reg: 0.1908  loss_rpn_cls: 0.01087  loss_rpn_loc: 0.02931    time: 0.4847  last_time: 0.4809  data_time: 0.0157  last_data_time: 0.0144   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:58:33 d2.utils.events]: \u001b[0m eta: 0:46:20  iter: 9259  total_loss: 0.6102  loss_cls: 0.313  loss_box_reg: 0.2365  loss_rpn_cls: 0.01183  loss_rpn_loc: 0.03212    time: 0.4847  last_time: 0.4875  data_time: 0.0153  last_data_time: 0.0163   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:58:45 d2.utils.events]: \u001b[0m eta: 0:46:10  iter: 9279  total_loss: 0.5609  loss_cls: 0.2816  loss_box_reg: 0.2028  loss_rpn_cls: 0.01101  loss_rpn_loc: 0.01567    time: 0.4847  last_time: 0.4836  data_time: 0.0162  last_data_time: 0.0163   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:58:57 d2.utils.events]: \u001b[0m eta: 0:46:00  iter: 9299  total_loss: 0.516  loss_cls: 0.2618  loss_box_reg: 0.1894  loss_rpn_cls: 0.01325  loss_rpn_loc: 0.01418    time: 0.4847  last_time: 0.4829  data_time: 0.0155  last_data_time: 0.0142   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:59:09 d2.utils.events]: \u001b[0m eta: 0:45:51  iter: 9319  total_loss: 0.5911  loss_cls: 0.3117  loss_box_reg: 0.2067  loss_rpn_cls: 0.01509  loss_rpn_loc: 0.0268    time: 0.4847  last_time: 0.4826  data_time: 0.0154  last_data_time: 0.0149   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:59:21 d2.utils.events]: \u001b[0m eta: 0:45:41  iter: 9339  total_loss: 0.5706  loss_cls: 0.2513  loss_box_reg: 0.2228  loss_rpn_cls: 0.01496  loss_rpn_loc: 0.02105    time: 0.4847  last_time: 0.4915  data_time: 0.0163  last_data_time: 0.0195   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:59:34 d2.utils.events]: \u001b[0m eta: 0:45:31  iter: 9359  total_loss: 0.5046  loss_cls: 0.2409  loss_box_reg: 0.23  loss_rpn_cls: 0.01485  loss_rpn_loc: 0.02586    time: 0.4847  last_time: 0.4835  data_time: 0.0168  last_data_time: 0.0146   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:59:46 d2.utils.events]: \u001b[0m eta: 0:45:21  iter: 9379  total_loss: 0.5698  loss_cls: 0.294  loss_box_reg: 0.227  loss_rpn_cls: 0.01616  loss_rpn_loc: 0.02728    time: 0.4847  last_time: 0.4822  data_time: 0.0161  last_data_time: 0.0143   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 02:59:58 d2.utils.events]: \u001b[0m eta: 0:45:12  iter: 9399  total_loss: 0.623  loss_cls: 0.3011  loss_box_reg: 0.242  loss_rpn_cls: 0.009978  loss_rpn_loc: 0.02135    time: 0.4847  last_time: 0.4860  data_time: 0.0158  last_data_time: 0.0179   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:00:10 d2.utils.events]: \u001b[0m eta: 0:45:02  iter: 9419  total_loss: 0.4853  loss_cls: 0.2515  loss_box_reg: 0.1882  loss_rpn_cls: 0.009349  loss_rpn_loc: 0.01802    time: 0.4847  last_time: 0.4874  data_time: 0.0166  last_data_time: 0.0176   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:00:22 d2.utils.events]: \u001b[0m eta: 0:44:52  iter: 9439  total_loss: 0.548  loss_cls: 0.2955  loss_box_reg: 0.2166  loss_rpn_cls: 0.01318  loss_rpn_loc: 0.02259    time: 0.4847  last_time: 0.4810  data_time: 0.0161  last_data_time: 0.0143   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:00:34 d2.utils.events]: \u001b[0m eta: 0:44:43  iter: 9459  total_loss: 0.5168  loss_cls: 0.2695  loss_box_reg: 0.1998  loss_rpn_cls: 0.01208  loss_rpn_loc: 0.02622    time: 0.4847  last_time: 0.4826  data_time: 0.0159  last_data_time: 0.0147   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:00:46 d2.utils.events]: \u001b[0m eta: 0:44:33  iter: 9479  total_loss: 0.5207  loss_cls: 0.2781  loss_box_reg: 0.2024  loss_rpn_cls: 0.01229  loss_rpn_loc: 0.01876    time: 0.4847  last_time: 0.4895  data_time: 0.0167  last_data_time: 0.0191   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:00:58 d2.utils.events]: \u001b[0m eta: 0:44:24  iter: 9499  total_loss: 0.4713  loss_cls: 0.2775  loss_box_reg: 0.1854  loss_rpn_cls: 0.01119  loss_rpn_loc: 0.01735    time: 0.4847  last_time: 0.4833  data_time: 0.0173  last_data_time: 0.0144   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:01:11 d2.utils.events]: \u001b[0m eta: 0:44:14  iter: 9519  total_loss: 0.4887  loss_cls: 0.254  loss_box_reg: 0.2018  loss_rpn_cls: 0.01237  loss_rpn_loc: 0.01323    time: 0.4847  last_time: 0.4822  data_time: 0.0160  last_data_time: 0.0161   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:01:23 d2.utils.events]: \u001b[0m eta: 0:44:04  iter: 9539  total_loss: 0.5745  loss_cls: 0.2902  loss_box_reg: 0.2592  loss_rpn_cls: 0.01646  loss_rpn_loc: 0.0279    time: 0.4847  last_time: 0.4855  data_time: 0.0179  last_data_time: 0.0161   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:01:35 d2.utils.events]: \u001b[0m eta: 0:43:55  iter: 9559  total_loss: 0.4936  loss_cls: 0.234  loss_box_reg: 0.2059  loss_rpn_cls: 0.01099  loss_rpn_loc: 0.02908    time: 0.4847  last_time: 0.4873  data_time: 0.0162  last_data_time: 0.0152   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:01:47 d2.utils.events]: \u001b[0m eta: 0:43:45  iter: 9579  total_loss: 0.482  loss_cls: 0.2367  loss_box_reg: 0.1808  loss_rpn_cls: 0.01388  loss_rpn_loc: 0.01939    time: 0.4847  last_time: 0.4846  data_time: 0.0164  last_data_time: 0.0147   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:01:59 d2.utils.events]: \u001b[0m eta: 0:43:35  iter: 9599  total_loss: 0.4713  loss_cls: 0.242  loss_box_reg: 0.2083  loss_rpn_cls: 0.01119  loss_rpn_loc: 0.02312    time: 0.4847  last_time: 0.4829  data_time: 0.0156  last_data_time: 0.0152   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:02:11 d2.utils.events]: \u001b[0m eta: 0:43:25  iter: 9619  total_loss: 0.5499  loss_cls: 0.2805  loss_box_reg: 0.2055  loss_rpn_cls: 0.01485  loss_rpn_loc: 0.02062    time: 0.4847  last_time: 0.4870  data_time: 0.0158  last_data_time: 0.0160   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:02:23 d2.utils.events]: \u001b[0m eta: 0:43:15  iter: 9639  total_loss: 0.5573  loss_cls: 0.2539  loss_box_reg: 0.2136  loss_rpn_cls: 0.009454  loss_rpn_loc: 0.01264    time: 0.4847  last_time: 0.4794  data_time: 0.0153  last_data_time: 0.0143   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:02:35 d2.utils.events]: \u001b[0m eta: 0:43:06  iter: 9659  total_loss: 0.6248  loss_cls: 0.2906  loss_box_reg: 0.2348  loss_rpn_cls: 0.01301  loss_rpn_loc: 0.02133    time: 0.4847  last_time: 0.5036  data_time: 0.0172  last_data_time: 0.0300   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:02:47 d2.utils.events]: \u001b[0m eta: 0:42:56  iter: 9679  total_loss: 0.5854  loss_cls: 0.2701  loss_box_reg: 0.2439  loss_rpn_cls: 0.0154  loss_rpn_loc: 0.02311    time: 0.4847  last_time: 0.4819  data_time: 0.0175  last_data_time: 0.0142   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:03:00 d2.utils.events]: \u001b[0m eta: 0:42:46  iter: 9699  total_loss: 0.5472  loss_cls: 0.2931  loss_box_reg: 0.2214  loss_rpn_cls: 0.01107  loss_rpn_loc: 0.02984    time: 0.4847  last_time: 0.4842  data_time: 0.0156  last_data_time: 0.0160   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:03:12 d2.utils.events]: \u001b[0m eta: 0:42:37  iter: 9719  total_loss: 0.5481  loss_cls: 0.2826  loss_box_reg: 0.2227  loss_rpn_cls: 0.01468  loss_rpn_loc: 0.01912    time: 0.4847  last_time: 0.4796  data_time: 0.0157  last_data_time: 0.0148   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:03:24 d2.utils.events]: \u001b[0m eta: 0:42:27  iter: 9739  total_loss: 0.4967  loss_cls: 0.2635  loss_box_reg: 0.1745  loss_rpn_cls: 0.007531  loss_rpn_loc: 0.01531    time: 0.4847  last_time: 0.4850  data_time: 0.0152  last_data_time: 0.0179   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:03:36 d2.utils.events]: \u001b[0m eta: 0:42:17  iter: 9759  total_loss: 0.6161  loss_cls: 0.2865  loss_box_reg: 0.2529  loss_rpn_cls: 0.01316  loss_rpn_loc: 0.02743    time: 0.4847  last_time: 0.4794  data_time: 0.0154  last_data_time: 0.0135   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:03:48 d2.utils.events]: \u001b[0m eta: 0:42:07  iter: 9779  total_loss: 0.4941  loss_cls: 0.2334  loss_box_reg: 0.204  loss_rpn_cls: 0.01394  loss_rpn_loc: 0.01459    time: 0.4847  last_time: 0.4863  data_time: 0.0163  last_data_time: 0.0190   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:04:00 d2.utils.events]: \u001b[0m eta: 0:41:57  iter: 9799  total_loss: 0.5251  loss_cls: 0.2658  loss_box_reg: 0.2459  loss_rpn_cls: 0.01017  loss_rpn_loc: 0.01999    time: 0.4847  last_time: 0.4828  data_time: 0.0152  last_data_time: 0.0143   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:04:12 d2.utils.events]: \u001b[0m eta: 0:41:47  iter: 9819  total_loss: 0.3917  loss_cls: 0.219  loss_box_reg: 0.1762  loss_rpn_cls: 0.008318  loss_rpn_loc: 0.01371    time: 0.4847  last_time: 0.4800  data_time: 0.0148  last_data_time: 0.0145   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:04:24 d2.utils.events]: \u001b[0m eta: 0:41:37  iter: 9839  total_loss: 0.5442  loss_cls: 0.2854  loss_box_reg: 0.207  loss_rpn_cls: 0.01254  loss_rpn_loc: 0.02112    time: 0.4847  last_time: 0.4827  data_time: 0.0159  last_data_time: 0.0152   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:04:36 d2.utils.events]: \u001b[0m eta: 0:41:28  iter: 9859  total_loss: 0.4458  loss_cls: 0.2299  loss_box_reg: 0.1691  loss_rpn_cls: 0.01039  loss_rpn_loc: 0.01536    time: 0.4847  last_time: 0.4825  data_time: 0.0168  last_data_time: 0.0144   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:04:48 d2.utils.events]: \u001b[0m eta: 0:41:18  iter: 9879  total_loss: 0.497  loss_cls: 0.2568  loss_box_reg: 0.1949  loss_rpn_cls: 0.01407  loss_rpn_loc: 0.0206    time: 0.4847  last_time: 0.5004  data_time: 0.0167  last_data_time: 0.0258   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:05:01 d2.utils.events]: \u001b[0m eta: 0:41:09  iter: 9899  total_loss: 0.5426  loss_cls: 0.2582  loss_box_reg: 0.1891  loss_rpn_cls: 0.0121  loss_rpn_loc: 0.02518    time: 0.4847  last_time: 0.4819  data_time: 0.0165  last_data_time: 0.0144   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:05:13 d2.utils.events]: \u001b[0m eta: 0:40:59  iter: 9919  total_loss: 0.5434  loss_cls: 0.2793  loss_box_reg: 0.2216  loss_rpn_cls: 0.01428  loss_rpn_loc: 0.02043    time: 0.4847  last_time: 0.4870  data_time: 0.0161  last_data_time: 0.0186   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:05:25 d2.utils.events]: \u001b[0m eta: 0:40:49  iter: 9939  total_loss: 0.5478  loss_cls: 0.2658  loss_box_reg: 0.2209  loss_rpn_cls: 0.01786  loss_rpn_loc: 0.02792    time: 0.4847  last_time: 0.4837  data_time: 0.0159  last_data_time: 0.0145   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:05:37 d2.utils.events]: \u001b[0m eta: 0:40:40  iter: 9959  total_loss: 0.5541  loss_cls: 0.2788  loss_box_reg: 0.2234  loss_rpn_cls: 0.01379  loss_rpn_loc: 0.02036    time: 0.4847  last_time: 0.4838  data_time: 0.0167  last_data_time: 0.0152   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:05:49 d2.utils.events]: \u001b[0m eta: 0:40:30  iter: 9979  total_loss: 0.5449  loss_cls: 0.2904  loss_box_reg: 0.209  loss_rpn_cls: 0.01179  loss_rpn_loc: 0.02535    time: 0.4847  last_time: 0.4842  data_time: 0.0164  last_data_time: 0.0165   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:06:01 d2.utils.events]: \u001b[0m eta: 0:40:20  iter: 9999  total_loss: 0.6169  loss_cls: 0.306  loss_box_reg: 0.2797  loss_rpn_cls: 0.01806  loss_rpn_loc: 0.02576    time: 0.4847  last_time: 0.4861  data_time: 0.0167  last_data_time: 0.0156   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:06:14 d2.utils.events]: \u001b[0m eta: 0:40:11  iter: 10019  total_loss: 0.551  loss_cls: 0.2842  loss_box_reg: 0.2217  loss_rpn_cls: 0.01506  loss_rpn_loc: 0.02569    time: 0.4847  last_time: 0.4981  data_time: 0.0173  last_data_time: 0.0159   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:06:26 d2.utils.events]: \u001b[0m eta: 0:40:01  iter: 10039  total_loss: 0.5027  loss_cls: 0.2528  loss_box_reg: 0.2007  loss_rpn_cls: 0.01078  loss_rpn_loc: 0.02187    time: 0.4847  last_time: 0.4853  data_time: 0.0171  last_data_time: 0.0153   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:06:38 d2.utils.events]: \u001b[0m eta: 0:39:51  iter: 10059  total_loss: 0.4845  loss_cls: 0.231  loss_box_reg: 0.1649  loss_rpn_cls: 0.01285  loss_rpn_loc: 0.01341    time: 0.4847  last_time: 0.4927  data_time: 0.0158  last_data_time: 0.0203   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:06:50 d2.utils.events]: \u001b[0m eta: 0:39:42  iter: 10079  total_loss: 0.5773  loss_cls: 0.28  loss_box_reg: 0.2532  loss_rpn_cls: 0.01364  loss_rpn_loc: 0.03006    time: 0.4847  last_time: 0.4846  data_time: 0.0165  last_data_time: 0.0147   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:07:02 d2.utils.events]: \u001b[0m eta: 0:39:32  iter: 10099  total_loss: 0.5001  loss_cls: 0.2546  loss_box_reg: 0.2237  loss_rpn_cls: 0.007617  loss_rpn_loc: 0.01761    time: 0.4847  last_time: 0.4839  data_time: 0.0158  last_data_time: 0.0165   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:07:14 d2.utils.events]: \u001b[0m eta: 0:39:23  iter: 10119  total_loss: 0.5328  loss_cls: 0.2779  loss_box_reg: 0.2078  loss_rpn_cls: 0.01237  loss_rpn_loc: 0.02159    time: 0.4847  last_time: 0.4868  data_time: 0.0162  last_data_time: 0.0171   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:07:26 d2.utils.events]: \u001b[0m eta: 0:39:13  iter: 10139  total_loss: 0.4917  loss_cls: 0.2702  loss_box_reg: 0.1866  loss_rpn_cls: 0.01228  loss_rpn_loc: 0.0169    time: 0.4847  last_time: 0.4858  data_time: 0.0169  last_data_time: 0.0161   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:07:39 d2.utils.events]: \u001b[0m eta: 0:39:04  iter: 10159  total_loss: 0.5657  loss_cls: 0.2622  loss_box_reg: 0.2255  loss_rpn_cls: 0.01444  loss_rpn_loc: 0.03033    time: 0.4847  last_time: 0.4865  data_time: 0.0179  last_data_time: 0.0177   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:07:51 d2.utils.events]: \u001b[0m eta: 0:38:54  iter: 10179  total_loss: 0.5814  loss_cls: 0.3018  loss_box_reg: 0.2509  loss_rpn_cls: 0.01312  loss_rpn_loc: 0.02385    time: 0.4847  last_time: 0.4885  data_time: 0.0158  last_data_time: 0.0166   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:08:03 d2.utils.events]: \u001b[0m eta: 0:38:44  iter: 10199  total_loss: 0.4707  loss_cls: 0.243  loss_box_reg: 0.1893  loss_rpn_cls: 0.01535  loss_rpn_loc: 0.01418    time: 0.4847  last_time: 0.4889  data_time: 0.0164  last_data_time: 0.0163   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:08:15 d2.utils.events]: \u001b[0m eta: 0:38:35  iter: 10219  total_loss: 0.4866  loss_cls: 0.2747  loss_box_reg: 0.1946  loss_rpn_cls: 0.009279  loss_rpn_loc: 0.01813    time: 0.4848  last_time: 0.4846  data_time: 0.0167  last_data_time: 0.0169   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:08:27 d2.utils.events]: \u001b[0m eta: 0:38:25  iter: 10239  total_loss: 0.541  loss_cls: 0.2872  loss_box_reg: 0.2171  loss_rpn_cls: 0.01415  loss_rpn_loc: 0.02039    time: 0.4848  last_time: 0.4849  data_time: 0.0162  last_data_time: 0.0154   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:08:39 d2.utils.events]: \u001b[0m eta: 0:38:16  iter: 10259  total_loss: 0.4145  loss_cls: 0.2011  loss_box_reg: 0.1547  loss_rpn_cls: 0.006785  loss_rpn_loc: 0.01672    time: 0.4848  last_time: 0.4854  data_time: 0.0165  last_data_time: 0.0169   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:08:51 d2.utils.events]: \u001b[0m eta: 0:38:06  iter: 10279  total_loss: 0.499  loss_cls: 0.2889  loss_box_reg: 0.187  loss_rpn_cls: 0.01283  loss_rpn_loc: 0.01482    time: 0.4848  last_time: 0.4843  data_time: 0.0168  last_data_time: 0.0157   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:09:04 d2.utils.events]: \u001b[0m eta: 0:37:57  iter: 10299  total_loss: 0.4468  loss_cls: 0.2373  loss_box_reg: 0.2066  loss_rpn_cls: 0.0103  loss_rpn_loc: 0.01603    time: 0.4848  last_time: 0.4861  data_time: 0.0160  last_data_time: 0.0194   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:09:16 d2.utils.events]: \u001b[0m eta: 0:37:47  iter: 10319  total_loss: 0.4727  loss_cls: 0.2471  loss_box_reg: 0.1878  loss_rpn_cls: 0.01452  loss_rpn_loc: 0.02031    time: 0.4848  last_time: 0.4849  data_time: 0.0165  last_data_time: 0.0149   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:09:28 d2.utils.events]: \u001b[0m eta: 0:37:38  iter: 10339  total_loss: 0.4845  loss_cls: 0.266  loss_box_reg: 0.2062  loss_rpn_cls: 0.01637  loss_rpn_loc: 0.01982    time: 0.4848  last_time: 0.4837  data_time: 0.0167  last_data_time: 0.0152   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:09:40 d2.utils.events]: \u001b[0m eta: 0:37:28  iter: 10359  total_loss: 0.6024  loss_cls: 0.3121  loss_box_reg: 0.231  loss_rpn_cls: 0.02063  loss_rpn_loc: 0.04825    time: 0.4848  last_time: 0.4932  data_time: 0.0173  last_data_time: 0.0218   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:09:52 d2.utils.events]: \u001b[0m eta: 0:37:18  iter: 10379  total_loss: 0.4  loss_cls: 0.2031  loss_box_reg: 0.161  loss_rpn_cls: 0.01146  loss_rpn_loc: 0.01865    time: 0.4848  last_time: 0.4857  data_time: 0.0155  last_data_time: 0.0143   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:10:04 d2.utils.events]: \u001b[0m eta: 0:37:09  iter: 10399  total_loss: 0.589  loss_cls: 0.2843  loss_box_reg: 0.2683  loss_rpn_cls: 0.0131  loss_rpn_loc: 0.02693    time: 0.4848  last_time: 0.4832  data_time: 0.0154  last_data_time: 0.0146   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:10:16 d2.utils.events]: \u001b[0m eta: 0:36:59  iter: 10419  total_loss: 0.4155  loss_cls: 0.2073  loss_box_reg: 0.1789  loss_rpn_cls: 0.008478  loss_rpn_loc: 0.01534    time: 0.4848  last_time: 0.4839  data_time: 0.0163  last_data_time: 0.0151   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:10:28 d2.utils.events]: \u001b[0m eta: 0:36:49  iter: 10439  total_loss: 0.5021  loss_cls: 0.2227  loss_box_reg: 0.2218  loss_rpn_cls: 0.01087  loss_rpn_loc: 0.01492    time: 0.4848  last_time: 0.4842  data_time: 0.0171  last_data_time: 0.0156   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:10:41 d2.utils.events]: \u001b[0m eta: 0:36:40  iter: 10459  total_loss: 0.5166  loss_cls: 0.2725  loss_box_reg: 0.2195  loss_rpn_cls: 0.01396  loss_rpn_loc: 0.01668    time: 0.4848  last_time: 0.4837  data_time: 0.0161  last_data_time: 0.0146   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:10:53 d2.utils.events]: \u001b[0m eta: 0:36:30  iter: 10479  total_loss: 0.6078  loss_cls: 0.307  loss_box_reg: 0.2516  loss_rpn_cls: 0.01055  loss_rpn_loc: 0.02484    time: 0.4848  last_time: 0.4846  data_time: 0.0156  last_data_time: 0.0180   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:11:05 d2.utils.events]: \u001b[0m eta: 0:36:20  iter: 10499  total_loss: 0.5204  loss_cls: 0.2473  loss_box_reg: 0.2136  loss_rpn_cls: 0.01672  loss_rpn_loc: 0.02661    time: 0.4848  last_time: 0.4822  data_time: 0.0166  last_data_time: 0.0151   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:11:17 d2.utils.events]: \u001b[0m eta: 0:36:11  iter: 10519  total_loss: 0.5633  loss_cls: 0.2648  loss_box_reg: 0.2076  loss_rpn_cls: 0.01384  loss_rpn_loc: 0.02453    time: 0.4848  last_time: 0.4833  data_time: 0.0180  last_data_time: 0.0150   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:11:29 d2.utils.events]: \u001b[0m eta: 0:36:01  iter: 10539  total_loss: 0.5491  loss_cls: 0.2825  loss_box_reg: 0.2382  loss_rpn_cls: 0.01377  loss_rpn_loc: 0.02277    time: 0.4848  last_time: 0.4799  data_time: 0.0154  last_data_time: 0.0149   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:11:41 d2.utils.events]: \u001b[0m eta: 0:35:51  iter: 10559  total_loss: 0.5601  loss_cls: 0.2909  loss_box_reg: 0.2439  loss_rpn_cls: 0.01571  loss_rpn_loc: 0.03371    time: 0.4848  last_time: 0.4850  data_time: 0.0157  last_data_time: 0.0162   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:11:53 d2.utils.events]: \u001b[0m eta: 0:35:42  iter: 10579  total_loss: 0.4908  loss_cls: 0.2263  loss_box_reg: 0.198  loss_rpn_cls: 0.01801  loss_rpn_loc: 0.01877    time: 0.4848  last_time: 0.4799  data_time: 0.0163  last_data_time: 0.0143   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:12:05 d2.utils.events]: \u001b[0m eta: 0:35:32  iter: 10599  total_loss: 0.6515  loss_cls: 0.2826  loss_box_reg: 0.2763  loss_rpn_cls: 0.01783  loss_rpn_loc: 0.02985    time: 0.4848  last_time: 0.4831  data_time: 0.0179  last_data_time: 0.0149   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:12:18 d2.utils.events]: \u001b[0m eta: 0:35:23  iter: 10619  total_loss: 0.5218  loss_cls: 0.2644  loss_box_reg: 0.2007  loss_rpn_cls: 0.01304  loss_rpn_loc: 0.01842    time: 0.4848  last_time: 0.4880  data_time: 0.0178  last_data_time: 0.0157   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:12:30 d2.utils.events]: \u001b[0m eta: 0:35:13  iter: 10639  total_loss: 0.4196  loss_cls: 0.2298  loss_box_reg: 0.1685  loss_rpn_cls: 0.01079  loss_rpn_loc: 0.01451    time: 0.4848  last_time: 0.4810  data_time: 0.0162  last_data_time: 0.0152   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:12:42 d2.utils.events]: \u001b[0m eta: 0:35:04  iter: 10659  total_loss: 0.5202  loss_cls: 0.2416  loss_box_reg: 0.2058  loss_rpn_cls: 0.01194  loss_rpn_loc: 0.02436    time: 0.4848  last_time: 0.4829  data_time: 0.0174  last_data_time: 0.0145   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:12:54 d2.utils.events]: \u001b[0m eta: 0:34:54  iter: 10679  total_loss: 0.5453  loss_cls: 0.2985  loss_box_reg: 0.2369  loss_rpn_cls: 0.008973  loss_rpn_loc: 0.02428    time: 0.4848  last_time: 0.4843  data_time: 0.0165  last_data_time: 0.0186   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:13:06 d2.utils.events]: \u001b[0m eta: 0:34:44  iter: 10699  total_loss: 0.5448  loss_cls: 0.2687  loss_box_reg: 0.2375  loss_rpn_cls: 0.01494  loss_rpn_loc: 0.02398    time: 0.4848  last_time: 0.4831  data_time: 0.0161  last_data_time: 0.0150   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:13:18 d2.utils.events]: \u001b[0m eta: 0:34:35  iter: 10719  total_loss: 0.5134  loss_cls: 0.2846  loss_box_reg: 0.202  loss_rpn_cls: 0.01413  loss_rpn_loc: 0.02365    time: 0.4848  last_time: 0.4839  data_time: 0.0176  last_data_time: 0.0152   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:13:30 d2.utils.events]: \u001b[0m eta: 0:34:25  iter: 10739  total_loss: 0.4607  loss_cls: 0.2339  loss_box_reg: 0.1695  loss_rpn_cls: 0.0081  loss_rpn_loc: 0.0113    time: 0.4848  last_time: 0.4860  data_time: 0.0181  last_data_time: 0.0153   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:13:43 d2.utils.events]: \u001b[0m eta: 0:34:15  iter: 10759  total_loss: 0.4684  loss_cls: 0.226  loss_box_reg: 0.2029  loss_rpn_cls: 0.009338  loss_rpn_loc: 0.02056    time: 0.4848  last_time: 0.4899  data_time: 0.0166  last_data_time: 0.0206   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:13:55 d2.utils.events]: \u001b[0m eta: 0:34:06  iter: 10779  total_loss: 0.4213  loss_cls: 0.2049  loss_box_reg: 0.1686  loss_rpn_cls: 0.008226  loss_rpn_loc: 0.01145    time: 0.4848  last_time: 0.4845  data_time: 0.0156  last_data_time: 0.0170   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:14:07 d2.utils.events]: \u001b[0m eta: 0:33:56  iter: 10799  total_loss: 0.5024  loss_cls: 0.2711  loss_box_reg: 0.203  loss_rpn_cls: 0.0141  loss_rpn_loc: 0.02567    time: 0.4848  last_time: 0.4844  data_time: 0.0171  last_data_time: 0.0146   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:14:19 d2.utils.events]: \u001b[0m eta: 0:33:47  iter: 10819  total_loss: 0.5119  loss_cls: 0.253  loss_box_reg: 0.2026  loss_rpn_cls: 0.01479  loss_rpn_loc: 0.0201    time: 0.4848  last_time: 0.4835  data_time: 0.0165  last_data_time: 0.0160   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:14:31 d2.utils.events]: \u001b[0m eta: 0:33:37  iter: 10839  total_loss: 0.6335  loss_cls: 0.3072  loss_box_reg: 0.2394  loss_rpn_cls: 0.0212  loss_rpn_loc: 0.03519    time: 0.4848  last_time: 0.4797  data_time: 0.0156  last_data_time: 0.0147   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:14:43 d2.utils.events]: \u001b[0m eta: 0:33:28  iter: 10859  total_loss: 0.5377  loss_cls: 0.3079  loss_box_reg: 0.2274  loss_rpn_cls: 0.008762  loss_rpn_loc: 0.01811    time: 0.4848  last_time: 0.4861  data_time: 0.0165  last_data_time: 0.0189   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:14:55 d2.utils.events]: \u001b[0m eta: 0:33:18  iter: 10879  total_loss: 0.4809  loss_cls: 0.2447  loss_box_reg: 0.1808  loss_rpn_cls: 0.008589  loss_rpn_loc: 0.0151    time: 0.4848  last_time: 0.4852  data_time: 0.0160  last_data_time: 0.0166   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:15:08 d2.utils.events]: \u001b[0m eta: 0:33:08  iter: 10899  total_loss: 0.5776  loss_cls: 0.2847  loss_box_reg: 0.2616  loss_rpn_cls: 0.01566  loss_rpn_loc: 0.03155    time: 0.4848  last_time: 0.4835  data_time: 0.0161  last_data_time: 0.0144   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:15:20 d2.utils.events]: \u001b[0m eta: 0:32:58  iter: 10919  total_loss: 0.4966  loss_cls: 0.2223  loss_box_reg: 0.2281  loss_rpn_cls: 0.01199  loss_rpn_loc: 0.02464    time: 0.4848  last_time: 0.4843  data_time: 0.0154  last_data_time: 0.0161   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:15:32 d2.utils.events]: \u001b[0m eta: 0:32:48  iter: 10939  total_loss: 0.5599  loss_cls: 0.2699  loss_box_reg: 0.2145  loss_rpn_cls: 0.01433  loss_rpn_loc: 0.03257    time: 0.4848  last_time: 0.4800  data_time: 0.0159  last_data_time: 0.0143   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:15:44 d2.utils.events]: \u001b[0m eta: 0:32:39  iter: 10959  total_loss: 0.4777  loss_cls: 0.2609  loss_box_reg: 0.1793  loss_rpn_cls: 0.008797  loss_rpn_loc: 0.01551    time: 0.4848  last_time: 0.4830  data_time: 0.0161  last_data_time: 0.0145   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:15:56 d2.utils.events]: \u001b[0m eta: 0:32:29  iter: 10979  total_loss: 0.5302  loss_cls: 0.2761  loss_box_reg: 0.2178  loss_rpn_cls: 0.01348  loss_rpn_loc: 0.02858    time: 0.4848  last_time: 0.4871  data_time: 0.0156  last_data_time: 0.0167   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:16:08 d2.utils.events]: \u001b[0m eta: 0:32:19  iter: 10999  total_loss: 0.5303  loss_cls: 0.2762  loss_box_reg: 0.1957  loss_rpn_cls: 0.01147  loss_rpn_loc: 0.02561    time: 0.4848  last_time: 0.4837  data_time: 0.0166  last_data_time: 0.0173   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:16:20 d2.utils.events]: \u001b[0m eta: 0:32:09  iter: 11019  total_loss: 0.5708  loss_cls: 0.2839  loss_box_reg: 0.2437  loss_rpn_cls: 0.009609  loss_rpn_loc: 0.01538    time: 0.4848  last_time: 0.4925  data_time: 0.0163  last_data_time: 0.0159   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:16:33 d2.utils.events]: \u001b[0m eta: 0:32:00  iter: 11039  total_loss: 0.5477  loss_cls: 0.2854  loss_box_reg: 0.2515  loss_rpn_cls: 0.01021  loss_rpn_loc: 0.02426    time: 0.4848  last_time: 0.4845  data_time: 0.0158  last_data_time: 0.0180   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:16:45 d2.utils.events]: \u001b[0m eta: 0:31:50  iter: 11059  total_loss: 0.481  loss_cls: 0.2629  loss_box_reg: 0.2109  loss_rpn_cls: 0.009813  loss_rpn_loc: 0.02912    time: 0.4848  last_time: 0.4825  data_time: 0.0156  last_data_time: 0.0146   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:16:57 d2.utils.events]: \u001b[0m eta: 0:31:40  iter: 11079  total_loss: 0.5908  loss_cls: 0.313  loss_box_reg: 0.2485  loss_rpn_cls: 0.01558  loss_rpn_loc: 0.02648    time: 0.4848  last_time: 0.4806  data_time: 0.0159  last_data_time: 0.0150   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:17:09 d2.utils.events]: \u001b[0m eta: 0:31:31  iter: 11099  total_loss: 0.5203  loss_cls: 0.2549  loss_box_reg: 0.2251  loss_rpn_cls: 0.01521  loss_rpn_loc: 0.01959    time: 0.4848  last_time: 0.4817  data_time: 0.0165  last_data_time: 0.0142   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:17:21 d2.utils.events]: \u001b[0m eta: 0:31:21  iter: 11119  total_loss: 0.5728  loss_cls: 0.3047  loss_box_reg: 0.176  loss_rpn_cls: 0.0152  loss_rpn_loc: 0.01982    time: 0.4848  last_time: 0.4824  data_time: 0.0164  last_data_time: 0.0147   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:17:33 d2.utils.events]: \u001b[0m eta: 0:31:11  iter: 11139  total_loss: 0.5161  loss_cls: 0.2363  loss_box_reg: 0.2024  loss_rpn_cls: 0.01276  loss_rpn_loc: 0.02298    time: 0.4848  last_time: 0.4823  data_time: 0.0155  last_data_time: 0.0145   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:17:45 d2.utils.events]: \u001b[0m eta: 0:31:01  iter: 11159  total_loss: 0.4881  loss_cls: 0.2598  loss_box_reg: 0.1786  loss_rpn_cls: 0.00897  loss_rpn_loc: 0.01131    time: 0.4848  last_time: 0.4822  data_time: 0.0156  last_data_time: 0.0147   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:17:57 d2.utils.events]: \u001b[0m eta: 0:30:51  iter: 11179  total_loss: 0.4764  loss_cls: 0.2453  loss_box_reg: 0.1755  loss_rpn_cls: 0.009128  loss_rpn_loc: 0.01694    time: 0.4848  last_time: 0.4834  data_time: 0.0157  last_data_time: 0.0141   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:18:09 d2.utils.events]: \u001b[0m eta: 0:30:41  iter: 11199  total_loss: 0.4812  loss_cls: 0.2495  loss_box_reg: 0.1983  loss_rpn_cls: 0.01078  loss_rpn_loc: 0.03114    time: 0.4848  last_time: 0.4805  data_time: 0.0162  last_data_time: 0.0144   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:18:22 d2.utils.events]: \u001b[0m eta: 0:30:32  iter: 11219  total_loss: 0.4967  loss_cls: 0.2529  loss_box_reg: 0.1927  loss_rpn_cls: 0.01804  loss_rpn_loc: 0.025    time: 0.4848  last_time: 0.4991  data_time: 0.0166  last_data_time: 0.0170   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:18:34 d2.utils.events]: \u001b[0m eta: 0:30:22  iter: 11239  total_loss: 0.5176  loss_cls: 0.251  loss_box_reg: 0.1955  loss_rpn_cls: 0.01448  loss_rpn_loc: 0.02147    time: 0.4848  last_time: 0.4978  data_time: 0.0165  last_data_time: 0.0144   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:18:46 d2.utils.events]: \u001b[0m eta: 0:30:12  iter: 11259  total_loss: 0.5574  loss_cls: 0.2752  loss_box_reg: 0.2537  loss_rpn_cls: 0.01045  loss_rpn_loc: 0.01794    time: 0.4848  last_time: 0.4929  data_time: 0.0164  last_data_time: 0.0162   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:18:58 d2.utils.events]: \u001b[0m eta: 0:30:02  iter: 11279  total_loss: 0.4829  loss_cls: 0.2267  loss_box_reg: 0.2155  loss_rpn_cls: 0.01687  loss_rpn_loc: 0.02089    time: 0.4848  last_time: 0.4839  data_time: 0.0161  last_data_time: 0.0144   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:19:10 d2.utils.events]: \u001b[0m eta: 0:29:53  iter: 11299  total_loss: 0.5112  loss_cls: 0.2739  loss_box_reg: 0.2037  loss_rpn_cls: 0.009997  loss_rpn_loc: 0.02053    time: 0.4848  last_time: 0.4882  data_time: 0.0166  last_data_time: 0.0193   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:19:22 d2.utils.events]: \u001b[0m eta: 0:29:43  iter: 11319  total_loss: 0.5494  loss_cls: 0.2353  loss_box_reg: 0.193  loss_rpn_cls: 0.01769  loss_rpn_loc: 0.02904    time: 0.4848  last_time: 0.4842  data_time: 0.0158  last_data_time: 0.0152   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:19:35 d2.utils.events]: \u001b[0m eta: 0:29:33  iter: 11339  total_loss: 0.4932  loss_cls: 0.2767  loss_box_reg: 0.1946  loss_rpn_cls: 0.01059  loss_rpn_loc: 0.01797    time: 0.4848  last_time: 0.4891  data_time: 0.0162  last_data_time: 0.0157   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:19:47 d2.utils.events]: \u001b[0m eta: 0:29:24  iter: 11359  total_loss: 0.4291  loss_cls: 0.2414  loss_box_reg: 0.1745  loss_rpn_cls: 0.01025  loss_rpn_loc: 0.0117    time: 0.4848  last_time: 0.4872  data_time: 0.0180  last_data_time: 0.0207   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:19:59 d2.utils.events]: \u001b[0m eta: 0:29:14  iter: 11379  total_loss: 0.5355  loss_cls: 0.2972  loss_box_reg: 0.2236  loss_rpn_cls: 0.01151  loss_rpn_loc: 0.01797    time: 0.4848  last_time: 0.4835  data_time: 0.0167  last_data_time: 0.0143   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:20:11 d2.utils.events]: \u001b[0m eta: 0:29:04  iter: 11399  total_loss: 0.3923  loss_cls: 0.2199  loss_box_reg: 0.1695  loss_rpn_cls: 0.00936  loss_rpn_loc: 0.02214    time: 0.4848  last_time: 0.4807  data_time: 0.0159  last_data_time: 0.0143   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:20:23 d2.utils.events]: \u001b[0m eta: 0:28:55  iter: 11419  total_loss: 0.5171  loss_cls: 0.2716  loss_box_reg: 0.2002  loss_rpn_cls: 0.01039  loss_rpn_loc: 0.02212    time: 0.4848  last_time: 0.4847  data_time: 0.0167  last_data_time: 0.0152   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:20:35 d2.utils.events]: \u001b[0m eta: 0:28:45  iter: 11439  total_loss: 0.4647  loss_cls: 0.228  loss_box_reg: 0.171  loss_rpn_cls: 0.01288  loss_rpn_loc: 0.02765    time: 0.4849  last_time: 0.4894  data_time: 0.0186  last_data_time: 0.0176   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:20:48 d2.utils.events]: \u001b[0m eta: 0:28:35  iter: 11459  total_loss: 0.4896  loss_cls: 0.2182  loss_box_reg: 0.1433  loss_rpn_cls: 0.00987  loss_rpn_loc: 0.01885    time: 0.4849  last_time: 0.4844  data_time: 0.0177  last_data_time: 0.0150   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:21:00 d2.utils.events]: \u001b[0m eta: 0:28:26  iter: 11479  total_loss: 0.5367  loss_cls: 0.2668  loss_box_reg: 0.2176  loss_rpn_cls: 0.01591  loss_rpn_loc: 0.03091    time: 0.4849  last_time: 0.4883  data_time: 0.0167  last_data_time: 0.0198   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:21:12 d2.utils.events]: \u001b[0m eta: 0:28:16  iter: 11499  total_loss: 0.4938  loss_cls: 0.2687  loss_box_reg: 0.2113  loss_rpn_cls: 0.01489  loss_rpn_loc: 0.03302    time: 0.4849  last_time: 0.4846  data_time: 0.0175  last_data_time: 0.0178   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:21:24 d2.utils.events]: \u001b[0m eta: 0:28:06  iter: 11519  total_loss: 0.5034  loss_cls: 0.238  loss_box_reg: 0.2128  loss_rpn_cls: 0.01046  loss_rpn_loc: 0.02258    time: 0.4849  last_time: 0.4836  data_time: 0.0164  last_data_time: 0.0152   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:21:36 d2.utils.events]: \u001b[0m eta: 0:27:57  iter: 11539  total_loss: 0.5236  loss_cls: 0.2877  loss_box_reg: 0.2199  loss_rpn_cls: 0.01867  loss_rpn_loc: 0.02918    time: 0.4849  last_time: 0.4806  data_time: 0.0177  last_data_time: 0.0148   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:21:48 d2.utils.events]: \u001b[0m eta: 0:27:47  iter: 11559  total_loss: 0.512  loss_cls: 0.2331  loss_box_reg: 0.2148  loss_rpn_cls: 0.0123  loss_rpn_loc: 0.01974    time: 0.4849  last_time: 0.4884  data_time: 0.0166  last_data_time: 0.0196   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:22:00 d2.utils.events]: \u001b[0m eta: 0:27:37  iter: 11579  total_loss: 0.5653  loss_cls: 0.2966  loss_box_reg: 0.2144  loss_rpn_cls: 0.01121  loss_rpn_loc: 0.02031    time: 0.4849  last_time: 0.4864  data_time: 0.0173  last_data_time: 0.0147   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:22:12 d2.utils.events]: \u001b[0m eta: 0:27:28  iter: 11599  total_loss: 0.4839  loss_cls: 0.2309  loss_box_reg: 0.1892  loss_rpn_cls: 0.0124  loss_rpn_loc: 0.01408    time: 0.4849  last_time: 0.4840  data_time: 0.0175  last_data_time: 0.0154   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:22:25 d2.utils.events]: \u001b[0m eta: 0:27:18  iter: 11619  total_loss: 0.5375  loss_cls: 0.2417  loss_box_reg: 0.2095  loss_rpn_cls: 0.01198  loss_rpn_loc: 0.0156    time: 0.4849  last_time: 0.4905  data_time: 0.0168  last_data_time: 0.0193   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:22:37 d2.utils.events]: \u001b[0m eta: 0:27:08  iter: 11639  total_loss: 0.4981  loss_cls: 0.2537  loss_box_reg: 0.212  loss_rpn_cls: 0.0114  loss_rpn_loc: 0.02893    time: 0.4849  last_time: 0.4826  data_time: 0.0165  last_data_time: 0.0150   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:22:49 d2.utils.events]: \u001b[0m eta: 0:26:59  iter: 11659  total_loss: 0.5452  loss_cls: 0.2919  loss_box_reg: 0.2255  loss_rpn_cls: 0.01214  loss_rpn_loc: 0.02329    time: 0.4849  last_time: 0.4808  data_time: 0.0171  last_data_time: 0.0144   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:23:01 d2.utils.events]: \u001b[0m eta: 0:26:49  iter: 11679  total_loss: 0.3965  loss_cls: 0.2187  loss_box_reg: 0.1792  loss_rpn_cls: 0.008818  loss_rpn_loc: 0.01976    time: 0.4849  last_time: 0.4889  data_time: 0.0166  last_data_time: 0.0155   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:23:13 d2.utils.events]: \u001b[0m eta: 0:26:39  iter: 11699  total_loss: 0.5437  loss_cls: 0.2577  loss_box_reg: 0.2315  loss_rpn_cls: 0.0158  loss_rpn_loc: 0.02209    time: 0.4849  last_time: 0.4795  data_time: 0.0163  last_data_time: 0.0151   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:23:25 d2.utils.events]: \u001b[0m eta: 0:26:30  iter: 11719  total_loss: 0.4979  loss_cls: 0.2549  loss_box_reg: 0.1996  loss_rpn_cls: 0.01137  loss_rpn_loc: 0.01703    time: 0.4849  last_time: 0.4841  data_time: 0.0167  last_data_time: 0.0152   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:23:37 d2.utils.events]: \u001b[0m eta: 0:26:20  iter: 11739  total_loss: 0.5875  loss_cls: 0.3367  loss_box_reg: 0.2433  loss_rpn_cls: 0.01366  loss_rpn_loc: 0.0183    time: 0.4849  last_time: 0.4833  data_time: 0.0167  last_data_time: 0.0147   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:23:49 d2.utils.events]: \u001b[0m eta: 0:26:10  iter: 11759  total_loss: 0.4447  loss_cls: 0.24  loss_box_reg: 0.1786  loss_rpn_cls: 0.008891  loss_rpn_loc: 0.01495    time: 0.4849  last_time: 0.4870  data_time: 0.0159  last_data_time: 0.0180   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:24:01 d2.utils.events]: \u001b[0m eta: 0:26:00  iter: 11779  total_loss: 0.5111  loss_cls: 0.2824  loss_box_reg: 0.2112  loss_rpn_cls: 0.0106  loss_rpn_loc: 0.01941    time: 0.4849  last_time: 0.4818  data_time: 0.0166  last_data_time: 0.0144   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:24:14 d2.utils.events]: \u001b[0m eta: 0:25:51  iter: 11799  total_loss: 0.5049  loss_cls: 0.2461  loss_box_reg: 0.2332  loss_rpn_cls: 0.01285  loss_rpn_loc: 0.02995    time: 0.4849  last_time: 0.4820  data_time: 0.0162  last_data_time: 0.0147   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:24:26 d2.utils.events]: \u001b[0m eta: 0:25:41  iter: 11819  total_loss: 0.5189  loss_cls: 0.3037  loss_box_reg: 0.2014  loss_rpn_cls: 0.01035  loss_rpn_loc: 0.02251    time: 0.4849  last_time: 0.4863  data_time: 0.0160  last_data_time: 0.0162   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:24:38 d2.utils.events]: \u001b[0m eta: 0:25:31  iter: 11839  total_loss: 0.5089  loss_cls: 0.2428  loss_box_reg: 0.2066  loss_rpn_cls: 0.01469  loss_rpn_loc: 0.01596    time: 0.4849  last_time: 0.4854  data_time: 0.0167  last_data_time: 0.0167   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:24:50 d2.utils.events]: \u001b[0m eta: 0:25:22  iter: 11859  total_loss: 0.4503  loss_cls: 0.2081  loss_box_reg: 0.1813  loss_rpn_cls: 0.008268  loss_rpn_loc: 0.01124    time: 0.4849  last_time: 0.4796  data_time: 0.0169  last_data_time: 0.0145   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:25:02 d2.utils.events]: \u001b[0m eta: 0:25:12  iter: 11879  total_loss: 0.4848  loss_cls: 0.2327  loss_box_reg: 0.1858  loss_rpn_cls: 0.01478  loss_rpn_loc: 0.03237    time: 0.4849  last_time: 0.4789  data_time: 0.0170  last_data_time: 0.0142   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:25:14 d2.utils.events]: \u001b[0m eta: 0:25:02  iter: 11899  total_loss: 0.5422  loss_cls: 0.2733  loss_box_reg: 0.2177  loss_rpn_cls: 0.01091  loss_rpn_loc: 0.01591    time: 0.4849  last_time: 0.4829  data_time: 0.0177  last_data_time: 0.0144   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:25:26 d2.utils.events]: \u001b[0m eta: 0:24:53  iter: 11919  total_loss: 0.5959  loss_cls: 0.2818  loss_box_reg: 0.2203  loss_rpn_cls: 0.01336  loss_rpn_loc: 0.02913    time: 0.4849  last_time: 0.4845  data_time: 0.0174  last_data_time: 0.0155   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:25:39 d2.utils.events]: \u001b[0m eta: 0:24:43  iter: 11939  total_loss: 0.5069  loss_cls: 0.2666  loss_box_reg: 0.2268  loss_rpn_cls: 0.0106  loss_rpn_loc: 0.01467    time: 0.4849  last_time: 0.4821  data_time: 0.0152  last_data_time: 0.0149   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:25:51 d2.utils.events]: \u001b[0m eta: 0:24:33  iter: 11959  total_loss: 0.5822  loss_cls: 0.2794  loss_box_reg: 0.2495  loss_rpn_cls: 0.0151  loss_rpn_loc: 0.02695    time: 0.4849  last_time: 0.4850  data_time: 0.0166  last_data_time: 0.0168   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:26:03 d2.utils.events]: \u001b[0m eta: 0:24:23  iter: 11979  total_loss: 0.5232  loss_cls: 0.2394  loss_box_reg: 0.2012  loss_rpn_cls: 0.01426  loss_rpn_loc: 0.03174    time: 0.4849  last_time: 0.4868  data_time: 0.0170  last_data_time: 0.0178   lr: 5e-06  max_mem: 6696M\n",
      "\u001b[32m[10/10 03:26:19 d2.data.datasets.coco]: \u001b[0mLoaded 4871 images in COCO format from /data/ephemeral/home/workspace/dataset/test.json\n",
      "\u001b[32m[10/10 03:26:19 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/10 03:26:19 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[10/10 03:26:19 d2.data.common]: \u001b[0mSerializing 4871 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/10 03:26:19 d2.data.common]: \u001b[0mSerialized dataset takes 0.63 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/10 03:26:19 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[10/10 03:26:19 d2.evaluation.evaluator]: \u001b[0mStart inference on 4871 batches\n",
      "\u001b[32m[10/10 03:26:19 d2.evaluation.evaluator]: \u001b[0mInference done 11/4871. Dataloading: 0.0010 s/iter. Inference: 0.0457 s/iter. Eval: 0.0003 s/iter. Total: 0.0471 s/iter. ETA=0:03:48\n",
      "\u001b[32m[10/10 03:26:24 d2.evaluation.evaluator]: \u001b[0mInference done 113/4871. Dataloading: 0.0014 s/iter. Inference: 0.0474 s/iter. Eval: 0.0003 s/iter. Total: 0.0491 s/iter. ETA=0:03:53\n",
      "\u001b[32m[10/10 03:26:29 d2.evaluation.evaluator]: \u001b[0mInference done 219/4871. Dataloading: 0.0014 s/iter. Inference: 0.0466 s/iter. Eval: 0.0003 s/iter. Total: 0.0483 s/iter. ETA=0:03:44\n",
      "\u001b[32m[10/10 03:26:34 d2.evaluation.evaluator]: \u001b[0mInference done 327/4871. Dataloading: 0.0013 s/iter. Inference: 0.0460 s/iter. Eval: 0.0002 s/iter. Total: 0.0477 s/iter. ETA=0:03:36\n",
      "\u001b[32m[10/10 03:26:40 d2.evaluation.evaluator]: \u001b[0mInference done 433/4871. Dataloading: 0.0014 s/iter. Inference: 0.0460 s/iter. Eval: 0.0002 s/iter. Total: 0.0476 s/iter. ETA=0:03:31\n",
      "\u001b[32m[10/10 03:26:45 d2.evaluation.evaluator]: \u001b[0mInference done 536/4871. Dataloading: 0.0014 s/iter. Inference: 0.0461 s/iter. Eval: 0.0002 s/iter. Total: 0.0478 s/iter. ETA=0:03:27\n",
      "\u001b[32m[10/10 03:26:50 d2.evaluation.evaluator]: \u001b[0mInference done 641/4871. Dataloading: 0.0014 s/iter. Inference: 0.0462 s/iter. Eval: 0.0002 s/iter. Total: 0.0479 s/iter. ETA=0:03:22\n",
      "\u001b[32m[10/10 03:26:55 d2.evaluation.evaluator]: \u001b[0mInference done 747/4871. Dataloading: 0.0014 s/iter. Inference: 0.0461 s/iter. Eval: 0.0002 s/iter. Total: 0.0478 s/iter. ETA=0:03:17\n",
      "\u001b[32m[10/10 03:27:00 d2.evaluation.evaluator]: \u001b[0mInference done 854/4871. Dataloading: 0.0014 s/iter. Inference: 0.0460 s/iter. Eval: 0.0002 s/iter. Total: 0.0477 s/iter. ETA=0:03:11\n",
      "\u001b[32m[10/10 03:27:05 d2.evaluation.evaluator]: \u001b[0mInference done 958/4871. Dataloading: 0.0014 s/iter. Inference: 0.0461 s/iter. Eval: 0.0003 s/iter. Total: 0.0478 s/iter. ETA=0:03:06\n",
      "\u001b[32m[10/10 03:27:10 d2.evaluation.evaluator]: \u001b[0mInference done 1059/4871. Dataloading: 0.0014 s/iter. Inference: 0.0462 s/iter. Eval: 0.0003 s/iter. Total: 0.0479 s/iter. ETA=0:03:02\n",
      "\u001b[32m[10/10 03:27:15 d2.evaluation.evaluator]: \u001b[0mInference done 1163/4871. Dataloading: 0.0014 s/iter. Inference: 0.0462 s/iter. Eval: 0.0003 s/iter. Total: 0.0480 s/iter. ETA=0:02:57\n",
      "\u001b[32m[10/10 03:27:20 d2.evaluation.evaluator]: \u001b[0mInference done 1265/4871. Dataloading: 0.0014 s/iter. Inference: 0.0464 s/iter. Eval: 0.0003 s/iter. Total: 0.0481 s/iter. ETA=0:02:53\n",
      "\u001b[32m[10/10 03:27:25 d2.evaluation.evaluator]: \u001b[0mInference done 1367/4871. Dataloading: 0.0014 s/iter. Inference: 0.0464 s/iter. Eval: 0.0003 s/iter. Total: 0.0482 s/iter. ETA=0:02:48\n",
      "\u001b[32m[10/10 03:27:30 d2.evaluation.evaluator]: \u001b[0mInference done 1468/4871. Dataloading: 0.0014 s/iter. Inference: 0.0465 s/iter. Eval: 0.0003 s/iter. Total: 0.0483 s/iter. ETA=0:02:44\n",
      "\u001b[32m[10/10 03:27:35 d2.evaluation.evaluator]: \u001b[0mInference done 1572/4871. Dataloading: 0.0014 s/iter. Inference: 0.0466 s/iter. Eval: 0.0003 s/iter. Total: 0.0483 s/iter. ETA=0:02:39\n",
      "\u001b[32m[10/10 03:27:40 d2.evaluation.evaluator]: \u001b[0mInference done 1676/4871. Dataloading: 0.0014 s/iter. Inference: 0.0466 s/iter. Eval: 0.0003 s/iter. Total: 0.0483 s/iter. ETA=0:02:34\n",
      "\u001b[32m[10/10 03:27:45 d2.evaluation.evaluator]: \u001b[0mInference done 1778/4871. Dataloading: 0.0014 s/iter. Inference: 0.0466 s/iter. Eval: 0.0003 s/iter. Total: 0.0484 s/iter. ETA=0:02:29\n",
      "\u001b[32m[10/10 03:27:50 d2.evaluation.evaluator]: \u001b[0mInference done 1883/4871. Dataloading: 0.0014 s/iter. Inference: 0.0466 s/iter. Eval: 0.0003 s/iter. Total: 0.0483 s/iter. ETA=0:02:24\n",
      "\u001b[32m[10/10 03:27:55 d2.evaluation.evaluator]: \u001b[0mInference done 1985/4871. Dataloading: 0.0014 s/iter. Inference: 0.0466 s/iter. Eval: 0.0003 s/iter. Total: 0.0484 s/iter. ETA=0:02:19\n",
      "\u001b[32m[10/10 03:28:00 d2.evaluation.evaluator]: \u001b[0mInference done 2087/4871. Dataloading: 0.0015 s/iter. Inference: 0.0467 s/iter. Eval: 0.0003 s/iter. Total: 0.0484 s/iter. ETA=0:02:14\n",
      "\u001b[32m[10/10 03:28:05 d2.evaluation.evaluator]: \u001b[0mInference done 2192/4871. Dataloading: 0.0014 s/iter. Inference: 0.0466 s/iter. Eval: 0.0003 s/iter. Total: 0.0484 s/iter. ETA=0:02:09\n",
      "\u001b[32m[10/10 03:28:10 d2.evaluation.evaluator]: \u001b[0mInference done 2294/4871. Dataloading: 0.0014 s/iter. Inference: 0.0467 s/iter. Eval: 0.0003 s/iter. Total: 0.0484 s/iter. ETA=0:02:04\n",
      "\u001b[32m[10/10 03:28:15 d2.evaluation.evaluator]: \u001b[0mInference done 2395/4871. Dataloading: 0.0014 s/iter. Inference: 0.0467 s/iter. Eval: 0.0003 s/iter. Total: 0.0485 s/iter. ETA=0:02:00\n",
      "\u001b[32m[10/10 03:28:20 d2.evaluation.evaluator]: \u001b[0mInference done 2498/4871. Dataloading: 0.0014 s/iter. Inference: 0.0467 s/iter. Eval: 0.0003 s/iter. Total: 0.0485 s/iter. ETA=0:01:55\n",
      "\u001b[32m[10/10 03:28:25 d2.evaluation.evaluator]: \u001b[0mInference done 2599/4871. Dataloading: 0.0015 s/iter. Inference: 0.0468 s/iter. Eval: 0.0003 s/iter. Total: 0.0485 s/iter. ETA=0:01:50\n",
      "\u001b[32m[10/10 03:28:30 d2.evaluation.evaluator]: \u001b[0mInference done 2702/4871. Dataloading: 0.0015 s/iter. Inference: 0.0468 s/iter. Eval: 0.0003 s/iter. Total: 0.0485 s/iter. ETA=0:01:45\n",
      "\u001b[32m[10/10 03:28:35 d2.evaluation.evaluator]: \u001b[0mInference done 2803/4871. Dataloading: 0.0015 s/iter. Inference: 0.0468 s/iter. Eval: 0.0003 s/iter. Total: 0.0486 s/iter. ETA=0:01:40\n",
      "\u001b[32m[10/10 03:28:40 d2.evaluation.evaluator]: \u001b[0mInference done 2908/4871. Dataloading: 0.0015 s/iter. Inference: 0.0468 s/iter. Eval: 0.0003 s/iter. Total: 0.0486 s/iter. ETA=0:01:35\n",
      "\u001b[32m[10/10 03:28:45 d2.evaluation.evaluator]: \u001b[0mInference done 3006/4871. Dataloading: 0.0015 s/iter. Inference: 0.0469 s/iter. Eval: 0.0003 s/iter. Total: 0.0486 s/iter. ETA=0:01:30\n",
      "\u001b[32m[10/10 03:28:50 d2.evaluation.evaluator]: \u001b[0mInference done 3108/4871. Dataloading: 0.0015 s/iter. Inference: 0.0469 s/iter. Eval: 0.0003 s/iter. Total: 0.0487 s/iter. ETA=0:01:25\n",
      "\u001b[32m[10/10 03:28:55 d2.evaluation.evaluator]: \u001b[0mInference done 3209/4871. Dataloading: 0.0015 s/iter. Inference: 0.0469 s/iter. Eval: 0.0003 s/iter. Total: 0.0487 s/iter. ETA=0:01:20\n",
      "\u001b[32m[10/10 03:29:00 d2.evaluation.evaluator]: \u001b[0mInference done 3313/4871. Dataloading: 0.0015 s/iter. Inference: 0.0469 s/iter. Eval: 0.0003 s/iter. Total: 0.0487 s/iter. ETA=0:01:15\n",
      "\u001b[32m[10/10 03:29:05 d2.evaluation.evaluator]: \u001b[0mInference done 3413/4871. Dataloading: 0.0015 s/iter. Inference: 0.0469 s/iter. Eval: 0.0003 s/iter. Total: 0.0487 s/iter. ETA=0:01:11\n",
      "\u001b[32m[10/10 03:29:10 d2.evaluation.evaluator]: \u001b[0mInference done 3516/4871. Dataloading: 0.0015 s/iter. Inference: 0.0469 s/iter. Eval: 0.0003 s/iter. Total: 0.0487 s/iter. ETA=0:01:06\n",
      "\u001b[32m[10/10 03:29:15 d2.evaluation.evaluator]: \u001b[0mInference done 3621/4871. Dataloading: 0.0015 s/iter. Inference: 0.0469 s/iter. Eval: 0.0003 s/iter. Total: 0.0487 s/iter. ETA=0:01:00\n",
      "\u001b[32m[10/10 03:29:20 d2.evaluation.evaluator]: \u001b[0mInference done 3723/4871. Dataloading: 0.0015 s/iter. Inference: 0.0469 s/iter. Eval: 0.0003 s/iter. Total: 0.0487 s/iter. ETA=0:00:55\n",
      "\u001b[32m[10/10 03:29:25 d2.evaluation.evaluator]: \u001b[0mInference done 3826/4871. Dataloading: 0.0015 s/iter. Inference: 0.0469 s/iter. Eval: 0.0003 s/iter. Total: 0.0487 s/iter. ETA=0:00:50\n",
      "\u001b[32m[10/10 03:29:27 d2.engine.hooks]: \u001b[0mOverall training speed: 11997 iterations in 1:36:57 (0.4849 s / it)\n",
      "\u001b[32m[10/10 03:29:27 d2.engine.hooks]: \u001b[0mTotal training time: 2:13:50 (0:36:52 on hooks)\n",
      "\u001b[32m[10/10 03:29:27 d2.utils.events]: \u001b[0m eta: 0:24:14  iter: 11999  total_loss: 0.4633  loss_cls: 0.2517  loss_box_reg: 0.1889  loss_rpn_cls: 0.01059  loss_rpn_loc: 0.01511    time: 0.4849  last_time: 0.4891  data_time: 0.0160  last_data_time: 0.0161   lr: 5e-06  max_mem: 6696M\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m trainer\u001b[38;5;241m.\u001b[39mregister_hooks(hooks\u001b[38;5;241m=\u001b[39m[mlflow_hook])\n\u001b[1;32m      8\u001b[0m trainer\u001b[38;5;241m.\u001b[39mresume_or_load(resume\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m----> 9\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/baselinecode/detectron2/detectron2/engine/defaults.py:520\u001b[0m, in \u001b[0;36mDefaultTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    514\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;124;03m    Run training.\u001b[39;00m\n\u001b[1;32m    516\u001b[0m \n\u001b[1;32m    517\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[1;32m    518\u001b[0m \u001b[38;5;124;03m        OrderedDict of results, if evaluation is enabled. Otherwise None.\u001b[39;00m\n\u001b[1;32m    519\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 520\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    521\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mTEST\u001b[38;5;241m.\u001b[39mEXPECTED_RESULTS) \u001b[38;5;129;01mand\u001b[39;00m comm\u001b[38;5;241m.\u001b[39mis_main_process():\n\u001b[1;32m    522\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\n\u001b[1;32m    523\u001b[0m             \u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_last_eval_results\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    524\u001b[0m         ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo evaluation results obtained during training!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/workspace/baselinecode/detectron2/detectron2/engine/train_loop.py:156\u001b[0m, in \u001b[0;36mTrainerBase.train\u001b[0;34m(self, start_iter, max_iter)\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbefore_step()\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_step()\n\u001b[0;32m--> 156\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mafter_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;66;03m# self.iter == max_iter can be used by `after_train` to\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;66;03m# tell whether the training successfully finished or failed\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;66;03m# due to exceptions.\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/workspace/baselinecode/detectron2/detectron2/engine/train_loop.py:190\u001b[0m, in \u001b[0;36mTrainerBase.after_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mafter_step\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hooks:\n\u001b[0;32m--> 190\u001b[0m         \u001b[43mh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mafter_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/baselinecode/detectron2/detectron2/engine/hooks.py:556\u001b[0m, in \u001b[0;36mEvalHook.after_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_period \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m next_iter \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_period \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    554\u001b[0m     \u001b[38;5;66;03m# do the last eval in after_train\u001b[39;00m\n\u001b[1;32m    555\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m next_iter \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmax_iter:\n\u001b[0;32m--> 556\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/baselinecode/detectron2/detectron2/engine/hooks.py:529\u001b[0m, in \u001b[0;36mEvalHook._do_eval\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_do_eval\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 529\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    531\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m results:\n\u001b[1;32m    532\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    533\u001b[0m             results, \u001b[38;5;28mdict\u001b[39m\n\u001b[1;32m    534\u001b[0m         ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEval function must return a dict. Got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(results)\n",
      "File \u001b[0;32m~/workspace/baselinecode/detectron2/detectron2/engine/defaults.py:489\u001b[0m, in \u001b[0;36mDefaultTrainer.build_hooks.<locals>.test_and_save_results\u001b[0;34m()\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtest_and_save_results\u001b[39m():\n\u001b[0;32m--> 489\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_eval_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    490\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_eval_results\n",
      "File \u001b[0;32m~/workspace/baselinecode/detectron2/detectron2/engine/defaults.py:653\u001b[0m, in \u001b[0;36mDefaultTrainer.test\u001b[0;34m(cls, cfg, model, evaluators)\u001b[0m\n\u001b[1;32m    651\u001b[0m         results[dataset_name] \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    652\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m--> 653\u001b[0m results_i \u001b[38;5;241m=\u001b[39m \u001b[43minference_on_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevaluator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    654\u001b[0m results[dataset_name] \u001b[38;5;241m=\u001b[39m results_i\n\u001b[1;32m    655\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m comm\u001b[38;5;241m.\u001b[39mis_main_process():\n",
      "File \u001b[0;32m~/workspace/baselinecode/detectron2/detectron2/evaluation/evaluator.py:165\u001b[0m, in \u001b[0;36minference_on_dataset\u001b[0;34m(model, data_loader, evaluator, callbacks)\u001b[0m\n\u001b[1;32m    163\u001b[0m start_compute_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28mdict\u001b[39m\u001b[38;5;241m.\u001b[39mget(callbacks \u001b[38;5;129;01mor\u001b[39;00m {}, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbefore_inference\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28;01mNone\u001b[39;00m)()\n\u001b[0;32m--> 165\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28mdict\u001b[39m\u001b[38;5;241m.\u001b[39mget(callbacks \u001b[38;5;129;01mor\u001b[39;00m {}, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mafter_inference\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28;01mNone\u001b[39;00m)()\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/workspace/baselinecode/detectron2/detectron2/modeling/meta_arch/rcnn.py:150\u001b[0m, in \u001b[0;36mGeneralizedRCNN.forward\u001b[0;34m(self, batched_inputs)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;124;03m    batched_inputs: a list, batched outputs of :class:`DatasetMapper` .\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;124;03m        \"pred_boxes\", \"pred_classes\", \"scores\", \"pred_masks\", \"pred_keypoints\"\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[0;32m--> 150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatched_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    152\u001b[0m images \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess_image(batched_inputs)\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstances\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m batched_inputs[\u001b[38;5;241m0\u001b[39m]:\n",
      "File \u001b[0;32m~/workspace/baselinecode/detectron2/detectron2/modeling/meta_arch/rcnn.py:208\u001b[0m, in \u001b[0;36mGeneralizedRCNN.inference\u001b[0;34m(self, batched_inputs, detected_instances, do_postprocess)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m detected_instances \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproposal_generator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 208\u001b[0m         proposals, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproposal_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproposals\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m batched_inputs[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/workspace/baselinecode/detectron2/detectron2/modeling/proposal_generator/rpn.py:452\u001b[0m, in \u001b[0;36mRPN.forward\u001b[0;34m(self, images, features, gt_instances)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;124;03m    images (ImageList): input images of length `N`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03m    loss: dict[Tensor] or None\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    451\u001b[0m features \u001b[38;5;241m=\u001b[39m [features[f] \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_features]\n\u001b[0;32m--> 452\u001b[0m anchors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43manchor_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    454\u001b[0m pred_objectness_logits, pred_anchor_deltas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrpn_head(features)\n\u001b[1;32m    455\u001b[0m \u001b[38;5;66;03m# Transpose the Hi*Wi*A dimension to the middle:\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/workspace/baselinecode/detectron2/detectron2/modeling/anchor_generator.py:230\u001b[0m, in \u001b[0;36mDefaultAnchorGenerator.forward\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;124;03m    features (list[Tensor]): list of backbone feature maps on which to generate anchors.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;124;03m        where Hi, Wi are resolution of the feature map divided by anchor stride.\u001b[39;00m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    229\u001b[0m grid_sizes \u001b[38;5;241m=\u001b[39m [feature_map\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:] \u001b[38;5;28;01mfor\u001b[39;00m feature_map \u001b[38;5;129;01min\u001b[39;00m features]\n\u001b[0;32m--> 230\u001b[0m anchors_over_all_feature_maps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_grid_anchors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrid_sizes\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pyre-ignore\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [Boxes(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m anchors_over_all_feature_maps]\n",
      "File \u001b[0;32m~/workspace/baselinecode/detectron2/detectron2/modeling/anchor_generator.py:174\u001b[0m, in \u001b[0;36mDefaultAnchorGenerator._grid_anchors\u001b[0;34m(self, grid_sizes)\u001b[0m\n\u001b[1;32m    172\u001b[0m buffers: List[torch\u001b[38;5;241m.\u001b[39mTensor] \u001b[38;5;241m=\u001b[39m [x[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcell_anchors\u001b[38;5;241m.\u001b[39mnamed_buffers()]\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m size, stride, base_anchors \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(grid_sizes, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrides, buffers):\n\u001b[0;32m--> 174\u001b[0m     shift_x, shift_y \u001b[38;5;241m=\u001b[39m \u001b[43m_create_grid_offsets\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_anchors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    175\u001b[0m     shifts \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack((shift_x, shift_y, shift_x, shift_y), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    177\u001b[0m     anchors\u001b[38;5;241m.\u001b[39mappend((shifts\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m4\u001b[39m) \u001b[38;5;241m+\u001b[39m base_anchors\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m4\u001b[39m))\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m4\u001b[39m))\n",
      "File \u001b[0;32m~/workspace/baselinecode/detectron2/detectron2/modeling/anchor_generator.py:43\u001b[0m, in \u001b[0;36m_create_grid_offsets\u001b[0;34m(size, stride, offset, target_device_tensor)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_create_grid_offsets\u001b[39m(\n\u001b[1;32m     40\u001b[0m     size: List[\u001b[38;5;28mint\u001b[39m], stride: \u001b[38;5;28mint\u001b[39m, offset: \u001b[38;5;28mfloat\u001b[39m, target_device_tensor: torch\u001b[38;5;241m.\u001b[39mTensor\n\u001b[1;32m     41\u001b[0m ):\n\u001b[1;32m     42\u001b[0m     grid_height, grid_width \u001b[38;5;241m=\u001b[39m size\n\u001b[0;32m---> 43\u001b[0m     shifts_x \u001b[38;5;241m=\u001b[39m \u001b[43mmove_device_like\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[43moffset\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrid_width\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_device_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m     shifts_y \u001b[38;5;241m=\u001b[39m move_device_like(\n\u001b[1;32m     48\u001b[0m         torch\u001b[38;5;241m.\u001b[39marange(offset \u001b[38;5;241m*\u001b[39m stride, grid_height \u001b[38;5;241m*\u001b[39m stride, step\u001b[38;5;241m=\u001b[39mstride, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32),\n\u001b[1;32m     49\u001b[0m         target_device_tensor,\n\u001b[1;32m     50\u001b[0m     )\n\u001b[1;32m     52\u001b[0m     shift_y, shift_x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmeshgrid(shifts_y, shifts_x)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/jit/_trace.py:1127\u001b[0m, in \u001b[0;36m_script_if_tracing.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(fn)\n\u001b[1;32m   1124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1125\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tracing():\n\u001b[1;32m   1126\u001b[0m         \u001b[38;5;66;03m# Not tracing, don't do anything\u001b[39;00m\n\u001b[0;32m-> 1127\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1129\u001b[0m     compiled_fn \u001b[38;5;241m=\u001b[39m script(wrapper\u001b[38;5;241m.\u001b[39m__original_fn)  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m compiled_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/workspace/baselinecode/detectron2/detectron2/layers/wrappers.py:177\u001b[0m, in \u001b[0;36mmove_device_like\u001b[0;34m(src, dst)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mscript_if_tracing\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmove_device_like\u001b[39m(src: torch\u001b[38;5;241m.\u001b[39mTensor, dst: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m    173\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;124;03m    Tracing friendly way to cast tensor to another tensor's device. Device will be treated\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;124;03m    as constant during tracing, scripting the casting process as whole can workaround this issue.\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 177\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msrc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok = True)\n",
    "\n",
    "mlflow_hook = MLflowHook(cfg)\n",
    "\n",
    "trainer = MyTrainer(cfg)\n",
    "trainer.register_hooks(hooks=[mlflow_hook])\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
